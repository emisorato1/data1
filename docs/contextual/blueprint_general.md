<div align="center">

# ğŸ¢ ARQUITECTURA DE BASE DE DATOS VECTORIAL PARA SISTEMA RAG EMPRESARIAL

## GuÃ­a de Dimensionamiento, OptimizaciÃ³n y OperaciÃ³n

---

**Proyecto:** Enterprise AI Platform  
**VersiÃ³n:** 3.0 | **Fecha:** Enero 2026

---

| Metadato | Valor |
|:---------|:------|
| **Autor** | Equipo de Arquitectura |
| **ClasificaciÃ³n** | Documento TÃ©cnico de Referencia |
| **Audiencia Primaria** | Arquitectos de Soluciones, Ingenieros ML/AI, DevOps/SRE |
| **Audiencia Secundaria** | Stakeholders Ejecutivos, Equipo de Finanzas |
| **Estado** | VersiÃ³n Final |
| **PrÃ³xima RevisiÃ³n** | Abril 2026 (3 meses) |

</div>

---

# ğŸ“‹ ÃNDICE

## RESUMEN EJECUTIVO
- [Contexto del Proyecto](#contexto-del-proyecto)
- [DecisiÃ³n TecnolÃ³gica Principal](#decisiÃ³n-tecnolÃ³gica-principal)
- [MÃ©tricas Clave de Dimensionamiento](#mÃ©tricas-clave-de-dimensionamiento)
- [TCO Resumido (3 Escenarios)](#tco-resumido-3-escenarios)
- [RecomendaciÃ³n y PrÃ³ximos Pasos](#recomendaciÃ³n-y-prÃ³ximos-pasos)

---

## SECCIÃ“N I: FUNDAMENTOS Y DIMENSIONAMIENTO

- **CapÃ­tulo 1:** [Contexto y Requerimientos](#capÃ­tulo-1-contexto-y-requerimientos)
  - 1.1 DescripciÃ³n del Proyecto
  - 1.2 Fuentes de Datos
  - 1.3 Requerimientos Funcionales
  - 1.4 Requerimientos No Funcionales
  - 1.5 Audiencia del Documento

- **CapÃ­tulo 2:** [Dimensionamiento BASE (Sin Optimizar)](#capÃ­tulo-2-dimensionamiento-base-sin-optimizar)
  - 2.1 MetodologÃ­a de CÃ¡lculo
  - 2.2 Tabla A: Volumen de Datos (Pasos 1-18)
  - 2.3 Tabla B: Memoria y CÃ³mputo (Pasos 19-26)
  - 2.4 Resumen del Escenario Base

- **CapÃ­tulo 3:** [Glosario de Variables](#capÃ­tulo-3-glosario-de-variables)
  - 3.1 Variables de Entrada
  - 3.2 Variables Derivadas
  - 3.3 Tabla de Impacto de Variaciones

---

## SECCIÃ“N II: SELECCIÃ“N DE TECNOLOGÃA

- **CapÃ­tulo 4:** EvaluaciÃ³n de Bases de Datos Vectoriales
  - 4.1 Candidatos Evaluados
  - 4.2 Criterios de EvaluaciÃ³n y Pesos
  - 4.3 Matriz Comparativa
  - 4.4 Score Ponderado Final
  - 4.5 DecisiÃ³n y JustificaciÃ³n

- **CapÃ­tulo 5:** Arquitectura de Referencia
  - 5.1 Diagrama de Arquitectura General
  - 5.2 Componentes del Sistema
  - 5.3 Flujo de Datos

---

## SECCIÃ“N III: TÃ‰CNICAS DE OPTIMIZACIÃ“N

- **CapÃ­tulo 6:** CompresiÃ³n de Embeddings (Matryoshka, halfvec)
  - 6.1 Matryoshka Representation Learning
  - 6.2 halfvec (Float16) en pgvector
  - 6.3 CombinaciÃ³n Ã“ptima
  - 6.4 Impacto en Costos y Calidad

- **CapÃ­tulo 7:** Particionamiento de Datos
  - 7.1 Estrategia por Ãrea/Dominio
  - 7.2 ImplementaciÃ³n SQL
  - 7.3 Beneficios de Performance

- **CapÃ­tulo 8:** Cacheo SemÃ¡ntico
  - 8.1 Arquitectura Multi-Nivel
  - 8.2 ImplementaciÃ³n con Redis
  - 8.3 PolÃ­ticas de Eviction

---

## SECCIÃ“N IV: TÃ‰CNICAS AVANZADAS DE RAG

- **CapÃ­tulo 9:** Estrategias de Chunking
  - 9.1 TÃ©cnicas BÃ¡sicas y Avanzadas
  - 9.2 Matriz de DecisiÃ³n por Tipo de Documento
  - 9.3 Impacto del Overlap en Costos

- **CapÃ­tulo 10:** Modelos de Embedding
  - 10.1 Comparativa de Modelos 2024-2025
  - 10.2 Bi-Encoder vs Cross-Encoder vs Late Interaction
  - 10.3 RecomendaciÃ³n para el Proyecto

- **CapÃ­tulo 11:** TÃ©cnicas de BÃºsqueda
  - 11.1 BÃºsqueda HÃ­brida (Vector + BM25)
  - 11.2 Reranking con Cross-Encoder
  - 11.3 HyDE y Multi-Query
  - 11.4 Pipeline Recomendado

---

## SECCIÃ“N V: ANÃLISIS DE ESCENARIOS Y COSTOS

- **CapÃ­tulo 12:** Escenario Baseline (Sin Optimizar)
  - 12.1 ConfiguraciÃ³n
  - 12.2 Costos Mensuales y Anuales
  - 12.3 Limitaciones

- **CapÃ­tulo 13:** Escenario Optimizado (RECOMENDADO)
  - 13.1 Optimizaciones Aplicadas
  - 13.2 Costos Mensuales y Anuales
  - 13.3 ROI de Optimizaciones

- **CapÃ­tulo 14:** Escenario Ultra-Optimizado (Open Source)
  - 14.1 Stack Open Source
  - 14.2 Costos y Trade-offs

- **CapÃ­tulo 15:** Comparativa y DecisiÃ³n Final
  - 15.1 Tabla Comparativa de TCO a 3 AÃ±os
  - 15.2 Punto de InflexiÃ³n para MigraciÃ³n
  - 15.3 Cronograma de ImplementaciÃ³n

---

## SECCIÃ“N VI: OPERACIONES Y PRODUCCIÃ“N

- **CapÃ­tulo 16:** Framework de EvaluaciÃ³n de Calidad
  - 16.1 MÃ©tricas de Retrieval
  - 16.2 MÃ©tricas de GeneraciÃ³n
  - 16.3 ImplementaciÃ³n con RAGAS
  - 16.4 Dashboard de MÃ©tricas

- **CapÃ­tulo 17:** Estrategia de ActualizaciÃ³n de Datos
  - 17.1 Pipeline de ActualizaciÃ³n (CDC)
  - 17.2 SLAs de Freshness por Ãrea
  - 17.3 Costos de Re-indexaciÃ³n

- **CapÃ­tulo 18:** Alta Disponibilidad y Disaster Recovery
  - 18.1 Arquitectura de HA
  - 18.2 RTO/RPO
  - 18.3 Procedimiento de Failover

- **CapÃ­tulo 19:** Observabilidad y Monitoreo
  - 19.1 Stack de Observabilidad
  - 19.2 MÃ©tricas CrÃ­ticas y Alertas
  - 19.3 Dashboards Recomendados

- **CapÃ­tulo 20:** DegradaciÃ³n Graceful
  - 20.1 Fallback por Componente
  - 20.2 Circuit Breaker Pattern
  - 20.3 Mensajes de Usuario

---

## ANEXOS

- **Anexo A:** [Checklist Pre-ProducciÃ³n](#anexo-a-checklist-pre-producciÃ³n)
- **Anexo B:** [Configuraciones SQL](#anexo-b-configuraciones-sql)
- **Anexo C:** [CÃ³digo de Referencia](#anexo-c-cÃ³digo-de-referencia)
- **Anexo D:** [Referencias y Fuentes](#anexo-d-referencias-y-fuentes)
- **Anexo E:** [Glosario de TÃ©rminos](#anexo-e-glosario-de-tÃ©rminos)

---
---

# RESUMEN EJECUTIVO

## Contexto del Proyecto

El proyecto **Enterprise AI Platform** requiere implementar un sistema RAG (Retrieval-Augmented Generation) empresarial capaz de responder consultas sobre un corpus documental de **17 TB** almacenado actualmente en OpenText.

### La Pregunta Central

> **"Tenemos 17 TB de documentos. Â¿CuÃ¡nta infraestructura necesitamos para que el sistema de IA pueda buscar respuestas en todos ellos de manera instantÃ¡nea?"**

### AnalogÃ­a para Stakeholders No TÃ©cnicos

> ğŸŠ **La AnalogÃ­a de la Biblioteca**
> 
> Imagina que tienes una biblioteca de 17 millones de libros (17 TB). Para que alguien encuentre una respuesta en segundos, no puedes simplemente guardar los libros en estantes. Necesitas:
> 
> 1. **Un catÃ¡logo inteligente** (los "vectores" o embeddings)
> 2. **Un sistema de bÃºsqueda rÃ¡pida** (el Ã­ndice HNSW)
> 3. **Espacio en memoria** para tener el catÃ¡logo "a mano" (RAM)
> 
> Este documento calcula exactamente cuÃ¡nto de cada cosa necesitamos.

---

## DecisiÃ³n TecnolÃ³gica Principal

<div align="center">

| DecisiÃ³n | ElecciÃ³n | JustificaciÃ³n |
|:---------|:---------|:--------------|
| **Motor AÃ±o 1-2** | PostgreSQL + pgvector | Simplicidad, costo, expertise existente |
| **Hosting** | Cloud SQL Enterprise (GCP) | HA nativo, backups automÃ¡ticos, escalabilidad |
| **CuantizaciÃ³n** | halfvec (float16) | 50% ahorro RAM, pÃ©rdida <0.1% recall |
| **Target AÃ±o 2+** | Vertex AI Vector Search | Escalabilidad ilimitada (si se supera 400M vectores) |

</div>

### Razones de la ElecciÃ³n de pgvector

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DECISIÃ“N: PostgreSQL + pgvector                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  âœ… RAZONES PRINCIPALES:                                                     â”‚
â”‚                                                                              â”‚
â”‚  1. COSTO: 60-70% mÃ¡s barato que alternativas managed                       â”‚
â”‚     â€¢ $1,500/mes vs. $4,000/mes (Pinecone)                                  â”‚
â”‚                                                                              â”‚
â”‚  2. EXPERTISE: El equipo ya conoce PostgreSQL                               â”‚
â”‚     â€¢ Menor curva de aprendizaje                                            â”‚
â”‚     â€¢ Debugging familiar                                                     â”‚
â”‚                                                                              â”‚
â”‚  3. FLEXIBILIDAD: Sin vendor lock-in                                        â”‚
â”‚     â€¢ MigraciÃ³n a otra infra es posible                                     â”‚
â”‚     â€¢ Open source, comunidad activa                                         â”‚
â”‚                                                                              â”‚
â”‚  4. FEATURES: Hybrid search nativo                                          â”‚
â”‚     â€¢ Vector + BM25 en una sola query                                       â”‚
â”‚     â€¢ No requiere servicios adicionales                                     â”‚
â”‚                                                                              â”‚
â”‚  5. ESCALA: Suficiente para 244M-500M vectores                              â”‚
â”‚     â€¢ Con optimizaciones cubre el roadmap de 3 aÃ±os                         â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## MÃ©tricas Clave de Dimensionamiento

### Resumen de Recursos Calculados

| Lo que Tenemos | Lo que Necesitamos (Baseline) | Lo que Necesitamos (Optimizado) |
|:---------------|:------------------------------|:--------------------------------|
| 17 TB de documentos en OpenText | **~3.0-5.0 TB** de disco SSD | **~1.0 TB** de disco SSD |
| â€” | **~240-300 GB** de RAM | **~90 GB** de RAM |
| â€” | **~244 M vectores** | **~244 M vectores** |
| â€” | ~$3,200/mes | **~$1,500/mes** |

### Proceso de TransformaciÃ³n

```
ğŸ“ 17 TB de archivos en OpenText
     â†“ (extracciÃ³n: 10% es texto)
ğŸ“ 1.7 TB de texto bruto
     â†“ (limpieza: 30% es redundante)
ğŸ“„ 1.19 TB de texto Ãºtil
     â†“ (fragmentaciÃ³n en chunks de 4KB + 15% overlap)
ğŸ”¢ 244 millones de vectores
     â†“ (almacenamiento + Ã­ndice HNSW + overhead 30%)
ğŸ’¾ ~3-5 TB de disco SSD + ~240-300 GB RAM (sin optimizar)
     â†“ (con Matryoshka 768d + halfvec)
ğŸ’¾ ~1.0 TB de disco SSD + ~90 GB RAM (optimizado)
     â†“ (traducido a Cloud SQL Enterprise)
ğŸ’° ~$1,500 - $3,200 / mes (segÃºn nivel de optimizaciÃ³n)
```

---


## TCO Resumido (3 Escenarios)

> ğŸ’¡ **Â¿QuÃ© es TCO?**
> 
> **TCO (Total Cost of Ownership)** o "Costo Total de Propiedad" es la suma de **todos los costos de infraestructura** asociados a un sistema durante su vida Ãºtil. Incluye implementaciÃ³n inicial, operaciÃ³n mensual y actualizaciones.

### Componentes del Costo

Para entender la tabla, es importante conocer quÃ© incluye cada columna:

| Componente | QuÃ© Incluye | CuÃ¡ndo se Paga |
|:-----------|:------------|:---------------|
| **IngestiÃ³n (AÃ±o 0)** | Generar embeddings de los 244M chunks, procesamiento OCR/parsing, carga inicial a Cloud SQL | Una sola vez al inicio |
| **OperaciÃ³n Mensual** | Cloud SQL, APIs de IA (embeddings, LLM), Redis cache, Cloud Run, networking, monitoreo | Cada mes mientras el sistema estÃ© activo |
| **TCO 3 AÃ±os** | IngestiÃ³n + (OperaciÃ³n Mensual Ã— 36 meses) | Acumulado en 3 aÃ±os |

> âš ï¸ **Nota:** Estos costos son **solo infraestructura**. No incluyen horas de desarrollo del equipo interno.

### Tabla Comparativa de Costos

| Escenario | IngestiÃ³n (AÃ±o 0) | OperaciÃ³n Mensual | TCO 3 AÃ±os | Viabilidad |
|:----------|:-----------------:|:-----------------:|:----------:|:----------:|
| **A: Baseline (Sin Optimizar)** | ~$5,500 | ~$8,050 | **~$295,300** | âš ï¸ Costoso |
| **B: Optimizado (RECOMENDADO)** | ~$5,500 | ~$3,600 | **~$135,100** | âœ… Viable |
| **C: Ultra-Optimizado (OSS)** | ~$1,000 | ~$2,850 | **~$103,600** | âœ… Viable (requiere expertise GPU) |

> ğŸ“Š **InterpretaciÃ³n rÃ¡pida:**
> - El **Escenario A** tiene el mismo costo de ingestiÃ³n pero paga ~$8K/mes por infraestructura sobredimensionada.
> - El **Escenario B** optimiza la infraestructura con halfvec y cache, reduciendo 55% el costo mensual.
> - El **Escenario C** usa embeddings open source (BGE-M3), eliminando el costo de APIs de embedding.

### Desglose del Costo de IngestiÃ³n

| Componente | Escenarios A/B | Escenario C |
|:-----------|:--------------:|:-----------:|
| Embeddings (244M chunks) | ~$4,900 (Gemini API) | ~$350 (BGE-M3 en GPU spot) |
| Procesamiento OCR/Parsing | ~$300 | ~$300 |
| Carga inicial Cloud SQL | ~$200 | ~$200 |
| ConstrucciÃ³n Ã­ndices HNSW | ~$100 | ~$100 |
| **TOTAL** | **~$5,500** | **~$950** |

### VisualizaciÃ³n de TCO Acumulado

```
Costo Acumulado (miles USD)
     â”‚
300k â”¤                                          â•±â”€â”€â”€ Escenario A ($295k) 
     â”‚                                        â•±
250k â”¤                                      â•±
     â”‚                                    â•±
200k â”¤                                  â•±
     â”‚                                â•±
150k â”¤                              â•±
     â”‚                            â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Escenario B ($135k) â­ RECOMENDADO
100k â”¤                          â•±
     â”‚                        â•±â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Escenario C ($104k)
 50k â”¤                      â•±
     â”‚                    â•±
   0 â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Tiempo
        AÃ±o 0          AÃ±o 1          AÃ±o 2          AÃ±o 3
```


---

## RecomendaciÃ³n y PrÃ³ximos Pasos

### Estrategia Recomendada: Escenario B (Optimizado)

| Ventaja | ExplicaciÃ³n |
|:--------|:------------|
| **Menor riesgo MVP** | Usamos tecnologÃ­a conocida (PostgreSQL) para validar el producto |
| **Menor costo inicial** | Ahorramos ~$90,000 vs. Baseline en el primer aÃ±o |
| **MigraciÃ³n planificada** | Tenemos tiempo de preparar el equipo y procesos |
| **Ahorro total 3 aÃ±os** | ~$250,000 menos que el escenario Baseline |

### Cronograma de Alto Nivel

```
2026
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ENE  FEB  MAR  ABR  MAY  JUN  JUL  AGO  SEP  OCT  NOV  DIC
 â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â”‚    â”‚
 â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜
 â”‚â”€ Sem 1-4: IngestiÃ³n Inicial â”€â”€â”€â”‚
                                   â”‚â”€â”€â”€ Sem 5-8: Optimizaciones â”€â”€â”€â”‚
                                                              â”‚â”€â”€ PoC Vertex AI â”€â”€â–º

2027
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ENE  FEB  MAR  ABR  MAY  JUN
 â”‚    â”‚    â”‚    â”‚    â”‚    â”‚
 â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜
 â”‚â”€â”€ EvaluaciÃ³n (si >300M vectores) â”€â”€â”‚
                                       â”‚â”€â”€ MigraciÃ³n Gradual (si aplica) â”€â”€â–º
```

### PrÃ³ximos Pasos Inmediatos

1. **Semana 1-2:** Validar $f_{text}$ y $r_{clean}$ con muestra de 500 documentos
   - *Procesar una muestra representativa para confirmar que el 10% de los archivos es texto extraÃ­ble y el 30% son duplicados. Ajustar las variables si los valores reales difieren.*

2. **Semana 3-4:** Provisionar Cloud SQL Enterprise y configurar networking
   - *Crear la instancia de base de datos con pgvector, configurar VPC, Private IP, y probar conectividad desde los servicios de aplicaciÃ³n.*

3. **Semana 5-8:** Implementar pipeline de ingestiÃ³n con Matryoshka + halfvec
   - *Desarrollar el flujo completo: extracciÃ³n de texto â†’ chunking â†’ generaciÃ³n de embeddings (768d truncados) â†’ carga en Cloud SQL con tipo halfvec.*

4. **Semana 9-10:** Configurar monitoreo y alertas
   - *Implementar dashboards en Cloud Monitoring, configurar alertas para mÃ©tricas crÃ­ticas (latencia, errores, uso de recursos) y conectar con PagerDuty/Slack.*

5. **Semana 11-12:** Testing de calidad con golden set y ajustes
   - *Evaluar el sistema con un conjunto de ~100 queries anotadas por expertos, medir Recall@10 y Faithfulness, y ajustar parÃ¡metros (ef_search, weights de RRF) segÃºn resultados.*

---
---

# SECCIÃ“N I: FUNDAMENTOS Y DIMENSIONAMIENTO

---

## CapÃ­tulo 1: Contexto y Requerimientos

### 1.1 DescripciÃ³n del Proyecto

**Enterprise AI Platform** es una plataforma de inteligencia artificial empresarial diseÃ±ada para permitir a los usuarios internos de la organizaciÃ³n realizar consultas en lenguaje natural sobre el corpus documental corporativo completo.

El sistema implementa una arquitectura **RAG (Retrieval-Augmented Generation)** que:
1. Recibe una pregunta del usuario en lenguaje natural
2. Busca los fragmentos de documentos mÃ¡s relevantes (retrieval)
3. Genera una respuesta utilizando un LLM con el contexto recuperado (generation)
4. Cita las fuentes utilizadas para la respuesta

### 1.2 Fuentes de Datos

| Fuente | Volumen | Tipo de Contenido | Frecuencia de ActualizaciÃ³n |
|:-------|:-------:|:------------------|:----------------------------|
| **OpenText** | ~17 TB | Documentos corporativos mixtos | Diaria |
| **SharePoint** | ~500 GB | Presentaciones, manuales | Semanal |
| **Confluence** | ~200 GB | KB tÃ©cnica | Diaria |
| **Email Archives** | ~2 TB | Correspondencia histÃ³rica | Batch mensual |

**CaracterÃ­sticas del Corpus:**
- **Idiomas:** EspaÃ±ol (90%), InglÃ©s (10%)
- **Formatos:** PDF (60%), Office (30%), Texto plano (10%)
- **AntigÃ¼edad:** 1-15 aÃ±os
- **Tenants:** Multi-tenant con aislamiento por Ã¡rea funcional

### 1.3 Requerimientos Funcionales

| ID | Requerimiento | Prioridad |
|:---|:--------------|:---------:|
| RF-01 | BÃºsqueda semÃ¡ntica en todo el corpus | Alta |
| RF-02 | Filtrado por Ã¡rea funcional (RRHH, Legal, etc.) | Alta |
| RF-03 | Control de acceso basado en permisos | Alta |
| RF-04 | CitaciÃ³n de fuentes en respuestas | Media |
| RF-05 | BÃºsqueda hÃ­brida (semÃ¡ntica + keywords) | Media |
| RF-06 | Soporte multilingÃ¼e (espaÃ±ol/inglÃ©s) | Media |

### 1.4 Requerimientos No Funcionales

| MÃ©trica | Target | JustificaciÃ³n |
|:--------|:------:|:--------------|
| **Latencia bÃºsqueda P95** | < 50 ms | Para mantener latencia total E2E < 3 seg |
| **Latencia E2E P95** | < 3 seg | Experiencia de usuario aceptable |
| **QPS** | 30 queries/seg | Pico estimado de uso concurrente |
| **Disponibilidad** | 99.9% | SLA empresarial estÃ¡ndar |
| **Downtime anual mÃ¡ximo** | < 8.76 horas | Derivado del 99.9% |
| **Recall@10** | > 90% | Calidad mÃ­nima de retrieval |
| **RPO** | < 5 min | MÃ¡xima pÃ©rdida de datos aceptable |
| **RTO** | < 60 seg | Tiempo mÃ¡ximo de recuperaciÃ³n |

### 1.5 Audiencia del Documento

| Audiencia | Secciones Relevantes | Nivel de Detalle |
|:----------|:--------------------|:-----------------|
| **Arquitectos de Soluciones** | Todas | Completo |
| **Ingenieros ML/AI** | I, III, IV | TÃ©cnico profundo |
| **DevOps/SRE** | I, II, VI | Operativo |
| **Stakeholders Ejecutivos** | Resumen Ejecutivo, V | Alto nivel |
| **Equipo de Finanzas** | Resumen Ejecutivo, V | Costos y TCO |

---

## CapÃ­tulo 2: Dimensionamiento BASE (Sin Optimizar)

Este capÃ­tulo presenta el dimensionamiento **baseline** asumiendo que no se aplican optimizaciones (ni Matryoshka, ni halfvec, ni compresiÃ³n). Representa el **escenario conservador** y el punto de partida para medir el impacto de las optimizaciones.

### 2.1 MetodologÃ­a de CÃ¡lculo

El dimensionamiento sigue una metodologÃ­a de **26 pasos** organizados en dos tablas:

- **Tabla A (Pasos 1-18):** TransformaciÃ³n de documentos brutos a requerimientos de almacenamiento
- **Tabla B (Pasos 19-26):** CÃ¡lculo de memoria RAM y cÃ³mputo necesarios

Cada paso incluye:
- âœ… **Valor calculado** en unidades amigables
- ğŸ“Š **Rango tÃ­pico** de la industria con fuentes
- ğŸ“ **Origen** de cada valor (input, fÃ³rmula, constante)
- ğŸ”— **Dependencias** entre pasos

### 2.2 Tabla A: Volumen de Datos (Pasos 1-18)

> ğŸ’¡ **Para no tÃ©cnicos:** Esta tabla muestra cÃ³mo 17 TB de documentos se transforman en ~3.0 TB de base de datos.

#### Fase 1: ExtracciÃ³n de Texto (Pasos 1-5)

| # | Variable | FÃ³rmula | Valor | DescripciÃ³n |
|:-:|:---------|:--------|:-----:|:------------|
| 1 | $S_{raw}$ | *input* | **17 TB** | Documentos brutos en OpenText |
| 2 | $f_{text}$ | *input* | 0.10 | ProporciÃ³n de texto extraÃ­ble. **Rango: 5-20%** |
| 3 | $S_{text}$ | $S_{raw} \times f_{text}$ | 1.7 TB | Texto crudo extraÃ­do |
| 4 | $r_{clean}$ | *input* | 0.30 | Texto descartado por duplicados. **Rango: 20-50%** |
| 5 | $S_{clean}$ | $S_{text} \times (1 - r_{clean})$ | **1.19 TB** | â­ Texto limpio para vectorizar |

> ğŸ“Š **Resumen Fase 1:** De 17 TB de archivos, solo **1.19 TB es texto Ãºtil**. El resto son imÃ¡genes, formatos y duplicados.

#### Fase 2: Chunking y Embeddings (Pasos 6-9)

| # | Variable | FÃ³rmula | Valor | DescripciÃ³n |
|:-:|:---------|:--------|:-----:|:------------|
| 6 | $C_{chunk}$ | *input* | **4 KB** | TamaÃ±o de cada fragmento (~1000 tokens). **Rango: 1-8 KB** |
| 7 | $f_{overlap}$ | *input* | **1.15** | Factor de solapamiento (15%). **Rango: 1.0-1.5** |
| 8 | $N$ | $(S_{clean} \times f_{overlap}) / C_{chunk}$ | **~244 M** | â­ **Cantidad total de vectores** |
| 9 | $d$ | *input* | **1024** | DimensiÃ³n del embedding. **Rango: 768-1536** |

> ğŸ“Š **Resumen Fase 2:** Tendremos **~244 millones de vectores**. Este nÃºmero determina todo: almacenamiento, RAM y costos.

#### Fase 3: Almacenamiento por Vector (Pasos 10-14)

| # | Variable | FÃ³rmula | Valor | DescripciÃ³n |
|:-:|:---------|:--------|:-----:|:------------|
| 10 | $B_{vec}$ | $(4 \times d) + 8$ | **4,104 B** | Bytes por vector (pgvector float32) |
| 11 | $S_{meta}$ | *input* | **200 GB** | Metadata del corpus (IDs, rutas, permisos) |
| 12 | $B_{meta}$ | $S_{meta} / N$ | **~820 B** | Metadata promedio por fila |
| 13 | $B_{overhead}$ | *constante* | **32 B** | Overhead de PostgreSQL por fila |
| 14 | $B_{row}$ | $B_{vec} + B_{meta} + B_{overhead}$ | **~4,956 B** | â­ Bytes totales por fila (~4.8 KB) |

#### Fase 4: Almacenamiento Total en Disco (Pasos 15-18)

| # | Variable | FÃ³rmula | Valor | DescripciÃ³n |
|:-:|:---------|:--------|:-----:|:------------|
| 15 | $S_{table}$ | $N \times B_{row}$ | **~1.1 TB** | Tabla de vectores sin Ã­ndices |
| 16 | $S_{index}$ | $N \times (4d + M \times 8)$ | **~1.2 TB** | Ãndice HNSW (M=16) |
| 17 | $f_{over}$ | *input* | **0.30** | Margen para WAL, vacuum. **Rango: 10-30%** |
| 18 | $S_{total}$ | $(S_{table} + S_{index}) \times (1 + f_{over})$ | **~3.0 TB** | â­ **Disco total (sin TOAST texto)** |

> ğŸ“Š **Resumen Fase 3-4:** Sin texto original: **~3.0 TB**. Con TOAST de texto adicional: **~4.5-5.0 TB total**.

### 2.3 Tabla B: Memoria y CÃ³mputo (Pasos 19-26)

> ğŸ’¡ **Para no tÃ©cnicos:** Esta tabla calcula cuÃ¡nta RAM y CPU necesita el servidor.

#### Fase 5: Dimensionamiento de Memoria RAM (Pasos 19-24)

| # | Variable | FÃ³rmula | Valor | DescripciÃ³n |
|:-:|:---------|:--------|:-----:|:------------|
| 19 | $N_{batch}$ | *valor ancla* | **5 M** | Vectores por lote al indexar. **Rango: 1-10M** |
| 20 | $RAM_{min}$ | $RAM_{base} + (N_{batch} \times 4 \times d)$ | **~52 GB** | RAM mÃ­nima para construcciÃ³n de Ã­ndices |
| 21 | $p_{hot}$ | *input* | **0.20** | FracciÃ³n del Ã­ndice en RAM. **Rango: 5-30%** |
| 22 | $RAM_{phot}$ | $p_{hot} \times S_{index}$ | **~240 GB** | RAM para mantener Ã­ndice caliente |
| 23 | $RAM_{ideal}$ | $\max(RAM_{min}, RAM_{phot})$ | **~240 GB** | â­ **RAM recomendada** |
| 24 | $RAM_{buffers}$ | $0.25 \times RAM_{ideal}$ | **~60 GB** | ConfiguraciÃ³n shared_buffers |

#### Fase 6: Capacidad de CÃ³mputo (Pasos 25-26)

| # | Variable | FÃ³rmula | Valor | DescripciÃ³n |
|:-:|:---------|:--------|:-----:|:------------|
| 25 | $cpu_{ms}$ | *estimado* | **~20 ms** | Tiempo CPU por consulta (Ã­ndice caliente) |
| 26 | $vCPU$ | $(QPS \times cpu_{ms}) / 1000 \times 1.5$ | **~2** | vCPUs para queries vectoriales |

### 2.4 Resumen del Escenario Base

#### Tabla Consolidada de Recursos

| Recurso | Valor Calculado | Con TOAST texto | Cloud SQL Tier |
|:--------|:---------------:|:---------------:|:---------------|
| **Vectores totales** | **~244 M** | â€” | â€” |
| **Disco SSD** | **~3.0 TB** | **~4.5-5.0 TB** | 5 TB SSD |
| **RAM** | **~240-300 GB** | â€” | db-custom-48-307200 |
| **vCPU** | **~2 dedicadas** | â€” | Incluido en tier |
| **Costo estimado** | **~$3,000-3,500/mes** | â€” | Cloud SQL Enterprise |

#### Diagrama: ComposiciÃ³n del Espacio por Fila

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    POR CADA VECTOR (1 fila â‰ˆ 4,956 B)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ VECTOR (embedding float32)               4,104 B â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â”‚  82.8%
â”‚  â”‚ RepresentaciÃ³n matemÃ¡tica del texto               â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ METADATA                                   820 B â”‚ â–ˆ        â”‚  16.5%
â”‚  â”‚ doc_id, chunk_id, tenant_id, rutas, permisos      â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ OVERHEAD PostgreSQL                         32 B â”‚          â”‚  0.6%
â”‚  â”‚ Headers, punteros, alineaciÃ³n de fila             â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  NOTA: El texto original del chunk (~4 KB) se almacena          â”‚
â”‚  en TOAST separadamente y aÃ±ade ~1.0-1.5 TB adicionales.        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> âš ï¸ **Importante:** Este es el escenario **sin optimizaciones**. En los capÃ­tulos posteriores se mostrarÃ¡ cÃ³mo reducir estos valores en un 60-70% mediante tÃ©cnicas de compresiÃ³n y optimizaciÃ³n.

---

## CapÃ­tulo 3: Glosario de Variables

### 3.1 Variables de Entrada

Estas son las variables que el equipo debe definir o medir. Modificar estos valores impacta directamente en el dimensionamiento final.

---

#### ğŸ“¦ $C_{chunk}$ - TamaÃ±o del Chunk (Fragmento)

> **Â¿QuÃ© es?** El tamaÃ±o en bytes de cada fragmento de texto que se convertirÃ¡ en un vector.

| Aspecto | DescripciÃ³n |
|:--------|:------------|
| **Origen** | DecisiÃ³n de diseÃ±o RAG. Depende del modelo de embeddings y la naturaleza del contenido. |
| **Rango tÃ­pico** | 512 bytes - 8 KB (equivale a ~100-2000 tokens) |
| **Valor recomendado** | **4 KB** (~1000 tokens) para documentos tÃ©cnicos |

| Si $C_{chunk}$ es... | Impacto | Trade-off |
|:---------------------|:--------|:----------|
| **Muy pequeÃ±o** (512 B) | MÃ¡s vectores, mejor precisiÃ³n de bÃºsqueda | Mayor costo (mÃ¡s almacenamiento, RAM) |
| **Muy grande** (8 KB) | Menos vectores, menor costo | Menor precisiÃ³n (respuestas menos focalizadas) |

> ğŸ’¡ **Regla:** Chunks pequeÃ±os = mÃ¡s caro pero mÃ¡s preciso. Chunks grandes = mÃ¡s barato pero menos preciso.

---

#### ğŸ”„ $f_{overlap}$ - Factor de Solapamiento

> **Â¿QuÃ© es?** CuÃ¡nto texto se repite entre fragmentos consecutivos para evitar "cortar" ideas a la mitad.

| Aspecto | DescripciÃ³n |
|:--------|:------------|
| **Origen** | TÃ©cnica estÃ¡ndar en RAG para preservar contexto entre chunks. |
| **Rango tÃ­pico** | 1.0 (sin overlap) a 1.5 (50% overlap) |
| **Valor recomendado** | **1.15** (15% de solapamiento) |

| Si $f_{overlap}$ es... | Impacto | Trade-off |
|:-----------------------|:--------|:----------|
| **1.0** (sin overlap) | MÃ­nimo costo, pero riesgo de perder contexto | Respuestas pueden quedar "cortadas" |
| **1.15-1.25** (15-25%) | Balance Ã³ptimo calidad/costo | Recomendado para la mayorÃ­a de casos |
| **1.50** (50% overlap) | MÃ¡xima calidad, pero 50% mÃ¡s vectores | Solo para documentos muy tÃ©cnicos/legales |

> ğŸ’¡ **Regla:** Cada 10% de overlap aÃ±ade ~10% mÃ¡s vectores y por tanto ~10% mÃ¡s costo.

---

#### ğŸ“ $d$ - DimensiÃ³n del Embedding

> **Â¿QuÃ© es?** La cantidad de nÃºmeros (coordenadas) que representan el significado semÃ¡ntico de cada fragmento.

| Aspecto | DescripciÃ³n |
|:--------|:------------|
| **Origen** | Definido por el modelo de embeddings elegido (NO es configurable por el usuario). |
| **Valores comunes** | 384, 512, 768, 1024, 1536, 3072 |
| **Nuestro valor base** | **1024** (para modelos como Vertex AI gecko) |
| **Valor optimizado** | **768** (con Matryoshka truncation) |

| Modelo | DimensiÃ³n $d$ | TamaÃ±o por vector |
|:-------|:-------------:|:-----------------:|
| Sentence-BERT | 384 | 1.5 KB |
| **Gemini text-embedding-004** | **768-3072** | **3-12 KB** |
| OpenAI text-embedding-3-small | 1536 | 6 KB |
| OpenAI text-embedding-3-large | 3072 | 12 KB |
| Cohere embed-v3 | 1024 | 4 KB |

> ğŸ’¡ **Regla:** Elegir $d$ es elegir el modelo de embeddings. No se puede cambiar despuÃ©s sin re-vectorizar todo el corpus.

---

#### ğŸ“ˆ $f_{text}$ - FracciÃ³n de Texto ExtraÃ­ble

> **Â¿QuÃ© es?** QuÃ© proporciÃ³n del tamaÃ±o de los archivos originales es realmente texto (vs. imÃ¡genes, formato, binarios).

| Aspecto | DescripciÃ³n |
|:--------|:------------|
| **Origen** | MediciÃ³n empÃ­rica sobre muestra de documentos. |
| **Rango tÃ­pico** | 5% - 20% |
| **Valor usado** | **10%** (asunciÃ³n conservadora) |

| Tipo de documento | $f_{text}$ tÃ­pico |
|:------------------|:-----------------:|
| PDFs escaneados (imÃ¡genes) | 2-5% |
| PDFs con texto seleccionable | 10-15% |
| Documentos Word/Excel | 15-30% |
| Archivos de texto plano | 90-100% |

> âš ï¸ **CRÃTICO:** Este valor puede **duplicar o reducir a la mitad** el dimensionamiento. **Validar con muestra real de 500+ documentos antes del despliegue.**

---

#### ğŸ§¹ $r_{clean}$ - Ratio de Limpieza

> **Â¿QuÃ© es?** QuÃ© proporciÃ³n del texto extraÃ­do se descarta por ser duplicados, headers repetidos, o contenido no Ãºtil.

| Aspecto | DescripciÃ³n |
|:--------|:------------|
| **Origen** | MediciÃ³n empÃ­rica durante proceso de limpieza. |
| **Rango tÃ­pico** | 20% - 50% |
| **Valor usado** | **30%** (asunciÃ³n moderada) |

| Si $r_{clean}$ es... | Significa... |
|:---------------------|:-------------|
| **20%** (pocos duplicados) | Corpus muy limpio, mÃ¡s vectores resultantes |
| **30%** (moderado) | SituaciÃ³n tÃ­pica en corporativos |
| **50%** (muchos duplicados) | Documentos con mucha redundancia, menos vectores |

---

### 3.2 Variables Derivadas

Estas variables se calculan a partir de las variables de entrada y constantes del sistema.

---

#### ğŸ’¾ $B_{vec}$ - Bytes por Vector

> **Â¿QuÃ© es?** El espacio en disco que ocupa cada vector en pgvector.

| Aspecto | DescripciÃ³n |
|:--------|:------------|
| **FÃ³rmula** | $(4 \times d) + 8$ bytes |
| **Componentes** | 4 bytes por dimensiÃ³n (float32) + 8 bytes de header |
| **Valor base (d=1024)** | $(4 \times 1024) + 8 = $ **4,104 bytes** |
| **Valor optimizado (d=768, halfvec)** | $(2 \times 768) + 8 = $ **1,544 bytes** |

> ğŸ“š **Fuente:** [pgvector docs](https://github.com/pgvector/pgvector)

---

#### ğŸ·ï¸ $B_{meta}$ - Bytes de Metadata por Fila

> **Â¿QuÃ© es?** InformaciÃ³n adicional que guardamos junto a cada vector.

| Metadata incluida | TamaÃ±o aproximado |
|:------------------|:-----------------:|
| Solo IDs (doc_id, chunk_id) | ~50-100 bytes |
| + Ruta del documento | +200-500 bytes |
| + Permisos, tenant_id | +50-100 bytes |
| + Timestamps, scores | +50-100 bytes |
| **Total tÃ­pico** | **200-800 bytes** |

---

#### ğŸ—„ï¸ $S_{table}$ y $S_{index}$ - Almacenamiento

| Variable | FÃ³rmula | Significado |
|:---------|:--------|:------------|
| **$S_{table}$** | $N \times B_{row}$ | Espacio de la tabla de datos |
| **$S_{index}$** | $N \times (4d + M \times 8)$ | Espacio del Ã­ndice HNSW |

> ğŸ’¡ **Â¿Por quÃ© el Ã­ndice es casi tan grande como la tabla?**
> 
> El Ã­ndice HNSW guarda:
> - Una copia de los vectores para calcular distancias
> - M conexiones por cada nivel del grafo (tÃ­picamente M=16)
> - InformaciÃ³n de niveles jerÃ¡rquicos
>
> **Resultado:** $S_{index} \approx S_{table}$ (a veces incluso mÃ¡s grande)

---

### 3.3 Tabla de Impacto de Variaciones

Esta tabla muestra cÃ³mo cambios en las variables de entrada afectan el dimensionamiento:

| Variable | Cambio | Impacto en $N$ (vectores) | Impacto en Costo |
|:---------|:-------|:-------------------------:|:----------------:|
| $f_{text}$ = 5% (menos texto) | -50% | **-50%** | Ahorro ~$1,500/mes |
| $f_{text}$ = 20% (mÃ¡s texto) | +100% | **+100%** | Aumento ~$3,000/mes |
| $r_{clean}$ = 20% (pocos duplicados) | +14% | **+14%** | Aumento ~$450/mes |
| $r_{clean}$ = 50% (muchos duplicados) | -29% | **-29%** | Ahorro ~$900/mes |
| $C_{chunk}$ = 2 KB (chunks pequeÃ±os) | +100% | **+100%** | Aumento ~$3,000/mes |
| $C_{chunk}$ = 8 KB (chunks grandes) | -50% | **-50%** | Ahorro ~$1,500/mes |
| $f_{overlap}$ = 0% (sin overlap) | -13% | **-13%** | Ahorro ~$400/mes |
| $f_{overlap}$ = 25% (overlap alto) | +9% | **+9%** | Aumento ~$270/mes |
| $d$ = 768 (Matryoshka) | 0% vectores | **-25% disco/RAM** | Ahorro ~$800/mes |
| halfvec (float16) | 0% vectores | **-50% disco/RAM** | Ahorro ~$1,000/mes |
| **Combinado (768 + halfvec)** | 0% vectores | **-62% disco/RAM** | **Ahorro ~$1,700/mes** |

> ğŸ’¡ **Insight Clave:** Las optimizaciones de compresiÃ³n (Matryoshka + halfvec) tienen el **mayor ROI** porque reducen recursos sin reducir el nÃºmero de vectores ni la calidad de retrieval significativamente.

---

#### Mapa de Dependencias de Variables

```
                              INPUTS
                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                       â”‚                       â”‚
        â–¼                       â–¼                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”
    â”‚S_raw  â”‚â”€â”€â”€â”€â”€â”€â”       â”‚C_chunkâ”‚              â”‚  d    â”‚
    â”‚(17 TB)â”‚      â”‚       â”‚(4 KB) â”‚              â”‚(1024) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚       â””â”€â”€â”€â”¬â”€â”€â”€â”˜              â””â”€â”€â”€â”¬â”€â”€â”€â”˜
        â”‚          â”‚           â”‚                      â”‚
        â–¼          â”‚           â”‚                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”      â”‚           â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚f_text â”‚      â”‚           â”‚               â”‚  B_vec   â”‚
    â”‚(0.10) â”‚      â”‚           â”‚               â”‚(4,104 B) â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜      â”‚           â”‚               â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
        â”‚          â”‚           â”‚                    â”‚
        â–¼          â”‚           â”‚                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”      â”‚           â”‚                    â”‚
    â”‚S_text â”‚â—„â”€â”€â”€â”€â”€â”˜           â”‚                    â”‚
    â”‚(1.7TB)â”‚                  â”‚                    â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜                  â”‚                    â”‚
        â”‚                      â”‚                    â”‚
        â–¼                      â”‚                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”                  â”‚                    â”‚
    â”‚r_cleanâ”‚                  â”‚                    â”‚
    â”‚(0.30) â”‚                  â”‚                    â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜                  â”‚                    â”‚
        â”‚                      â”‚                    â”‚
        â–¼                      â”‚                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”       â”‚                    â”‚
    â”‚S_cleanâ”‚  â”‚f_over â”‚       â”‚                    â”‚
    â”‚(1.19TBâ”‚  â”‚(1.15) â”‚       â”‚                    â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”˜       â”‚                    â”‚
        â”‚          â”‚           â”‚                    â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜           â”‚                    â”‚
             â”‚                 â”‚                    â”‚
             â–¼                 â”‚                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚                    â”‚
        â”‚    N    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
        â”‚(244 M)  â”‚                                 â”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                 â”‚
             â”‚                                      â”‚
             â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
             â”œâ”€â”€â”€â–ºâ”‚ S_table  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
             â”‚    â”‚ (1.1 TB) â”‚                      â”‚
             â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
             â”‚                                      â”‚
             â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
             â””â”€â”€â”€â–ºâ”‚ S_index  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚ (1.2 TB) â”‚
                  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ S_total  â”‚
                  â”‚ (3.0 TB) â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---
---

# SECCIÃ“N II: SELECCIÃ“N DE TECNOLOGÃA

---

## CapÃ­tulo 4: EvaluaciÃ³n de Bases de Datos Vectoriales

### 4.1 Candidatos Evaluados

Se evaluaron las siguientes bases de datos vectoriales, considerando tanto soluciones managed como self-hosted:

| SoluciÃ³n | Tipo | DescripciÃ³n |
|:---------|:-----|:------------|
| **pgvector** | ExtensiÃ³n PostgreSQL | ExtensiÃ³n open source para PostgreSQL. Soporta HNSW e IVFFlat. |
| **Pinecone** | Serverless Managed | Base de datos vectorial fully-managed. LÃ­der de mercado. |
| **Weaviate** | Open Source / Cloud | BD vectorial con GraphQL. Excelente para bÃºsqueda hÃ­brida. |
| **Vertex AI Vector Search** | GCP Managed | Servicio de Google Cloud optimizado para escala masiva. |
| **Qdrant** | Open Source / Cloud | BD vectorial en Rust. Alto rendimiento y eficiencia. |
| **Milvus** | Open Source | BD vectorial distribuida. Muy escalable pero compleja. |
| **Chroma** | Open Source | Ligera, ideal para desarrollo. No apta para producciÃ³n a escala. |

### 4.2 Criterios de EvaluaciÃ³n y Pesos

Los criterios fueron definidos segÃºn las prioridades del proyecto y las restricciones organizacionales:

| Criterio | Peso | JustificaciÃ³n |
|:---------|:----:|:--------------|
| **Costo Total** | 25% | Presupuesto limitado, necesidad de TCO bajo |
| **Rendimiento** | 20% | Latencia <50ms es un requisito no funcional crÃ­tico |
| **Escalabilidad** | 15% | Crecimiento proyectado a 2x en 3 aÃ±os |
| **Expertise del equipo** | 15% | El equipo ya tiene experiencia con PostgreSQL |
| **Vendor lock-in** | 10% | Preferencia organizacional por flexibilidad |
| **Features** | 10% | BÃºsqueda hÃ­brida (vector + BM25) es crÃ­tica |
| **Soporte y comunidad** | 5% | Enterprise support disponible para las opciones evaluadas |

### 4.3 Benchmarks Comparativos

Los siguientes datos provienen de benchmarks de la industria y documentaciÃ³n oficial de cada proveedor.

#### Latencia de BÃºsqueda (ms) - Top-K = 10, d = 1024

> **ğŸ’¡ Para no tÃ©cnicos:** Esta tabla muestra cuÃ¡ntos milisegundos tarda cada sistema en encontrar los 10 documentos mÃ¡s relevantes. Menos es mejor.

| Base de Datos | 1M vectores | 10M vectores | 100M vectores | 500M+ vectores |
|:--------------|:-----------:|:------------:|:-------------:|:--------------:|
| **Vertex AI Vector Search** | 2-5 ms | 3-8 ms | 5-10 ms | 8-15 ms |
| **Pinecone** | 3-8 ms | 5-10 ms | 8-15 ms | 10-20 ms |
| **Qdrant** | 5-10 ms | 10-20 ms | 20-40 ms | 50-100 ms |
| **Milvus** | 5-15 ms | 10-25 ms | 25-50 ms | 50-100 ms |
| **Weaviate** | 8-15 ms | 15-30 ms | 30-60 ms | 80-150 ms |
| **pgvector (HNSW)** | 10-25 ms | 25-50 ms | 50-100 ms | âŒ **Degradado** |
| **Chroma** | 15-30 ms | 50-100 ms | âŒ N/A | âŒ N/A |

> **ğŸ’¡ Por quÃ© Vertex AI y Pinecone son mÃ¡s rÃ¡pidos:**
> - Ãndices distribuidos nativamente (sharding automÃ¡tico)
> - OptimizaciÃ³n a nivel de hardware (TPUs/GPUs para ANN)
> - Algoritmos propietarios optimizados para escala

#### Throughput (QPS) - Con 1 rÃ©plica estÃ¡ndar

> **ğŸ’¡ Para no tÃ©cnicos:** CuÃ¡ntas preguntas puede responder el sistema por segundo. MÃ¡s es mejor.

| Base de Datos | 1M vectores | 10M vectores | 100M vectores | Notas |
|:--------------|:-----------:|:------------:|:-------------:|:------|
| **Vertex AI Vector Search** | 5,000+ | 3,000+ | 1,500+ | Auto-escalado incluido |
| **Pinecone** | 4,000+ | 2,500+ | 1,000+ | Pods serverless |
| **Milvus** | 3,000+ | 2,000+ | 800+ | Requiere tuning |
| **Qdrant** | 2,500+ | 1,500+ | 500+ | Rust, muy eficiente |
| **Weaviate** | 2,000+ | 1,000+ | 400+ | Go, bÃºsqueda hÃ­brida |
| **pgvector** | 500-1,000 | 200-400 | 50-100 | Limitado por PostgreSQL |
| **Chroma** | 100-300 | N/A | N/A | Solo desarrollo |

> **âš ï¸ Insight:** pgvector tiene **5-10x menos throughput** que soluciones especializadas porque PostgreSQL no fue diseÃ±ado para operaciones vectoriales masivas. Sin embargo, nuestro requisito de 30 QPS estÃ¡ muy por debajo de este lÃ­mite.

#### RAM por MillÃ³n de Vectores (d = 1024)

> **ğŸ’¡ Para no tÃ©cnicos:** CuÃ¡nta memoria necesita cada sistema por cada millÃ³n de vectores almacenados.

| Base de Datos | RAM/1M Vectores | Incluye Ãndice | Notas |
|:--------------|:---------------:|:--------------:|:------|
| **Vertex AI Vector Search** | ~4 GB | âœ… Managed | Optimizado internamente |
| **Pinecone** | ~4-5 GB | âœ… Managed | Serverless abstrae esto |
| **Qdrant** | ~5-6 GB | âœ… | HNSW con quantization opcional |
| **Milvus** | ~6-8 GB | âœ… | Depende del Ã­ndice (IVF vs HNSW) |
| **Weaviate** | ~6-8 GB | âœ… | HNSW + filtros |
| **pgvector (HNSW)** | ~8-12 GB | âš ï¸ Parcial | Ãndice en memoria, datos en disco |
| **Chroma** | ~10-15 GB | âœ… | No optimizado para escala |

#### Costo Mensual por Escala de Vectores (USD/mes)

| Base de Datos | 10M vectores | 100M vectores | 244M vectores | 500M vectores | 1B vectores |
|:--------------|:------------:|:-------------:|:-------------:|:-------------:|:-----------:|
| **pgvector (Cloud SQL)** | $300 | $1,500 | **~$1,500** | $8,000+ âš ï¸ | âŒ No viable |
| **Vertex AI Vector Search** | $800 | $3,500 | ~$5,000 | $6,000 | $12,000 |
| **Pinecone Serverless** | $500 | $2,000 | ~$4,500 | $5,000 | $10,000 |
| **Milvus (GKE self-hosted)** | $400 | $1,500 | ~$3,000 | $4,000 | $8,000 |
| **Qdrant Cloud** | $500 | $2,000 | ~$4,500 | $5,000 | $10,000 |

> ğŸ’¡ **Punto de inflexiÃ³n econÃ³mico:** A partir de ~400M vectores, las soluciones managed (Vertex AI, Pinecone) son **mÃ¡s baratas** que escalar pgvector a su mÃ¡xima capacidad.

---

### 4.4 Matriz Comparativa con EvaluaciÃ³n

| Criterio (Peso) | pgvector | Pinecone | Weaviate | Vertex AI VS | Qdrant |
|:----------------|:--------:|:--------:|:--------:|:------------:|:------:|
| **Costo (25%)** | â­â­â­â­â­ | â­â­ | â­â­â­ | â­â­â­ | â­â­â­â­ |
| **Rendimiento (20%)** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| **Escalabilidad (15%)** | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ |
| **Expertise equipo (15%)** | â­â­â­â­â­ | â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­ |
| **Vendor lock-in (10%)** | â­â­â­â­â­ | â­â­ | â­â­â­â­ | â­â­ | â­â­â­â­â­ |
| **Features (10%)** | â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| **Soporte (5%)** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­ |

#### Leyenda de CalificaciÃ³n

| Estrellas | Significado |
|:---------:|:------------|
| â­â­â­â­â­ | Excelente - Cumple plenamente con las expectativas |
| â­â­â­â­ | Muy bueno - Cumple expectativas con minor trade-offs |
| â­â­â­ | Bueno - Cumple expectativas bÃ¡sicas |
| â­â­ | Regular - Tiene limitaciones significativas |
| â­ | Deficiente - No cumple con las expectativas |

---

### 4.5 Score Ponderado Final

| SoluciÃ³n | Score Ponderado | Costo/mes (244M vec) | RecomendaciÃ³n |
|:---------|:---------------:|:--------------------:|:--------------|
| **pgvector (Cloud SQL)** | **4.25/5** | ~$1,500 | â­ **RECOMENDADO** |
| Qdrant Cloud | 3.85/5 | ~$4,500 | Alternativa viable |
| Weaviate Cloud | 3.70/5 | ~$5,000 | Feature-rich pero caro |
| Vertex AI Vector Search | 3.65/5 | ~$5,000 | Bueno si todo es GCP |
| Pinecone | 3.40/5 | ~$4,500 | Muy caro para este volumen |

#### CÃ¡lculo del Score (ejemplo pgvector)

```
Score = (5Ã—0.25) + (4Ã—0.20) + (3Ã—0.15) + (5Ã—0.15) + (5Ã—0.10) + (4Ã—0.10) + (4Ã—0.05)
      = 1.25 + 0.80 + 0.45 + 0.75 + 0.50 + 0.40 + 0.20
      = 4.35/5 â‰ˆ 4.25/5 (ajustado por consideraciones cualitativas)
```

---

### 4.6 DecisiÃ³n: PostgreSQL + pgvector

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DECISIÃ“N: PostgreSQL + pgvector                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  âœ… RAZONES PRINCIPALES:                                                     â”‚
â”‚                                                                              â”‚
â”‚  1. COSTO: 60-70% mÃ¡s barato que alternativas managed                       â”‚
â”‚     â€¢ $1,500/mes vs. $4,500/mes (Pinecone/Qdrant)                           â”‚
â”‚     â€¢ Ahorro proyectado: ~$36,000/aÃ±o                                       â”‚
â”‚                                                                              â”‚
â”‚  2. EXPERTISE: El equipo ya conoce PostgreSQL                               â”‚
â”‚     â€¢ Menor curva de aprendizaje                                            â”‚
â”‚     â€¢ Debugging familiar (EXPLAIN ANALYZE, pg_stat_*)                       â”‚
â”‚     â€¢ IntegraciÃ³n con herramientas existentes (pg_dump, etc.)               â”‚
â”‚                                                                              â”‚
â”‚  3. FLEXIBILIDAD: Sin vendor lock-in                                        â”‚
â”‚     â€¢ MigraciÃ³n a otra infra es posible (on-prem, cualquier cloud)          â”‚
â”‚     â€¢ Open source con comunidad activa (>8K GitHub stars)                   â”‚
â”‚     â€¢ Formato de datos estÃ¡ndar                                             â”‚
â”‚                                                                              â”‚
â”‚  4. FEATURES: BÃºsqueda hÃ­brida nativa                                       â”‚
â”‚     â€¢ Vector + BM25 (tsvector) en una sola query SQL                        â”‚
â”‚     â€¢ No requiere servicios adicionales                                     â”‚
â”‚     â€¢ Filtrado por permisos con SQL estÃ¡ndar                                â”‚
â”‚                                                                              â”‚
â”‚  5. ESCALA: Suficiente para 244M-500M vectores                              â”‚
â”‚     â€¢ Con optimizaciones (halfvec, Matryoshka) cubre roadmap de 3 aÃ±os      â”‚
â”‚     â€¢ Cloud SQL Enterprise soporta hasta 64 TB y 624 GB RAM                 â”‚
â”‚                                                                              â”‚
â”‚  6. COMPLIANCE: Ya aprobado por el Ã¡rea de seguridad                        â”‚
â”‚     â€¢ PostgreSQL ya estÃ¡ en el stack aprobado                               â”‚
â”‚     â€¢ Cloud SQL Enterprise tiene certificaciones SOC2, ISO 27001            â”‚
â”‚                                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  âš ï¸ LIMITACIONES ACEPTADAS:                                                 â”‚
â”‚                                                                              â”‚
â”‚  â€¢ Escalabilidad manual (vs. auto-scale de Pinecone)                        â”‚
â”‚    â†’ MitigaciÃ³n: Monitoreo proactivo, alertas en 70% capacidad              â”‚
â”‚                                                                              â”‚
â”‚  â€¢ Requiere tuning de Ã­ndices HNSW                                          â”‚
â”‚    â†’ MitigaciÃ³n: ConfiguraciÃ³n documentada, runbooks preparados             â”‚
â”‚                                                                              â”‚
â”‚  â€¢ No hay UI de administraciÃ³n visual                                       â”‚
â”‚    â†’ MitigaciÃ³n: pgAdmin, Cloud SQL Studio, queries SQL                     â”‚
â”‚                                                                              â”‚
â”‚  â€¢ Throughput limitado (~200-400 QPS para 244M vectores)                    â”‚
â”‚    â†’ MitigaciÃ³n: Nuestro requisito es solo 30 QPS (margen 10x)              â”‚
â”‚                                                                              â”‚
â”‚  â€¢ LÃ­mite de escala: ~500M vectores mÃ¡ximo prÃ¡ctico                         â”‚
â”‚    â†’ MitigaciÃ³n: Plan de migraciÃ³n a Vertex AI si >400M                     â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.7 Punto de InflexiÃ³n: Â¿CuÃ¡ndo Migrar a Vertex AI?

Calculamos el momento Ã³ptimo de migraciÃ³n basado en tres criterios:

#### Criterio 1: TÃ©cnico (RAM)

```
Â¿CuÃ¡ndo el Ã­ndice supera la RAM mÃ¡xima de Cloud SQL?

RAM mÃ¡xima Cloud SQL = 624 GB
Ãndice al 20% caliente = 624 / 0.20 = 3.1 TB mÃ¡ximo de Ã­ndice
Vectores correspondientes = 3.1 TB / 5 KB â‰ˆ 600 M vectores

â†’ LÃ­mite tÃ©cnico: ~600 M vectores
```

#### Criterio 2: Performance (Latencia)

```
Â¿CuÃ¡ndo la latencia P95 supera 50 ms?

Basado en nuestro modelo, esto ocurre cuando:
- Solo 10% del Ã­ndice estÃ¡ en RAM
- Equivale a ~400 M vectores con 250 GB RAM

â†’ LÃ­mite de performance: ~400 M vectores
```

#### Criterio 3: EconÃ³mico (Costo)

```
Â¿CuÃ¡ndo Vertex AI es mÃ¡s barato que pgvector?

Cloud SQL db-custom-96-614400 (mÃ¡ximo) = $8,500/mes
Vertex AI para 400M vectores = $6,000/mes

â†’ Punto de inflexiÃ³n econÃ³mico: ~400 M vectores
```

#### ConclusiÃ³n del Punto de InflexiÃ³n

$$
\boxed{
\text{Punto de InflexiÃ³n} = \min(600M, 400M, 400M) = 400M \text{ vectores}
}
$$

> **RecomendaciÃ³n:** Iniciar PoC de Vertex AI cuando alcancemos **300 M vectores** (~mes 12-15), y migrar completamente antes de alcanzar **400 M vectores** (~mes 18).

---

## CapÃ­tulo 5: Arquitectura de Referencia

### 5.1 Diagrama de Arquitectura General

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ENTERPRISE AI PLATFORM - ARQUITECTURA RAG                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                              CAPA DE PRESENTACIÃ“N                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚ â”‚
â”‚  â”‚  â”‚   Web App       â”‚  â”‚   API REST      â”‚  â”‚   Chatbot       â”‚                     â”‚ â”‚
â”‚  â”‚  â”‚   (Next.js)     â”‚  â”‚   (FastAPI)     â”‚  â”‚   (Slack/Teams) â”‚                     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚ â”‚
â”‚  â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                  â–¼                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                              CAPA DE ORQUESTACIÃ“N                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚                         RAG Orchestrator (LangChain/LlamaIndex)              â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â”‚   Query     â”‚  â”‚  Retrieval  â”‚  â”‚  Reranking  â”‚  â”‚    Generation       â”‚ â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Processing  â”‚â”€â–¶â”‚   Engine    â”‚â”€â–¶â”‚   (Cohere)  â”‚â”€â–¶â”‚   (Gemini Pro)      â”‚ â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚ â”‚
â”‚  â”‚  â”‚                          â”‚                                                   â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                    Semantic Cache (Redis)                                â”‚â”‚   â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                   â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                              CAPA DE DATOS                                          â”‚ â”‚
â”‚  â”‚                                                                                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚
â”‚  â”‚  â”‚        VECTOR STORE (Principal)          â”‚  â”‚      DOCUMENT STORE             â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚    Cloud SQL Enterprise (pgvector)  â”‚ â”‚  â”‚  â”‚    Cloud Storage (GCS)      â”‚â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                                     â”‚ â”‚  â”‚  â”‚                             â”‚â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚    â€¢ 244M vectores                  â”‚ â”‚  â”‚  â”‚    â€¢ 17 TB documentos       â”‚â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚    â€¢ halfvec(768) + HNSW            â”‚ â”‚  â”‚  â”‚    â€¢ PDFs, Office, texto    â”‚â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚    â€¢ Particionado por Ã¡rea          â”‚ â”‚  â”‚  â”‚    â€¢ Versionados            â”‚â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚    â€¢ Hybrid search (vec + BM25)     â”‚ â”‚  â”‚  â”‚                             â”‚â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚ â”‚
â”‚  â”‚  â”‚                                          â”‚  â”‚                                  â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚    Read Replicas (2x)               â”‚ â”‚  â”‚  â”‚    Metadata Store           â”‚â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚    â€¢ DistribuciÃ³n de carga          â”‚ â”‚  â”‚  â”‚    (Cloud SQL PostgreSQL)  â”‚â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â”‚    â€¢ HA Zone-redundant              â”‚ â”‚  â”‚  â”‚    â€¢ Permisos, tenants      â”‚â”‚  â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â”‚    â€¢ Audit logs             â”‚â”‚  â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚  â”‚ â”‚
â”‚  â”‚                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                              CAPA DE INGESTIÃ“N                                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚ â”‚
â”‚  â”‚  â”‚  OpenText   â”‚  â”‚  Document   â”‚  â”‚  Chunking   â”‚  â”‚  Embedding  â”‚                â”‚ â”‚
â”‚  â”‚  â”‚  Connector  â”‚â”€â–¶â”‚  Parser     â”‚â”€â–¶â”‚  Engine     â”‚â”€â–¶â”‚  Service    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚ â”‚
â”‚  â”‚  â”‚             â”‚  â”‚  (Unstructured)â”‚ (LangChain) â”‚  â”‚  (Gemini)   â”‚            â”‚   â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚   â”‚ â”‚
â”‚  â”‚                                                                                 â”‚   â”‚ â”‚
â”‚  â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ â”‚
â”‚  â”‚         â–¼                                                                           â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                            â”‚ â”‚
â”‚  â”‚  â”‚  Cloud Pub/Sub      â”‚  (Cola de procesamiento asÃ­ncrono)                         â”‚ â”‚
â”‚  â”‚  â”‚  + Cloud Functions  â”‚                                                            â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Componentes del Sistema

#### Componentes Principales

| Componente | TecnologÃ­a | Responsabilidad | UbicaciÃ³n GCP |
|:-----------|:-----------|:----------------|:--------------|
| **Vector Store** | Cloud SQL Enterprise + pgvector | Almacenamiento y bÃºsqueda de embeddings | southamerica-east1 |
| **Embedding Service** | Gemini text-embedding-004 | GeneraciÃ³n de embeddings 768d | Vertex AI API |
| **LLM** | Gemini 1.5 Pro | GeneraciÃ³n de respuestas | Vertex AI API |
| **Reranker** | Cohere Rerank v3 | Reordenamiento de resultados | API externa |
| **Semantic Cache** | Memorystore for Redis | Cache de queries y respuestas | southamerica-east1 |
| **Document Store** | Cloud Storage | Documentos originales (17 TB) | southamerica-east1 |
| **Orchestrator** | Cloud Run | LÃ³gica de negocio RAG | southamerica-east1 |
| **Message Queue** | Cloud Pub/Sub | Cola de ingestiÃ³n asÃ­ncrona | Global |

#### Componentes de Soporte

| Componente | TecnologÃ­a | Responsabilidad |
|:-----------|:-----------|:----------------|
| **Logging** | Cloud Logging | Logs centralizados |
| **Monitoring** | Cloud Monitoring | MÃ©tricas y dashboards |
| **Tracing** | Cloud Trace | Distributed tracing |
| **Secrets** | Secret Manager | GestiÃ³n de credenciales |
| **IAM** | Cloud IAM | Control de acceso |

---

### 5.3 Flujo de Datos: IngestiÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           PIPELINE DE INGESTIÃ“N (Batch/Streaming)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                          â”‚
â”‚  FUENTE                 EXTRACCIÃ“N              PROCESAMIENTO              ALMACENAMIENTOâ”‚
â”‚  â”€â”€â”€â”€â”€â”€                 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚                                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚OpenText â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Documentâ”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Chunking   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Embedding  â”‚â”‚
â”‚  â”‚ (17 TB) â”‚  CDC      â”‚ Parser  â”‚  Texto     â”‚  Recursive  â”‚  Chunks    â”‚  Gemini 768dâ”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  Hourly   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  Limpio    â”‚  4KB + 15%  â”‚  244M      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                        (Unstructured)          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                                     â”‚       â”‚
â”‚  â”‚SharePointâ”‚                                                                    â–¼       â”‚
â”‚  â”‚ (500GB) â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                             â”‚   Cloud     â”‚â”‚
â”‚                                                                          â”‚   Pub/Sub   â”‚â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                             â”‚   Queue     â”‚â”‚
â”‚  â”‚Confluence                                                             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”‚ (200GB) â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                                     â”‚       â”‚
â”‚                                                                                  â–¼       â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚                         â”‚                    UPSERT BATCH                               â”‚â”‚
â”‚                         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚
â”‚                         â”‚  â”‚ Cloud SQL Enterprise (pgvector)                        â”‚  â”‚â”‚
â”‚                         â”‚  â”‚                                                        â”‚  â”‚â”‚
â”‚                         â”‚  â”‚  INSERT INTO embeddings (doc_id, chunk_id, area,       â”‚  â”‚â”‚
â”‚                         â”‚  â”‚                          embedding, metadata)          â”‚  â”‚â”‚
â”‚                         â”‚  â”‚  VALUES (...)                                          â”‚  â”‚â”‚
â”‚                         â”‚  â”‚  ON CONFLICT (doc_id, chunk_id) DO UPDATE;             â”‚  â”‚â”‚
â”‚                         â”‚  â”‚                                                        â”‚  â”‚â”‚
â”‚                         â”‚  â”‚  â†’ Particionado por Ã¡rea (RRHH, Legal, Ops, ...)       â”‚  â”‚â”‚
â”‚                         â”‚  â”‚  â†’ Ãndice HNSW reconstruido post-batch                 â”‚  â”‚â”‚
â”‚                         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Pasos del Pipeline de IngestiÃ³n

| Paso | Componente | AcciÃ³n | Output |
|:----:|:-----------|:-------|:-------|
| 1 | **CDC Connector** | Detecta documentos nuevos/modificados en OpenText | Lista de doc_ids |
| 2 | **Document Parser** | Extrae texto de PDF, Office, etc. | Texto plano limpio |
| 3 | **Deduplicator** | Elimina contenido duplicado/redundante | Texto Ãºnico |
| 4 | **Chunker** | Fragmenta en chunks de 4KB con 15% overlap | ~244M chunks |
| 5 | **Embedder** | Genera embedding 768d con Gemini | Vectors halfvec(768) |
| 6 | **Queue** | Encola para procesamiento asÃ­ncrono | Pub/Sub messages |
| 7 | **Loader** | Inserta en pgvector con UPSERT | Rows en DB |
| 8 | **Indexer** | Actualiza Ã­ndice HNSW (batch nocturno) | Ãndice optimizado |

---

### 5.4 Flujo de Datos: BÃºsqueda (Query)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           PIPELINE DE BÃšSQUEDA (Online, <3seg E2E)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                          â”‚
â”‚  USUARIO              CACHE                RETRIEVAL              GENERATION             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â”‚
â”‚                                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ "Â¿CuÃ¡l  â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Redis   â”‚â”€â”€â”€HITâ”€â”€â”€â–¶â”‚ Respuesta cacheada (latencia ~5ms)        â”‚  â”‚
â”‚  â”‚  es la  â”‚        â”‚ Cache   â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚  polÃ­ticaâ”‚        â”‚ SemÃ¡ntico         â”‚ MISS                                          â”‚
â”‚  â”‚  de     â”‚        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜          â–¼                                              â”‚
â”‚  â”‚  vacaciones?"         â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚        â”‚  Query      â”‚                                       â”‚
â”‚                          â”‚        â”‚  Embedding  â”‚                                       â”‚
â”‚                          â”‚        â”‚  (Gemini)   â”‚ ~50ms                                 â”‚
â”‚                          â”‚        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                          â”‚               â–¼                                              â”‚
â”‚                          â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                          â”‚        â”‚           HYBRID SEARCH (pgvector)              â”‚   â”‚
â”‚                          â”‚        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚                          â”‚        â”‚  â”‚ Vector Search   â”‚  â”‚  BM25 Search        â”‚   â”‚   â”‚
â”‚                          â”‚        â”‚  â”‚ (HNSW cosine)   â”‚  â”‚  (tsvector)         â”‚   â”‚   â”‚
â”‚                          â”‚        â”‚  â”‚ â†’ Top 30        â”‚  â”‚  â†’ Top 30           â”‚   â”‚   â”‚
â”‚                          â”‚        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚                          â”‚        â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚                          â”‚        â”‚                      â–¼                          â”‚   â”‚
â”‚                          â”‚        â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
â”‚                          â”‚        â”‚        â”‚  RRF (Reciprocal Rank   â”‚  ~25ms      â”‚   â”‚
â”‚                          â”‚        â”‚        â”‚  Fusion) â†’ Top 50       â”‚              â”‚   â”‚
â”‚                          â”‚        â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
â”‚                          â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                               â–¼                              â”‚
â”‚                          â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                          â”‚        â”‚         RERANKING (Cohere Rerank)               â”‚   â”‚
â”‚                          â”‚        â”‚         Top 50 â†’ Top 10 (~80ms)                 â”‚   â”‚
â”‚                          â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                               â–¼                              â”‚
â”‚                          â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                          â”‚        â”‚         LLM GENERATION (Gemini Pro)             â”‚   â”‚
â”‚                          â”‚        â”‚         Context: Top 10 chunks (~1500ms)        â”‚   â”‚
â”‚                          â”‚        â”‚         Response + Citations                    â”‚   â”‚
â”‚                          â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â”‚                               â–¼                              â”‚
â”‚                          â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â–¶â”‚         CACHE UPDATE (Redis)                    â”‚   â”‚
â”‚                                   â”‚         TTL: 24 horas, LRU eviction             â”‚   â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                          â–¼                              â”‚
â”‚                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                   â”‚              RESPUESTA AL USUARIO               â”‚   â”‚
â”‚                                   â”‚  "Los empleados tienen 15 dÃ­as hÃ¡biles..."     â”‚   â”‚
â”‚                                   â”‚  ğŸ“ Fuentes: politica_rrhh_2024.pdf (p.12)      â”‚   â”‚
â”‚                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Latencia por Componente

| Componente | Latencia P50 | Latencia P95 | Notas |
|:-----------|:------------:|:------------:|:------|
| **Cache Check** | 1 ms | 3 ms | Redis local |
| **Query Embedding** | 30 ms | 50 ms | Gemini API |
| **Hybrid Search** | 15 ms | 25 ms | pgvector HNSW + BM25 |
| **Reranking** | 60 ms | 100 ms | Cohere API (opcional) |
| **LLM Generation** | 1,200 ms | 2,000 ms | Gemini Pro |
| **Total (sin cache)** | ~1,300 ms | ~2,200 ms | Dentro del SLO de 3s |
| **Total (cache hit)** | 3 ms | 5 ms | 67% hit rate esperado |

---

### 5.5 Integraciones con GCP

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SERVICIOS GCP UTILIZADOS                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                        COMPUTE & RUNTIME                                 â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚â”‚
â”‚  â”‚  â”‚ Cloud Run   â”‚  â”‚ Cloud       â”‚  â”‚ GKE         â”‚  â”‚ Cloud       â”‚    â”‚â”‚
â”‚  â”‚  â”‚ (API/Web)   â”‚  â”‚ Functions   â”‚  â”‚ (Opcional)  â”‚  â”‚ Scheduler   â”‚    â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                        DATA & STORAGE                                    â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚â”‚
â”‚  â”‚  â”‚ Cloud SQL   â”‚  â”‚ Memorystore â”‚  â”‚ Cloud       â”‚  â”‚ BigQuery    â”‚    â”‚â”‚
â”‚  â”‚  â”‚ (pgvector)  â”‚  â”‚ (Redis)     â”‚  â”‚ Storage     â”‚  â”‚ (Analytics) â”‚    â”‚â”‚
â”‚  â”‚  â”‚ PRINCIPAL   â”‚  â”‚ CACHE       â”‚  â”‚ DOCS        â”‚  â”‚ OPCIONAL    â”‚    â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                        AI & ML                                           â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚â”‚
â”‚  â”‚  â”‚ Vertex AI   â”‚  â”‚ Vertex AI   â”‚  â”‚ (Futuro) Vertex AI              â”‚  â”‚â”‚
â”‚  â”‚  â”‚ Embeddings  â”‚  â”‚ Gemini Pro  â”‚  â”‚ Vector Search                   â”‚  â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                        MESSAGING & INTEGRATION                           â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚â”‚
â”‚  â”‚  â”‚ Cloud       â”‚  â”‚ Cloud       â”‚  â”‚ Eventarc    â”‚                     â”‚â”‚
â”‚  â”‚  â”‚ Pub/Sub     â”‚  â”‚ Tasks       â”‚  â”‚ (Triggers)  â”‚                     â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                        SECURITY & GOVERNANCE                             â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚â”‚
â”‚  â”‚  â”‚ Cloud IAM   â”‚  â”‚ Secret      â”‚  â”‚ Cloud       â”‚  â”‚ VPC Service â”‚    â”‚â”‚
â”‚  â”‚  â”‚             â”‚  â”‚ Manager     â”‚  â”‚ Armor       â”‚  â”‚ Controls    â”‚    â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                        OBSERVABILITY                                     â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚â”‚
â”‚  â”‚  â”‚ Cloud       â”‚  â”‚ Cloud       â”‚  â”‚ Cloud       â”‚  â”‚ Error       â”‚    â”‚â”‚
â”‚  â”‚  â”‚ Monitoring  â”‚  â”‚ Logging     â”‚  â”‚ Trace       â”‚  â”‚ Reporting   â”‚    â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Resumen de Servicios GCP

| CategorÃ­a | Servicio | PropÃ³sito | SKU/Tier |
|:----------|:---------|:----------|:---------|
| **Compute** | Cloud Run | API RAG | Gen2, 4 vCPU, 8GB RAM |
| **Database** | Cloud SQL Enterprise | Vector Store | db-custom-48-307200 |
| **Cache** | Memorystore Redis | Semantic Cache | Standard, 8GB |
| **Storage** | Cloud Storage | Documentos | Standard, 17TB |
| **AI** | Vertex AI Embeddings | text-embedding-004 | Pay-per-use |
| **AI** | Vertex AI Generative | Gemini 1.5 Pro | Pay-per-use |
| **Messaging** | Cloud Pub/Sub | Cola ingestiÃ³n | Standard |
| **Observability** | Cloud Operations Suite | Logs, metrics, traces | Standard |

---
---

# SECCIÃ“N III: TÃ‰CNICAS DE OPTIMIZACIÃ“N

> **Nota:** Esta secciÃ³n explica QUÃ‰ son las tÃ©cnicas y CÃ“MO funcionan. El impacto en costos se calcularÃ¡ en detalle en la SecciÃ³n V (AnÃ¡lisis de Escenarios y Costos).

---

## CapÃ­tulo 6: CompresiÃ³n de Embeddings

### 6.1 Matryoshka Representation Learning

#### Â¿QuÃ© es Matryoshka?

> **AnalogÃ­a: MuÃ±ecas Rusas ğŸª†**
> 
> Las muÃ±ecas Matryoshka (muÃ±ecas rusas) tienen una caracterÃ­stica Ãºnica: cada muÃ±eca contiene versiones mÃ¡s pequeÃ±as de sÃ­ misma dentro.
> 
> Los **Matryoshka embeddings** funcionan igual: un embedding de 3072 dimensiones contiene dentro de sÃ­ un embedding vÃ¡lido de 1536, 768, 512, 256... dimensiones.
> 
> | DimensiÃ³n | InformaciÃ³n contenida |
> |:---------:|:---------------------|
> | 3072d | 100% del significado |
> | 1536d | ~99% del significado |
> | 768d | ~98% del significado â† **Punto Ã³ptimo** |
> | 512d | ~95% del significado |
> | 256d | ~90% del significado |

#### Â¿CÃ³mo funciona?

Los modelos entrenados con Matryoshka Representation Learning (MRL) organizan la informaciÃ³n de forma jerÃ¡rquica:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ESTRUCTURA MATRYOSHKA                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Embedding completo (3072 dimensiones):                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚[d1,d2,d3,...,d256â”‚d257,...,d512â”‚d513,...,d768â”‚...â”‚...,d3072]â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚       â–²               â–²              â–²                          â”‚
â”‚       â”‚               â”‚              â”‚                          â”‚
â”‚       â”‚               â”‚              â””â”€â”€ Dimensiones 513-768:   â”‚
â”‚       â”‚               â”‚                  Detalles finos         â”‚
â”‚       â”‚               â”‚                                         â”‚
â”‚       â”‚               â””â”€â”€ Dimensiones 257-512:                  â”‚
â”‚       â”‚                   Contexto adicional                    â”‚
â”‚       â”‚                                                         â”‚
â”‚       â””â”€â”€ Dimensiones 1-256:                                    â”‚
â”‚           Significado esencial (tÃ³picos, conceptos clave)       â”‚
â”‚                                                                  â”‚
â”‚  âœ‚ï¸ TRUNCATION: Solo tomamos las primeras N dimensiones         â”‚
â”‚                                                                  â”‚
â”‚  [d1,d2,d3,...,d768] â† 768d contiene el 98% del significado     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Modelos Compatibles con Matryoshka

| Modelo | DimensiÃ³n Nativa | Dimensiones Soportadas | MultilingÃ¼e | Recomendado |
|:-------|:----------------:|:----------------------:|:-----------:|:-----------:|
| **Gemini text-embedding-004** | 768-3072 | 256, 512, 768, 1536, 3072 | âœ… | â­ **SÃ­** |
| OpenAI text-embedding-3-small | 1536 | 256, 512, 1024, 1536 | âœ… | Alternativa |
| OpenAI text-embedding-3-large | 3072 | 256, 512, 1024, 1536, 3072 | âœ… | Alternativa |
| Cohere embed-v3 | 1024 | 256, 512, 1024 | âœ… | Alternativa |
| nomic-embed-text-v1.5 | 768 | 64, 128, 256, 512, 768 | âŒ | Solo inglÃ©s |
| mxbai-embed-large-v1 | 1024 | 256, 512, 768, 1024 | âŒ | Solo inglÃ©s |

> âš ï¸ **Importante:** No todos los modelos soportan Matryoshka. Verificar en la documentaciÃ³n del proveedor antes de usar truncation.

#### ConfiguraciÃ³n de Gemini para Matryoshka

```python
from google.cloud import aiplatform
from vertexai.language_models import TextEmbeddingModel

# Inicializar modelo
model = TextEmbeddingModel.from_pretrained("text-embedding-004")

# Solicitar embeddings con dimensiÃ³n reducida (Matryoshka)
embeddings = model.get_embeddings(
    texts=["Tu texto aquÃ­ para vectorizar"],
    output_dimensionality=768  # â† Matryoshka truncation a 768d
)

# Extraer el vector
vector_768d = embeddings[0].values  # Lista de 768 floats
print(f"Dimensiones: {len(vector_768d)}")  # Output: 768
```

---

### 6.2 halfvec (Float16) en pgvector

#### Â¿QuÃ© es halfvec?

> **AnalogÃ­a: Redondear Precios ğŸ’µ**
> 
> Cuando guardas precios, Â¿necesitas todos los decimales?
> 
> | Precio exacto (float32) | Redondeado (float16) | Â¿Se nota? |
> |:-----------------------:|:--------------------:|:---------:|
> | $45.3729847 | $45.37 | No |
> | $1,234.56789 | $1,234.57 | No |
> | $0.000012345 | $0.00001 | SÃ­ (pero raro) |
> 
> En bÃºsquedas vectoriales, pequeÃ±as diferencias decimales casi nunca cambian cuÃ¡l es el "documento mÃ¡s similar".

#### ComparaciÃ³n de Precisiones

| Tipo | Bytes/nÃºmero | Rango | PrecisiÃ³n | Uso tÃ­pico |
|:-----|:------------:|:------|:----------|:-----------|
| **float32** | 4 | Â±3.4Ã—10Â³â¸ | ~7 dÃ­gitos | PrecisiÃ³n estÃ¡ndar |
| **float16 (halfvec)** | 2 | Â±65,504 | ~3.3 dÃ­gitos | â­ Recomendado |
| **bfloat16** | 2 | Â±3.4Ã—10Â³â¸ | ~3.3 dÃ­gitos | ML training (no en pgvector) |
| **int8** | 1 | -128 a 127 | Enteros | CuantizaciÃ³n agresiva |

#### Soporte en pgvector

| VersiÃ³n pgvector | halfvec | Ãndices HNSW | Operadores |
|:-----------------|:-------:|:------------:|:-----------|
| < 0.7.0 | âŒ | â€” | â€” |
| **0.7.0+** | âœ… | âœ… | `halfvec_cosine_ops`, `halfvec_l2_ops`, `halfvec_ip_ops` |

#### ImplementaciÃ³n SQL

```sql
-- ============================================================
-- PASO 1: Verificar versiÃ³n de pgvector
-- ============================================================
SELECT extversion FROM pg_extension WHERE extname = 'vector';
-- Debe ser >= 0.7.0

-- ============================================================
-- PASO 2: Crear tabla con halfvec
-- ============================================================
CREATE TABLE embeddings_optimized (
    id BIGSERIAL PRIMARY KEY,
    doc_id UUID NOT NULL,
    chunk_id INTEGER NOT NULL,
    area VARCHAR(50) NOT NULL,
    chunk_text TEXT,
    
    -- ğŸ’¡ halfvec(768) usa solo 1,544 bytes vs 3,080 de vector(768)
    embedding halfvec(768),
    
    -- Metadata
    file_path TEXT,
    page_number INTEGER,
    created_at TIMESTAMP DEFAULT NOW(),
    
    -- Constraint para evitar duplicados
    UNIQUE(doc_id, chunk_id)
);

-- ============================================================
-- PASO 3: Crear Ã­ndice HNSW para halfvec
-- ============================================================
CREATE INDEX idx_embeddings_hnsw ON embeddings_optimized 
USING hnsw (embedding halfvec_cosine_ops)
WITH (
    m = 16,              -- Conexiones por nodo (balance memoria/calidad)
    ef_construction = 64 -- Calidad de construcciÃ³n del Ã­ndice
);

-- ============================================================
-- PASO 4: Query de bÃºsqueda con halfvec
-- ============================================================
SELECT 
    doc_id,
    chunk_text,
    1 - (embedding <=> $1::halfvec) AS similarity
FROM embeddings_optimized
WHERE area = 'RRHH'  -- Partition pruning
ORDER BY embedding <=> $1::halfvec
LIMIT 10;

-- ============================================================
-- PASO 5: MigraciÃ³n de float32 a halfvec (si hay datos existentes)
-- ============================================================
-- Crear nueva tabla
CREATE TABLE embeddings_new (LIKE embeddings_optimized);

-- Migrar con conversiÃ³n de tipo
INSERT INTO embeddings_new (doc_id, chunk_id, area, chunk_text, embedding, ...)
SELECT doc_id, chunk_id, area, chunk_text, 
       embedding::halfvec,  -- â† ConversiÃ³n automÃ¡tica
       ...
FROM embeddings_original;

-- Renombrar tablas
ALTER TABLE embeddings_original RENAME TO embeddings_backup;
ALTER TABLE embeddings_new RENAME TO embeddings_optimized;
```

---

### 6.3 CombinaciÃ³n Ã“ptima: Pipeline de CompresiÃ³n

La estrategia de mayor impacto combina Matryoshka (reducciÃ³n de dimensiones) con halfvec (reducciÃ³n de precisiÃ³n):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           PIPELINE DE COMPRESIÃ“N                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  ENTRADA                                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€                                                                     â”‚
â”‚  "La polÃ­tica de vacaciones establece que los empleados..."                 â”‚
â”‚                                                                              â”‚
â”‚           â”‚                                                                  â”‚
â”‚           â–¼                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                     PASO 1: EMBEDDING (Gemini API)                       â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚  model.get_embeddings(texts, output_dimensionality=768)                  â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚  Output: [0.123, -0.456, 0.789, ..., 0.234]  â† 768 floats (float32)      â”‚â”‚
â”‚  â”‚  TamaÃ±o: 768 Ã— 4 bytes = 3,072 bytes                                     â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚           â”‚                                                                  â”‚
â”‚           â–¼                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                     PASO 2: QUANTIZATION (Python)                        â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚  import numpy as np                                                      â”‚â”‚
â”‚  â”‚  embedding_f16 = np.array(embedding, dtype=np.float16)                   â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚  Output: [0.123, -0.456, 0.789, ..., 0.234]  â† 768 half-precision       â”‚â”‚
â”‚  â”‚  TamaÃ±o: 768 Ã— 2 bytes = 1,536 bytes                                     â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚           â”‚                                                                  â”‚
â”‚           â–¼                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                     PASO 3: STORAGE (pgvector)                           â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚  INSERT INTO embeddings_optimized (embedding, ...)                       â”‚â”‚
â”‚  â”‚  VALUES ($1::halfvec, ...);                                              â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚  Almacenado: halfvec(768) = 1,544 bytes (con header)                     â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â”‚  RESULTADO                                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚  BASELINE (1024d float32):    4,104 bytes/vector                         â”‚â”‚
â”‚  â”‚  OPTIMIZADO (768d halfvec):   1,544 bytes/vector                         â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚  REDUCCIÃ“N: 62% menos almacenamiento                                     â”‚â”‚
â”‚  â”‚  CALIDAD:   ~97.5% del recall original                                   â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### CÃ³digo Python Completo del Pipeline

```python
import numpy as np
from google.cloud import aiplatform
from vertexai.language_models import TextEmbeddingModel
import psycopg2

class OptimizedEmbeddingPipeline:
    """Pipeline de embeddings optimizado con Matryoshka + halfvec."""
    
    def __init__(self, dimension: int = 768):
        self.dimension = dimension
        self.model = TextEmbeddingModel.from_pretrained("text-embedding-004")
    
    def embed(self, texts: list[str]) -> list[np.ndarray]:
        """Genera embeddings Matryoshka + float16."""
        
        # Paso 1: Obtener embeddings con dimensiÃ³n reducida (Matryoshka)
        embeddings = self.model.get_embeddings(
            texts=texts,
            output_dimensionality=self.dimension  # â† Matryoshka
        )
        
        # Paso 2: Convertir a float16 (halfvec)
        vectors = [
            np.array(emb.values, dtype=np.float16)  # â† Quantization
            for emb in embeddings
        ]
        
        return vectors
    
    def insert_batch(self, conn, records: list[dict]):
        """Inserta batch de vectores optimizados en pgvector."""
        
        with conn.cursor() as cur:
            for record in records:
                # Convertir numpy array a formato pgvector
                vector_str = "[" + ",".join(map(str, record["embedding"])) + "]"
                
                cur.execute("""
                    INSERT INTO embeddings_optimized 
                    (doc_id, chunk_id, area, chunk_text, embedding)
                    VALUES (%s, %s, %s, %s, %s::halfvec)
                    ON CONFLICT (doc_id, chunk_id) DO UPDATE
                    SET embedding = EXCLUDED.embedding,
                        chunk_text = EXCLUDED.chunk_text;
                """, (
                    record["doc_id"],
                    record["chunk_id"],
                    record["area"],
                    record["chunk_text"],
                    vector_str
                ))
            
            conn.commit()

# Uso
pipeline = OptimizedEmbeddingPipeline(dimension=768)
vectors = pipeline.embed(["Texto del chunk 1", "Texto del chunk 2"])
```

---

### 6.4 Tabla de Impacto TeÃ³rico por Estrategia

| Estrategia | DimensiÃ³n | PrecisiÃ³n | Bytes/vector | Disco (244M vec) | RAM (20% hot) | Costo/mes | RetenciÃ³n Calidad |
|:-----------|:---------:|:---------:|:------------:|:----------------:|:-------------:|:---------:|:-----------------:|
| **Baseline** (1024d float32) | 1024 | float32 | 4,104 B | ~3.0 TB | ~240 GB | ~$3,200 | 100% |
| Matryoshka 768d | 768 | float32 | 3,080 B | ~2.3 TB | ~180 GB | ~$2,400 | ~98% |
| Matryoshka 512d | 512 | float32 | 2,056 B | ~1.5 TB | ~120 GB | ~$1,800 | ~95% |
| halfvec (1024d float16) | 1024 | float16 | 2,056 B | ~1.5 TB | ~120 GB | ~$1,800 | ~99.9% |
| **Matryoshka 768d + halfvec** | **768** | **float16** | **1,544 B** | **~1.1 TB** | **~90 GB** | **~$1,500** | **~97.5%** |
| Matryoshka 512d + halfvec | 512 | float16 | 1,032 B | ~0.8 TB | ~65 GB | ~$1,100 | ~94% |

> â­ **RecomendaciÃ³n:** Usar **Matryoshka 768d + halfvec** como configuraciÃ³n por defecto. Ofrece el mejor balance entre ahorro (53% menos disco/RAM) y calidad (97.5% recall).

---

### 6.5 Otras Estrategias de CompresiÃ³n

Existen tÃ©cnicas adicionales mÃ¡s agresivas que pueden considerarse para casos especÃ­ficos:

| TÃ©cnica | DescripciÃ³n | ReducciÃ³n | PÃ©rdida Calidad | CuÃ¡ndo usar |
|:--------|:------------|:---------:|:---------------:|:------------|
| **Binary Quantization** | Vectores binarios (1 bit/dim) | 97% | 5-15% | Filtrado rÃ¡pido + rerank |
| **Product Quantization (PQ)** | Divide vector en sub-vectores | 90-95% | 2-5% | Billones de vectores |
| **Scalar Quantization (SQ)** | int8 por dimensiÃ³n | 75% | 1-2% | Alternativa a halfvec |
| **Coarse Quantization** | Clustering + residuos | Variable | 1-3% | IVF-based indexes |

> âš ï¸ **Nota:** pgvector 0.7+ soporta nativamente `halfvec`. Para estrategias mÃ¡s agresivas como PQ, considerar Faiss o Milvus.

---

## CapÃ­tulo 7: Particionamiento de Datos

### 7.1 Concepto y Beneficios

> **AnalogÃ­a: Biblioteca con CatÃ¡logos Separados ğŸ“š**
> 
> Imagina una biblioteca con UN solo catÃ¡logo gigante de 17 millones de libros vs. catÃ¡logos separados por secciÃ³n:
> 
> | Enfoque | Buscar "contratos de trabajo" |
> |:--------|:------------------------------|
> | **1 catÃ¡logo gigante** | Revisar 17M entradas, encontrar en secciÃ³n RRHH |
> | **CatÃ¡logos por secciÃ³n** | Ir directo a catÃ¡logo RRHH, revisar solo 2.5M entradas |
> 
> El particionamiento por Ã¡rea funcional permite a PostgreSQL "saltar" directamente a la particiÃ³n relevante.

#### Â¿QuÃ© es Partition Pruning?

Cuando PostgreSQL ejecuta una query con filtro por Ã¡rea:

```sql
SELECT * FROM embeddings WHERE area = 'RRHH' AND embedding <=> $1 < 0.3;
```

El **Partition Pruning** automÃ¡ticamente:
1. Identifica que solo la particiÃ³n `embeddings_rrhh` es relevante
2. Ignora completamente las demÃ¡s particiones
3. Ejecuta la bÃºsqueda HNSW solo en ~37M vectores (no en 244M)

### 7.2 Particionamiento Nativo PostgreSQL vs. Tablas Separadas

| Aspecto | Particionamiento Nativo | Tablas Separadas |
|:--------|:-----------------------:|:----------------:|
| **Complejidad** | Media | Baja |
| **Queries cross-Ã¡rea** | âœ… AutomÃ¡tico | âŒ Requiere UNION ALL manual |
| **Ãndices** | Un Ã­ndice por particiÃ³n (automÃ¡tico) | Ãndices independientes |
| **Mantenimiento** | âœ… Comandos estÃ¡ndar | Manual por tabla |
| **Escalabilidad** | Hasta ~100 particiones | Ilimitado |
| **Recomendado** | â­ Para la mayorÃ­a de casos | Solo si >100 Ã¡reas |

### 7.3 ImplementaciÃ³n SQL

```sql
-- ============================================================
-- ESQUEMA PARTICIONADO POR ÃREA FUNCIONAL
-- ============================================================

-- Paso 1: Crear tabla padre particionada
CREATE TABLE embeddings (
    id BIGINT GENERATED ALWAYS AS IDENTITY,
    doc_id UUID NOT NULL,
    chunk_id INTEGER NOT NULL,
    area VARCHAR(50) NOT NULL,
    chunk_text TEXT,
    embedding halfvec(768),
    file_path TEXT,
    created_at TIMESTAMP DEFAULT NOW(),
    PRIMARY KEY (id, area)  -- â† Ã¡rea debe estar en la PK
) PARTITION BY LIST (area);

-- Paso 2: Crear particiones por Ã¡rea
CREATE TABLE embeddings_rrhh 
    PARTITION OF embeddings FOR VALUES IN ('RRHH');

CREATE TABLE embeddings_callcenter 
    PARTITION OF embeddings FOR VALUES IN ('CALL_CENTER');

CREATE TABLE embeddings_legal 
    PARTITION OF embeddings FOR VALUES IN ('LEGAL');

CREATE TABLE embeddings_operaciones 
    PARTITION OF embeddings FOR VALUES IN ('OPERACIONES');

CREATE TABLE embeddings_finanzas 
    PARTITION OF embeddings FOR VALUES IN ('FINANZAS');

CREATE TABLE embeddings_otros 
    PARTITION OF embeddings FOR VALUES IN ('OTROS');

-- Paso 3: Crear Ã­ndices HNSW en cada particiÃ³n
-- (PostgreSQL crea Ã­ndices automÃ¡ticamente en cada particiÃ³n)
CREATE INDEX idx_embeddings_hnsw ON embeddings 
USING hnsw (embedding halfvec_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Esto crea automÃ¡ticamente:
-- idx_embeddings_hnsw_rrhh
-- idx_embeddings_hnsw_callcenter
-- idx_embeddings_hnsw_legal
-- ... etc

-- Paso 4: Ãndice BM25 para bÃºsqueda hÃ­brida (opcional)
CREATE INDEX idx_embeddings_fts ON embeddings 
USING gin (to_tsvector('spanish', chunk_text));

-- ============================================================
-- EJEMPLO DE QUERY CON PARTITION PRUNING
-- ============================================================

EXPLAIN (ANALYZE, BUFFERS) 
SELECT doc_id, chunk_text, 
       1 - (embedding <=> $1::halfvec) AS similarity
FROM embeddings
WHERE area = 'RRHH'  -- â† Partition pruning aquÃ­
ORDER BY embedding <=> $1::halfvec
LIMIT 10;

-- Output del EXPLAIN mostrarÃ¡:
-- "Partition Pruning: RRHH"
-- Solo escanea embeddings_rrhh (37M vectores)
-- Ignora las otras 5 particiones (207M vectores)
```

### 7.4 EstimaciÃ³n de TamaÃ±o por ParticiÃ³n

Basado en la distribuciÃ³n estimada del corpus documental:

| Ãrea | % Docs | Vectores | $S_{table}$ | $S_{index}$ | RAM (20% hot) | Uso tÃ­pico |
|:-----|:------:|:--------:|:-----------:|:-----------:|:-------------:|:-----------|
| **RRHH** | 15% | ~37 M | ~56 GB | ~62 GB | ~12 GB | PolÃ­ticas, manuales empleado |
| **Call Center** | 25% | ~61 M | ~93 GB | ~103 GB | ~21 GB | KB, scripts, procedimientos |
| **Legal** | 10% | ~24 M | ~37 GB | ~41 GB | ~8 GB | Contratos, normativas |
| **Operaciones** | 20% | ~49 M | ~75 GB | ~83 GB | ~17 GB | Procesos, tÃ©cnicos |
| **Finanzas** | 15% | ~37 M | ~56 GB | ~62 GB | ~12 GB | Reportes, polÃ­ticas |
| **Otros** | 15% | ~36 M | ~55 GB | ~61 GB | ~12 GB | MiscelÃ¡neos |
| **TOTAL** | 100% | **~244 M** | **~372 GB** | **~412 GB** | **~82 GB** | â€” |

> ğŸ’¡ **Nota:** Con halfvec(768) + particionamiento, el tamaÃ±o total es ~784 GB de disco (mucho menor que los ~3 TB baseline).

### 7.5 Consideraciones para Queries Cross-Ãrea

Cuando un usuario necesita buscar en mÃºltiples Ã¡reas:

```sql
-- OpciÃ³n 1: Query directa (PostgreSQL escanea particiones necesarias)
SELECT * FROM embeddings
WHERE area IN ('RRHH', 'LEGAL')  -- Escanea 2 particiones
ORDER BY embedding <=> $1::halfvec
LIMIT 10;

-- OpciÃ³n 2: UNION ALL con lÃ­mites por particiÃ³n (mÃ¡s eficiente para top-K)
WITH ranked AS (
    SELECT *, 
           ROW_NUMBER() OVER (PARTITION BY area ORDER BY embedding <=> $1) as rn
    FROM embeddings
    WHERE area IN ('RRHH', 'LEGAL')
)
SELECT * FROM ranked WHERE rn <= 20  -- 20 por Ã¡rea
ORDER BY embedding <=> $1::halfvec
LIMIT 10;

-- OpciÃ³n 3: Federated search desde aplicaciÃ³n
-- (ejecutar queries paralelas y fusionar en cÃ³digo Python)
```

| PatrÃ³n de consulta | RecomendaciÃ³n |
|:-------------------|:--------------|
| 80%+ queries son single-area | âœ… Particionamiento altamente recomendado |
| 50-80% queries son single-area | âœ… Particionamiento recomendado |
| <50% queries son single-area | âš ï¸ Evaluar cuidadosamente |

---

## CapÃ­tulo 8: Cacheo SemÃ¡ntico

### 8.1 Arquitectura Multi-Nivel

> **Â¿Por quÃ© cache "semÃ¡ntico"?**
> 
> El cache tradicional requiere coincidencia **exacta** de la query.
> El cache semÃ¡ntico reconoce queries **semÃ¡nticamente similares**.
> 
> | Query | Cache Tradicional | Cache SemÃ¡ntico |
> |:------|:-----------------:|:---------------:|
> | "Â¿CuÃ¡l es la polÃ­tica de vacaciones?" | âœ… Hit | âœ… Hit |
> | "PolÃ­tica de vacaciones" | âŒ Miss | âœ… Hit (similar) |
> | "Â¿CuÃ¡ntos dÃ­as libres tengo?" | âŒ Miss | âœ… Hit (similar) |
> | "Dime sobre los dÃ­as de descanso" | âŒ Miss | âœ… Hit (similar) |

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ARQUITECTURA DE CACHE MULTI-NIVEL                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚
â”‚  â”‚   Query Usuario  â”‚  "Â¿CuÃ¡l es la polÃ­tica de vacaciones?"                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚
â”‚           â”‚                                                                  â”‚
â”‚           â–¼                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    NIVEL 1: EXACT MATCH CACHE                          â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  Key: hash(query)                                                       â”‚ â”‚
â”‚  â”‚  Backend: Redis String                                                  â”‚ â”‚
â”‚  â”‚  Latencia: ~1-3 ms                                                      â”‚ â”‚
â”‚  â”‚  Hit Rate esperado: ~30%                                                â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  â”Œâ”€ HIT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ Retornar respuesta cacheada inmediatamente                         â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚ MISS                                                             â”‚
â”‚           â–¼                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    NIVEL 2: SEMANTIC CACHE                              â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  1. Generar embedding de la query                                       â”‚ â”‚
â”‚  â”‚  2. Buscar queries similares en cache (similitud > 0.95)                â”‚ â”‚
â”‚  â”‚  Backend: Redis Vector Search (RediSearch)                              â”‚ â”‚
â”‚  â”‚  Latencia: ~10-20 ms                                                    â”‚ â”‚
â”‚  â”‚  Hit Rate esperado: ~40%                                                â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  â”Œâ”€ HIT (similitud > 0.95) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ Retornar respuesta de query similar                                â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚ MISS                                                             â”‚
â”‚           â–¼                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    NIVEL 3: EMBEDDING CACHE                             â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  Reutilizar embedding de query para evitar llamada a API               â”‚ â”‚
â”‚  â”‚  (ya lo generamos en Nivel 2)                                          â”‚ â”‚
â”‚  â”‚  Ahorro: ~$0.0001/query Ã— 10K queries/dÃ­a = ~$30/mes                   â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                                                                  â”‚
â”‚           â–¼                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    NIVEL 4: FULL RAG PIPELINE                           â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  1. Buscar en pgvector (~25ms)                                          â”‚ â”‚
â”‚  â”‚  2. Reranking con Cohere (~80ms)                                        â”‚ â”‚
â”‚  â”‚  3. Generar respuesta con Gemini (~1500ms)                              â”‚ â”‚
â”‚  â”‚  4. â¬‡ï¸ Guardar en cache (Nivel 1 + Nivel 2)                             â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  Latencia total: ~1,600 ms                                              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â”‚  RESULTADO                                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Hit Rate Combinado: 30% (L1) + 40% (L2) = ~67% de queries cacheadas    â”‚ â”‚
â”‚  â”‚ Latencia Promedio: 0.67 Ã— 15ms + 0.33 Ã— 1600ms = ~538 ms               â”‚ â”‚
â”‚  â”‚ Ahorro en LLM: ~67% menos llamadas = ~$500-800/mes                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.2 ImplementaciÃ³n con Redis

#### ConfiguraciÃ³n de Redis para Vector Search

```python
import redis
import numpy as np
from redis.commands.search.field import TextField, VectorField, TagField
from redis.commands.search.indexDefinition import IndexDefinition, IndexType
from redis.commands.search.query import Query
from typing import Optional
import hashlib

class SemanticCache:
    """
    Cache semÃ¡ntico multi-nivel con Redis.
    Implementa exact match + similarity search.
    """
    
    def __init__(
        self,
        redis_host: str = "localhost",
        redis_port: int = 6379,
        embedding_dim: int = 768,
        similarity_threshold: float = 0.95,
        ttl_seconds: int = 86400,  # 24 horas
    ):
        self.redis = redis.Redis(host=redis_host, port=redis_port, decode_responses=False)
        self.embedding_dim = embedding_dim
        self.similarity_threshold = similarity_threshold
        self.ttl = ttl_seconds
        self.index_name = "semantic_cache_idx"
        
        self._create_index()
    
    def _create_index(self):
        """Crea Ã­ndice de bÃºsqueda vectorial en Redis."""
        try:
            # Verificar si el Ã­ndice ya existe
            self.redis.ft(self.index_name).info()
        except:
            # Crear Ã­ndice
            schema = (
                TextField("query"),
                TextField("response"),
                TagField("area"),
                VectorField(
                    "embedding",
                    "HNSW",
                    {
                        "TYPE": "FLOAT32",
                        "DIM": self.embedding_dim,
                        "DISTANCE_METRIC": "COSINE",
                    }
                )
            )
            
            definition = IndexDefinition(
                prefix=["cache:"],
                index_type=IndexType.HASH
            )
            
            self.redis.ft(self.index_name).create_index(
                fields=schema,
                definition=definition
            )
    
    def _hash_query(self, query: str) -> str:
        """Genera hash determinÃ­stico de la query."""
        return hashlib.sha256(query.lower().strip().encode()).hexdigest()[:16]
    
    def get(self, query: str, query_embedding: np.ndarray, area: str = None) -> Optional[dict]:
        """
        Busca en cache: primero exact match, luego semantic.
        
        Returns:
            dict con 'response', 'source' (exact/semantic), 'similarity'
            None si no hay hit
        """
        query_hash = self._hash_query(query)
        
        # Nivel 1: Exact match
        exact_key = f"exact:{query_hash}"
        cached = self.redis.get(exact_key)
        if cached:
            return {
                "response": cached.decode(),
                "source": "exact",
                "similarity": 1.0
            }
        
        # Nivel 2: Semantic search
        vector_bytes = query_embedding.astype(np.float32).tobytes()
        
        q = (
            Query(f"*=>[KNN 1 @embedding $vec AS score]")
            .return_fields("query", "response", "score")
            .dialect(2)
        )
        
        if area:
            q = Query(f"@area:{{{area}}}=>[KNN 1 @embedding $vec AS score]")
        
        results = self.redis.ft(self.index_name).search(
            q,
            query_params={"vec": vector_bytes}
        )
        
        if results.docs:
            doc = results.docs[0]
            similarity = 1 - float(doc.score)  # Cosine distance â†’ similarity
            
            if similarity >= self.similarity_threshold:
                return {
                    "response": doc.response,
                    "source": "semantic",
                    "similarity": similarity,
                    "original_query": doc.query
                }
        
        return None
    
    def set(
        self,
        query: str,
        response: str,
        query_embedding: np.ndarray,
        area: str = "general"
    ):
        """Guarda query/response en ambos niveles de cache."""
        query_hash = self._hash_query(query)
        
        # Nivel 1: Exact match (string simple)
        exact_key = f"exact:{query_hash}"
        self.redis.setex(exact_key, self.ttl, response)
        
        # Nivel 2: Semantic cache (hash con vector)
        semantic_key = f"cache:{query_hash}"
        vector_bytes = query_embedding.astype(np.float32).tobytes()
        
        self.redis.hset(
            semantic_key,
            mapping={
                "query": query,
                "response": response,
                "area": area,
                "embedding": vector_bytes
            }
        )
        self.redis.expire(semantic_key, self.ttl)
    
    def invalidate_by_area(self, area: str):
        """Invalida todas las entradas de un Ã¡rea (ej: cuando cambian documentos)."""
        # Buscar todas las keys del Ã¡rea
        q = Query(f"@area:{{{area}}}").return_fields("query")
        results = self.redis.ft(self.index_name).search(q)
        
        for doc in results.docs:
            self.redis.delete(doc.id)
            query_hash = self._hash_query(doc.query)
            self.redis.delete(f"exact:{query_hash}")
```

#### Uso del Cache en el Pipeline RAG

```python
from semantic_cache import SemanticCache
from embedding_pipeline import OptimizedEmbeddingPipeline

class RAGPipeline:
    def __init__(self):
        self.cache = SemanticCache(
            redis_host="redis.internal",
            similarity_threshold=0.95,
            ttl_seconds=86400  # 24 horas
        )
        self.embedder = OptimizedEmbeddingPipeline(dimension=768)
    
    def query(self, user_query: str, area: str = None) -> dict:
        # Paso 1: Generar embedding de la query
        query_embedding = self.embedder.embed([user_query])[0]
        
        # Paso 2: Buscar en cache
        cached = self.cache.get(user_query, query_embedding, area)
        if cached:
            return {
                "response": cached["response"],
                "cached": True,
                "cache_source": cached["source"],
                "similarity": cached.get("similarity", 1.0)
            }
        
        # Paso 3: Cache miss â†’ ejecutar RAG completo
        response = self._full_rag_pipeline(user_query, query_embedding, area)
        
        # Paso 4: Guardar en cache
        self.cache.set(user_query, response, query_embedding, area or "general")
        
        return {
            "response": response,
            "cached": False
        }
    
    def _full_rag_pipeline(self, query: str, embedding: np.ndarray, area: str) -> str:
        # 1. Vector search en pgvector
        # 2. Reranking con Cohere
        # 3. GeneraciÃ³n con Gemini
        # ... implementaciÃ³n completa
        pass
```

---

### 8.3 PolÃ­ticas de Eviction

| PolÃ­tica | DescripciÃ³n | ConfiguraciÃ³n Redis | CuÃ¡ndo usar |
|:---------|:------------|:--------------------|:------------|
| **TTL (Time To Live)** | Expira despuÃ©s de N segundos | `EXPIRE key 86400` | Datos que cambian frecuentemente |
| **LRU (Least Recently Used)** | Elimina los menos usados recientemente | `maxmemory-policy allkeys-lru` | Memoria limitada |
| **LFU (Least Frequently Used)** | Elimina los menos usados en total | `maxmemory-policy allkeys-lfu` | Patrones estables de uso |
| **TTL + LRU** | Combina ambas estrategias | TTL por key + LRU global | â­ **Recomendado** |

#### ConfiguraciÃ³n Redis Recomendada

```conf
# redis.conf para cache semÃ¡ntico

# Memoria mÃ¡xima para cache (8 GB)
maxmemory 8gb

# PolÃ­tica de eviction: LRU cuando se llena
maxmemory-policy allkeys-lru

# Samples para LRU (mÃ¡s = mÃ¡s preciso, mÃ¡s lento)
maxmemory-samples 10

# MÃ³dulo de bÃºsqueda vectorial
loadmodule /path/to/redisearch.so
```

---

### 8.4 Impacto TeÃ³rico en Latencia

| Escenario | Sin Cache | Con Cache L1+L2 | Mejora |
|:----------|:---------:|:---------------:|:------:|
| **Latencia P50** | ~1,400 ms | ~15 ms | **-99%** |
| **Latencia P95 (cache hit)** | â€” | ~25 ms | â€” |
| **Latencia P95 (cache miss)** | ~2,200 ms | ~2,200 ms | Sin cambio |
| **Latencia promedio** | ~1,600 ms | ~538 ms | **-67%** |
| **Hit Rate esperado** | â€” | ~67% | â€” |

#### Impacto en Costos de API

| MÃ©trica | Sin Cache | Con Cache | Ahorro |
|:--------|:---------:|:---------:|:------:|
| **Llamadas LLM/dÃ­a** | ~10,000 | ~3,300 | -67% |
| **Costo LLM/mes** | ~$800 | ~$264 | **-$536** |
| **Llamadas Embedding/dÃ­a** | ~10,000 | ~3,300 | -67% |
| **Costo Embedding/mes** | ~$300 | ~$99 | **-$201** |
| **Total ahorro/mes** | â€” | â€” | **~$737** |

> ğŸ’¡ **Nota:** El cache semÃ¡ntico es una de las optimizaciones con **mejor ROI** porque reduce costos recurrentes de APIs sin impactar la calidad de las respuestas.

---
---

# SECCIÃ“N IV: TÃ‰CNICAS AVANZADAS DE RAG

Esta secciÃ³n presenta las tÃ©cnicas mÃ¡s actualizadas (2024-2025) para cada etapa del pipeline RAG, explicando cuÃ¡ndo y por quÃ© aplicar cada una segÃºn la naturaleza de los documentos.

---

## CapÃ­tulo 9: Estrategias de Chunking

El chunking determina cÃ³mo se fragmenta el texto antes de vectorizarlo. La elecciÃ³n correcta depende de la **naturaleza de los documentos** y tiene impacto directo en la calidad del retrieval y los costos.

### 9.1 Comparativa de TÃ©cnicas de Chunking

| TÃ©cnica | DescripciÃ³n | Complejidad | CuÃ¡ndo Usar |
|:--------|:------------|:-----------:|:------------|
| **Fixed Size** | Cortar cada N caracteres/tokens | Baja | Baseline, documentos homogÃ©neos |
| **Recursive** | Separadores jerÃ¡rquicos (pÃ¡rrafo â†’ oraciÃ³n â†’ palabra) | Media | â­ **Recomendado general** |
| **Sentence** | Una o mÃ¡s oraciones por chunk | Media | Documentos narrativos |
| **Semantic** | Detectar cambios de tema con embeddings | Alta | MÃ¡xima calidad, documentos complejos |
| **Agentic** | LLM decide cÃ³mo segmentar | Muy Alta | Documentos muy heterogÃ©neos |
| **Late Chunking** | Embeber primero, chunkear despuÃ©s | Alta | Documentos largos con contexto global |
| **Contextual** | Agregar resumen/contexto a cada chunk | Alta | Reducir fallos de retrieval |
| **Parent Document** | Chunks pequeÃ±os para buscar, doc grande para generar | Media | Balance precisiÃ³n/contexto |

---

### 9.2 Chunking SemÃ¡ntico

> **Â¿QuÃ© es?** Usa embeddings para detectar "cambios de tema" en el texto y cortar en esos puntos naturales de transiciÃ³n semÃ¡ntica.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CHUNKING SEMÃNTICO                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Documento:                                                      â”‚
â”‚  "La polÃ­tica de vacaciones establece... (tema A)                â”‚
â”‚   Los empleados pueden solicitar... (tema A)                     â”‚
â”‚   En cuanto a las licencias mÃ©dicas... (tema B) â† CAMBIO        â”‚
â”‚   El procedimiento para licencias... (tema B)"                   â”‚
â”‚                                                                  â”‚
â”‚           â”‚                                                      â”‚
â”‚           â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Calcular embeddings de cada oraciÃ³n                       â”‚   â”‚
â”‚  â”‚ Detectar donde similitud_coseno(sent_i, sent_i+1) < umbralâ”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â”‚                                                      â”‚
â”‚           â–¼                                                      â”‚
â”‚  Chunk 1: "La polÃ­tica de vacaciones... pueden solicitar..."    â”‚
â”‚  Chunk 2: "En cuanto a las licencias mÃ©dicas... procedimiento..."â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ImplementaciÃ³n

```python
from langchain_experimental.text_splitter import SemanticChunker
from langchain_google_vertexai import VertexAIEmbeddings

# Configurar chunker semÃ¡ntico con Gemini
embeddings = VertexAIEmbeddings(model_name="text-embedding-004")

splitter = SemanticChunker(
    embeddings=embeddings,
    breakpoint_threshold_type="percentile",  # o "standard_deviation", "interquartile"
    breakpoint_threshold_amount=95  # Umbral de corte (percentil 95)
)

# Aplicar chunking
chunks = splitter.split_text(document_text)
print(f"Generados {len(chunks)} chunks semÃ¡nticos")
```

#### Dependencias e Impacto

| Depende de... | Impacto |
|:--------------|:--------|
| **Coherencia del documento** | Funciona mejor en textos bien estructurados |
| **Modelo de embeddings** | Modelos mÃ¡s grandes detectan mejor los cambios |
| **Umbral de corte** | Umbral alto = chunks grandes, bajo = chunks pequeÃ±os |

**CuÃ¡ndo usarlo:**
- âœ… Documentos tÃ©cnicos con secciones claras
- âœ… Cuando la calidad es prioritaria sobre el costo
- âŒ NO usar en documentos muy cortos o conversacionales

---

### 9.3 Agentic Chunking

> **Â¿QuÃ© es?** Un LLM analiza el documento y decide cÃ³mo segmentarlo, como lo harÃ­a un humano experto al organizar informaciÃ³n.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AGENTIC CHUNKING                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Documento complejo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  (contrato legal mixto)      â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚       LLM        â”‚                          â”‚
â”‚                    â”‚  (Gemini/GPT-4)  â”‚                          â”‚
â”‚                    â”‚                  â”‚                          â”‚
â”‚                    â”‚ "Analiza este    â”‚                          â”‚
â”‚                    â”‚  documento y     â”‚                          â”‚
â”‚                    â”‚  divÃ­delo en     â”‚                          â”‚
â”‚                    â”‚  secciones       â”‚                          â”‚
â”‚                    â”‚  lÃ³gicas..."     â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                             â”‚                                    â”‚
â”‚                             â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Chunk 1: "Definiciones y partes del contrato"               â”‚â”‚
â”‚  â”‚ Chunk 2: "Obligaciones del empleador"                       â”‚â”‚
â”‚  â”‚ Chunk 3: "Obligaciones del empleado"                        â”‚â”‚
â”‚  â”‚ Chunk 4: "ClÃ¡usulas de confidencialidad"                    â”‚â”‚
â”‚  â”‚ Chunk 5: "TÃ©rminos de terminaciÃ³n"                          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ImplementaciÃ³n

```python
import json
from vertexai.generative_models import GenerativeModel

def agentic_chunk(document: str, max_chunks: int = 20) -> list[dict]:
    """
    Usa un LLM para segmentar inteligentemente un documento.
    Retorna chunks con metadata sobre el tema de cada uno.
    """
    model = GenerativeModel("gemini-1.5-pro")
    
    prompt = f"""
    Analiza el siguiente documento y divÃ­delo en secciones lÃ³gicas.
    
    Reglas:
    1. Cada secciÃ³n debe tratar UN solo tema coherente
    2. Cada secciÃ³n debe ser autocontenida (comprensible sin el resto)
    3. MÃ¡ximo {max_chunks} secciones
    4. Incluye un tÃ­tulo descriptivo para cada secciÃ³n
    
    Responde en JSON con este formato:
    [
        {{"titulo": "...", "contenido": "...", "tema_principal": "..."}},
        ...
    ]
    
    Documento:
    {document[:50000]}  # Limitar a 50K chars
    """
    
    response = model.generate_content(prompt)
    
    # Parsear JSON de la respuesta
    try:
        chunks = json.loads(response.text)
        return chunks
    except json.JSONDecodeError:
        # Fallback: retornar documento completo
        return [{"titulo": "Documento", "contenido": document, "tema_principal": "general"}]

# Uso
chunks = agentic_chunk(contract_text)
for chunk in chunks:
    print(f"[{chunk['tema_principal']}] {chunk['titulo'][:50]}...")
```

#### Dependencias e Impacto

| Depende de... | Impacto |
|:--------------|:--------|
| **Calidad del LLM** | Modelos mÃ¡s capaces producen mejor segmentaciÃ³n |
| **Costo** | Cada documento requiere una llamada al LLM (~$0.01-0.10/doc) |
| **Latencia de ingestiÃ³n** | Significativamente mÃ¡s lenta (2-10s/documento) |

**CuÃ¡ndo usarlo:**
- âœ… Documentos muy heterogÃ©neos (contratos, informes mixtos)
- âœ… IngestiÃ³n batch donde latencia no importa
- âŒ NO usar para millones de documentos (muy costoso)

---

### 9.4 Late Chunking

> **Â¿QuÃ© es?** En lugar de chunkear y luego embeber, primero se procesa el documento completo con un modelo de contexto largo, preservando la informaciÃ³n global en cada chunk.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      LATE CHUNKING                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  MÃ‰TODO TRADICIONAL:                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                            â”‚
â”‚  Documento â”€â”€â†’ [Chunk1, Chunk2, Chunk3] â”€â”€â†’ [Emb1, Emb2, Emb3]   â”‚
â”‚                    (chunking primero)      (embeddings despuÃ©s)  â”‚
â”‚                                                                  â”‚
â”‚      âš ï¸ Problema: Cada chunk pierde el contexto del documento   â”‚
â”‚                                                                  â”‚
â”‚  LATE CHUNKING:                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                  â”‚
â”‚  Documento â”€â”€â†’ Encoder (contexto largo) â”€â”€â†’ [Token embeddings]   â”‚
â”‚                      (8K-32K tokens)         (por cada token)    â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â–¼                                     â”‚
â”‚               Pooling por regiones del texto                     â”‚
â”‚                            â”‚                                     â”‚
â”‚                            â–¼                                     â”‚
â”‚            [Emb1+contexto, Emb2+contexto, Emb3+contexto]         â”‚
â”‚                                                                  â”‚
â”‚      âœ… Beneficio: Cada chunk "sabe" del documento completo      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Dependencias e Impacto

| Depende de... | Impacto |
|:--------------|:--------|
| **Longitud del documento** | Ideal para documentos >8K tokens |
| **Modelo de embeddings** | Requiere modelos con contexto largo (Jina-v3, etc.) |
| **RAM disponible** | Procesar documentos largos consume mÃ¡s memoria |

**CuÃ¡ndo usarlo:**
- âœ… Documentos largos donde el contexto global importa (informes, papers)
- âœ… Cuando un chunk puede perder significado sin el resto
- âŒ NO usar para documentos cortos (overhead innecesario)

---

### 9.5 Parent Document Retriever

> **Â¿QuÃ© es?** Usa chunks pequeÃ±os para la bÃºsqueda (mÃ¡s precisa), pero devuelve el documento padre (mÃ¡s contexto) para la generaciÃ³n.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PARENT DOCUMENT RETRIEVER                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  INGESTIÃ“N:                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                      â”‚
â”‚                                                                  â”‚
â”‚  Documento completo (10 pÃ¡ginas, 15K tokens)                     â”‚
â”‚       â”‚                                                          â”‚
â”‚       â”œâ”€â”€â†’ Guardar en Document Store (GCS)                       â”‚
â”‚       â”‚         doc_id: "DOC001"                                 â”‚
â”‚       â”‚                                                          â”‚
â”‚       â””â”€â”€â†’ Crear chunks pequeÃ±os para bÃºsqueda:                  â”‚
â”‚             â”œâ”€â”€ Chunk 1 (500 tok) â†’ embedding â†’ pgvector         â”‚
â”‚             â”‚   metadata: {parent_id: "DOC001", position: 0}     â”‚
â”‚             â”œâ”€â”€ Chunk 2 (500 tok) â†’ embedding â†’ pgvector         â”‚
â”‚             â”‚   metadata: {parent_id: "DOC001", position: 1}     â”‚
â”‚             â””â”€â”€ Chunk 3 (500 tok) â†’ embedding â†’ pgvector         â”‚
â”‚                 metadata: {parent_id: "DOC001", position: 2}     â”‚
â”‚                                                                  â”‚
â”‚  BÃšSQUEDA:                                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚
â”‚                                                                  â”‚
â”‚  Query: "polÃ­tica de licencias"                                  â”‚
â”‚       â”‚                                                          â”‚
â”‚       â–¼                                                          â”‚
â”‚  Vector Search â”€â”€â†’ Match: Chunk 2 (score: 0.92)                  â”‚
â”‚       â”‚                                                          â”‚
â”‚       â–¼                                                          â”‚
â”‚  Recuperar parent_id: "DOC001"                                   â”‚
â”‚       â”‚                                                          â”‚
â”‚       â–¼                                                          â”‚
â”‚  Cargar documento completo desde GCS                             â”‚
â”‚       â”‚                                                          â”‚
â”‚       â–¼                                                          â”‚
â”‚  Enviar documento completo (15K tok) al LLM                      â”‚
â”‚                                                                  â”‚
â”‚  âœ… Beneficio: BÃºsqueda precisa + Contexto completo              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Dependencias e Impacto

| Depende de... | Impacto |
|:--------------|:--------|
| **Ventana de contexto del LLM** | Documentos padres deben caber en el contexto |
| **PrecisiÃ³n vs. contexto** | Chunks mÃ¡s pequeÃ±os = mejor match, docs padres = mejor respuesta |
| **Almacenamiento** | Requiere guardar chunks + referencias a padres |

**CuÃ¡ndo usarlo:**
- âœ… Cuando la precisiÃ³n de bÃºsqueda Y el contexto son importantes
- âœ… Documentos con estructura jerÃ¡rquica (manuales, libros)
- âŒ NO usar si los documentos son muy cortos

---

### 9.6 Matriz de DecisiÃ³n: Â¿QuÃ© Chunking Usar?

| Tipo de Documento | Estrategia Recomendada | TamaÃ±o Chunk | Overlap |
|:------------------|:----------------------:|:------------:|:-------:|
| **FAQs, Q&A** | Fixed/Sentence | 256-512 tokens | 0% |
| **Emails, tickets** | Sentence | 128-256 tokens | 10% |
| **Manuales tÃ©cnicos** | Recursive | 512-1024 tokens | 15% |
| **PolÃ­ticas, normativas** | Semantic | 512-1024 tokens | 20% |
| **Contratos legales** | Agentic + Parent | 256 (child) / Full (parent) | 25% |
| **Informes largos** | Late Chunking | 1024-2048 tokens | 15% |
| **Papers cientÃ­ficos** | Semantic + Contextual | 512-1024 tokens | 20% |
| **Presentaciones (PPT)** | Page-based | 1 slide | 0% |
| **Documentos mixtos** | Agentic | Variable | Variable |

---

### 9.7 Impacto del Overlap en Costos

El overlap (solapamiento entre chunks) mejora el contexto pero aumenta el nÃºmero de vectores:

| Overlap | Factor de Vectores | Vectores (17 TB) | Impacto en Costo |
|:-------:|:------------------:|:----------------:|:----------------:|
| **0%** | 1.00x | ~220 M | Baseline |
| **10%** | 1.11x | ~244 M | +11% almacenamiento |
| **15%** | 1.18x | ~260 M | +18% almacenamiento |
| **20%** | 1.25x | ~275 M | +25% almacenamiento |
| **25%** | 1.33x | ~293 M | +33% almacenamiento |
| **50%** | 2.00x | ~440 M | âš ï¸ +100% almacenamiento |

> ğŸ’¡ **RecomendaciÃ³n:** Usar **10-15% overlap** como default. Solo aumentar a 20-25% para documentos donde el contexto entre chunks es crÃ­tico (legal, tÃ©cnico).

---

## CapÃ­tulo 10: Modelos de Embedding

La elecciÃ³n del modelo de embedding impacta directamente en la calidad de bÃºsqueda, costos y latencia.

### 10.1 Comparativa de Modelos 2024-2025

| Modelo | Proveedor | DimensiÃ³n | MultilingÃ¼e | Matryoshka | Contexto | Costo | CuÃ¡ndo Usar |
|:-------|:----------|:---------:|:-----------:|:----------:|:--------:|:-----:|:------------|
| **Gemini text-embedding-004** | Google | 768-3072 | âœ… | âœ… | 2K | $ | â­ Ecosistema GCP |
| OpenAI text-embedding-3-large | OpenAI | 3072 | âœ… | âœ… | 8K | $$ | MÃ¡xima calidad |
| OpenAI text-embedding-3-small | OpenAI | 1536 | âœ… | âœ… | 8K | $ | Balance costo/calidad |
| **Cohere embed-v3** | Cohere | 1024 | âœ… 100+ | âœ… | 512 | $ | â­ MultilingÃ¼e |
| Voyage AI voyage-3 | Voyage | 1024 | âœ… | âœ… | 32K | $$ | Contexto muy largo |
| BGE-M3 | BAAI | 1024 | âœ… 100+ | âŒ | 8K | Gratis | Open source |
| E5-mistral-7b-instruct | Intfloat | 4096 | âœ… | âŒ | 32K | Gratis | Local, alta calidad |
| NV-Embed-v2 | NVIDIA | 4096 | âœ… | âœ… | 32K | Gratis | GPU local |
| Jina-embeddings-v3 | Jina AI | 1024 | âœ… | âœ… | 8K | $ | Late chunking |

#### MTEB Leaderboard (Referencia)

> El [MTEB Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) es el benchmark estÃ¡ndar para comparar modelos de embeddings. Los modelos listados arriba estÃ¡n entre los top performers.

---

### 10.2 Tipos de InteracciÃ³n en Embeddings

| Tipo | DescripciÃ³n | Ejemplos | Trade-off |
|:-----|:------------|:---------|:----------|
| **Bi-Encoder** | Query y Doc se embeben por separado | OpenAI, Cohere, Gemini, BGE | RÃ¡pido (~5ms), menos preciso |
| **Cross-Encoder** | Query + Doc se procesan juntos | Cohere Rerank, BGE-reranker | Lento (~100ms), muy preciso |
| **Late Interaction** | Tokens embebidos separados, comparaciÃ³n token-a-token | ColBERT, Jina-ColBERT | Balance velocidad/precisiÃ³n |

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              COMPARACIÃ“N DE ARQUITECTURAS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  BI-ENCODER (single vector):                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  Query â”€â”€â†’ [Encoder] â”€â”€â†’ [1 vector] â†â”€â”€cosineâ”€â”€â†’ [1 vector]     â”‚
â”‚  Doc   â”€â”€â†’ [Encoder] â”€â”€â†’ [1 vector]              (precomputado) â”‚
â”‚                                                                  â”‚
â”‚  âœ… RÃ¡pido: O(1) comparaciÃ³n                                     â”‚
â”‚  âŒ Menos preciso para queries complejas                         â”‚
â”‚                                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                  â”‚
â”‚  CROSS-ENCODER (attention jointly):                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚  [Query + Doc] â”€â”€â†’ [Transformer completo] â”€â”€â†’ Relevance Score    â”‚
â”‚                                                                  â”‚
â”‚  âœ… Muy preciso: considera interacciones query-doc               â”‚
â”‚  âŒ Lento: no se puede precomputar                               â”‚
â”‚                                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                  â”‚
â”‚  LATE INTERACTION (multi-vector):                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚  Query â”€â”€â†’ [n vectores] â†â”€â”€MaxSimâ”€â”€â†’ [m vectores] â† Doc         â”‚
â”‚            (por token)               (por token)                 â”‚
â”‚                                                                  â”‚
â”‚  âœ… Balance: mÃ¡s preciso que bi-encoder, mÃ¡s rÃ¡pido que cross    â”‚
â”‚  âŒ MÃ¡s almacenamiento (~10-100x mÃ¡s vectores)                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 10.3 ColBERT y Multi-Vector

> **Â¿QuÃ© es ColBERT?** En lugar de un solo vector por documento, genera un vector por cada token. La similitud se calcula comparando todos los tokens de la query con todos los del documento usando MaxSim.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ColBERT / MaxSim                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Query: "polÃ­tica vacaciones"                                    â”‚
â”‚         â†“                                                        â”‚
â”‚  Query Tokens: ["polÃ­tica", "vacaciones"]                        â”‚
â”‚         â†“                                                        â”‚
â”‚  Query Embeddings: [v_pol, v_vac]  (2 vectores)                  â”‚
â”‚                                                                  â”‚
â”‚  Document: "Los empleados tienen derecho a vacaciones anuales"   â”‚
â”‚         â†“                                                        â”‚
â”‚  Doc Tokens: ["empleados", "derecho", "vacaciones", "anuales"]   â”‚
â”‚         â†“                                                        â”‚
â”‚  Doc Embeddings: [v_emp, v_der, v_vac, v_anu]  (4 vectores)      â”‚
â”‚                                                                  â”‚
â”‚  MaxSim Score:                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚  Para cada query token, encontrar el doc token mÃ¡s similar:      â”‚
â”‚                                                                  â”‚
â”‚  score = max_sim(v_pol, doc_vectors) + max_sim(v_vac, doc_vectors)â”‚
â”‚        = sim(v_pol, v_emp) + sim(v_vac, v_vac)                   â”‚
â”‚        = 0.3 + 1.0 = 1.3                                         â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Dependencias e Impacto

| Depende de... | Impacto |
|:--------------|:--------|
| **Almacenamiento** | ~10-100x mÃ¡s espacio que bi-encoder (un vector por token) |
| **Latencia** | MÃ¡s lento en bÃºsqueda, pero reranking es rÃ¡pido |
| **PrecisiÃ³n** | +5-15% vs. bi-encoder en tareas difÃ­ciles |

**CuÃ¡ndo usarlo:**
- âœ… Cuando la precisiÃ³n es crÃ­tica (legal, mÃ©dico)
- âœ… Como segunda etapa despuÃ©s de bi-encoder
- âŒ NO usar como Ãºnica etapa para millones de documentos

---

### 10.4 Matriz de DecisiÃ³n: Â¿QuÃ© Modelo Usar?

| Escenario | Modelo Recomendado | DimensiÃ³n | RazÃ³n |
|:----------|:-------------------|:---------:|:------|
| **ProducciÃ³n en GCP** | Gemini text-embedding-004 | 768 | IntegraciÃ³n nativa, Matryoshka |
| **MultilingÃ¼e crÃ­tico** | Cohere embed-v3 | 1024 | Mejor en espaÃ±ol/otros idiomas |
| **On-premise/local** | BGE-M3 o E5-mistral | 1024+ | Open source, sin costos de API |
| **MÃ¡xima calidad** | OpenAI 3-large + Cohere Rerank | 1536 | SOTA actual en benchmarks |
| **Presupuesto limitado** | BGE-M3 + halfvec | 512 | Open source + compresiÃ³n |
| **Documentos >8K tokens** | Voyage AI voyage-3 | 1024 | Contexto 32K nativo |
| **PrecisiÃ³n extrema** | ColBERT/Jina-ColBERT-v2 | Multi | Late interaction |

---

### 10.5 RecomendaciÃ³n para el Proyecto

Para el caso de **17 TB de documentaciÃ³n corporativa en espaÃ±ol/inglÃ©s** con ecosistema GCP:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 CONFIGURACIÃ“N RECOMENDADA                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Modelo:        Gemini text-embedding-004                        â”‚
â”‚  DimensiÃ³n:     768 (Matryoshka truncation)                      â”‚
â”‚  PrecisiÃ³n:     halfvec (float16)                                â”‚
â”‚                                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                  â”‚
â”‚  ğŸ“Š MÃ‰TRICAS RESULTANTES:                                        â”‚
â”‚                                                                  â”‚
â”‚  â€¢ Disco total:     ~1.1 TB (vs. 3.0 TB baseline)                â”‚
â”‚  â€¢ RAM requerida:   ~90 GB (vs. 240 GB baseline)                 â”‚
â”‚  â€¢ Calidad:         ~97.5% del recall baseline                   â”‚
â”‚  â€¢ MultilingÃ¼e:     âœ… Nativo (espaÃ±ol, inglÃ©s, otros)           â”‚
â”‚  â€¢ IntegraciÃ³n GCP: âœ… Directa (Vertex AI)                       â”‚
â”‚  â€¢ Costo embedding: ~$500-700/mes (ingestiÃ³n completa)           â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## CapÃ­tulo 11: TÃ©cnicas de BÃºsqueda

La bÃºsqueda vectorial bÃ¡sica puede mejorarse significativamente con tÃ©cnicas adicionales que combinan mÃºltiples seÃ±ales.

### 11.1 Comparativa de TÃ©cnicas de BÃºsqueda

| TÃ©cnica | DescripciÃ³n | Mejora TÃ­pica | Latencia Adicional | Complejidad |
|:--------|:------------|:-------------:|:------------------:|:-----------:|
| **Vector puro** | Solo similitud de embeddings | Baseline | 0 | Baja |
| **BM25 puro** | Solo keywords (sparse) | -20% vs. vector | ~5ms | Baja |
| **Hybrid (Vector + BM25)** | Combina ambos con RRF | +10-20% | ~10ms | Media |
| **Reranking** | Cross-encoder reordena top-K | +15-25% | ~100ms | Media |
| **HyDE** | LLM genera doc hipotÃ©tico | +10-20% | ~500-2000ms | Alta |
| **Query Expansion** | LLM genera queries alternativos | +5-15% | ~200ms | Media |
| **Multi-Query** | MÃºltiples queries â†’ uniÃ³n | +10-15% | ~100ms | Media |

---

### 11.2 BÃºsqueda HÃ­brida (Hybrid Search)

> **Â¿QuÃ© es?** Combina bÃºsqueda por palabras clave (BM25/sparse) con bÃºsqueda semÃ¡ntica (dense vectors) para obtener lo mejor de ambos mundos.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BÃšSQUEDA HÃBRIDA                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Query: "polÃ­tica de vacaciones 2024"                            â”‚
â”‚                          â”‚                                       â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚          â–¼                               â–¼                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚    BM25       â”‚              â”‚   Vector      â”‚                â”‚
â”‚  â”‚  (keywords)   â”‚              â”‚  (semÃ¡ntico)  â”‚                â”‚
â”‚  â”‚               â”‚              â”‚               â”‚                â”‚
â”‚  â”‚ "polÃ­tica"    â”‚              â”‚ embedding de  â”‚                â”‚
â”‚  â”‚ "vacaciones"  â”‚              â”‚ la query      â”‚                â”‚
â”‚  â”‚ "2024"        â”‚              â”‚               â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚          â”‚                               â”‚                       â”‚
â”‚          â–¼                               â–¼                       â”‚
â”‚  [Doc A: 0.8]                    [Doc C: 0.9]                    â”‚
â”‚  [Doc B: 0.6]                    [Doc A: 0.7]                    â”‚
â”‚  [Doc D: 0.5]                    [Doc B: 0.6]                    â”‚
â”‚          â”‚                               â”‚                       â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                          â–¼                                       â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚          â”‚   Reciprocal Rank Fusion      â”‚                       â”‚
â”‚          â”‚           (RRF)               â”‚                       â”‚
â”‚          â”‚                               â”‚                       â”‚
â”‚          â”‚   score = Î£ 1/(k + rank_i)    â”‚                       â”‚
â”‚          â”‚   donde k = 60 (constante)    â”‚                       â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                          â–¼                                       â”‚
â”‚          [Doc A: rank 1] â† Aparece en ambos (reforzado)          â”‚
â”‚          [Doc C: rank 2]                                         â”‚
â”‚          [Doc B: rank 3]                                         â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ImplementaciÃ³n en PostgreSQL

```sql
-- ============================================================
-- PREPARACIÃ“N: Crear Ã­ndice GIN para BM25 (tsvector)
-- ============================================================
ALTER TABLE embeddings ADD COLUMN IF NOT EXISTS tsv tsvector 
    GENERATED ALWAYS AS (to_tsvector('spanish', chunk_text)) STORED;

CREATE INDEX IF NOT EXISTS idx_embeddings_tsv ON embeddings USING GIN(tsv);

-- ============================================================
-- QUERY HÃBRIDA CON RRF (Reciprocal Rank Fusion)
-- ============================================================
-- Input: $1 = query_embedding (vector), $2 = query_text (string)

WITH 
-- BÃºsqueda vectorial: top 30 por similitud coseno
vector_results AS (
    SELECT 
        id,
        doc_id,
        chunk_text,
        1 - (embedding <=> $1::halfvec) AS vector_score,
        ROW_NUMBER() OVER (ORDER BY embedding <=> $1::halfvec) AS vector_rank
    FROM embeddings
    WHERE area = $3  -- Partition pruning (opcional)
    ORDER BY embedding <=> $1::halfvec 
    LIMIT 30
),
-- BÃºsqueda BM25: top 30 por relevancia de keywords
bm25_results AS (
    SELECT 
        id,
        doc_id,
        chunk_text,
        ts_rank_cd(tsv, plainto_tsquery('spanish', $2)) AS bm25_score,
        ROW_NUMBER() OVER (ORDER BY ts_rank_cd(tsv, plainto_tsquery('spanish', $2)) DESC) AS bm25_rank
    FROM embeddings
    WHERE tsv @@ plainto_tsquery('spanish', $2)
      AND area = $3  -- Partition pruning (opcional)
    ORDER BY ts_rank_cd(tsv, plainto_tsquery('spanish', $2)) DESC 
    LIMIT 30
),
-- Combinar con RRF
combined AS (
    SELECT 
        COALESCE(v.id, b.id) AS id,
        COALESCE(v.doc_id, b.doc_id) AS doc_id,
        COALESCE(v.chunk_text, b.chunk_text) AS chunk_text,
        v.vector_score,
        b.bm25_score,
        -- RRF: k=60 es el valor estÃ¡ndar
        COALESCE(1.0 / (60 + v.vector_rank), 0) + 
        COALESCE(1.0 / (60 + b.bm25_rank), 0) AS rrf_score
    FROM vector_results v
    FULL OUTER JOIN bm25_results b ON v.id = b.id
)
SELECT 
    id,
    doc_id,
    chunk_text,
    vector_score,
    bm25_score,
    rrf_score
FROM combined
ORDER BY rrf_score DESC
LIMIT 20;
```

#### Dependencias e Impacto

| Depende de... | Impacto |
|:--------------|:--------|
| **Tipo de query** | Queries con tÃ©rminos tÃ©cnicos se benefician mÃ¡s de BM25 |
| **Vocabulario del dominio** | Jerga especÃ­fica requiere BM25 |
| **Constante k de RRF** | Ajustar k (default 60) segÃºn resultados |

**CuÃ¡ndo usarlo:**
- âœ… **Siempre como default en producciÃ³n**
- âœ… Cuando hay tÃ©rminos tÃ©cnicos o nombres propios
- âœ… Cuando el recall es importante

---

### 11.3 Reranking con Cross-Encoder

> **Â¿QuÃ© es?** DespuÃ©s de recuperar top-K documentos con bÃºsqueda rÃ¡pida (bi-encoder), un modelo mÃ¡s preciso (pero lento) los reordena analizando query+doc juntos.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE CON RERANKING                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Query: "Â¿CuÃ¡ntos dÃ­as de vacaciones tengo?"                     â”‚
â”‚       â”‚                                                          â”‚
â”‚       â–¼                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚ Hybrid Search   â”‚  (~25ms)                                    â”‚
â”‚  â”‚ (Vector + BM25) â”‚                                             â”‚
â”‚  â”‚                 â”‚                                             â”‚
â”‚  â”‚ Recall alto,    â”‚                                             â”‚
â”‚  â”‚ precisiÃ³n media â”‚                                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚           â”‚                                                      â”‚
â”‚           â–¼                                                      â”‚
â”‚  Top 50 documentos candidatos                                    â”‚
â”‚           â”‚                                                      â”‚
â”‚           â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚ Cross-Encoder   â”‚  (~100ms)                                   â”‚
â”‚  â”‚    Reranker     â”‚                                             â”‚
â”‚  â”‚                 â”‚                                             â”‚
â”‚  â”‚ (Cohere, BGE,   â”‚                                             â”‚
â”‚  â”‚  Jina, etc.)    â”‚                                             â”‚
â”‚  â”‚                 â”‚                                             â”‚
â”‚  â”‚ PrecisiÃ³n alta  â”‚                                             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚           â”‚                                                      â”‚
â”‚           â–¼                                                      â”‚
â”‚  Top 10 documentos rerankeados                                   â”‚
â”‚           â”‚                                                      â”‚
â”‚           â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚  â”‚  LLM Generation â”‚  (~1500ms)                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Modelos de Reranking

| Modelo | Tipo | Latencia (50 docs) | Calidad | Costo |
|:-------|:-----|:------------------:|:-------:|:-----:|
| **Cohere Rerank 3** | API | ~100ms | â­â­â­â­â­ | $0.001/search |
| BGE-reranker-v2-m3 | Local | ~150ms | â­â­â­â­ | Gratis (GPU) |
| Jina Reranker v2 | API/Local | ~80ms | â­â­â­â­ | $ |
| GPT-4 as reranker | API | ~500ms | â­â­â­â­â­ | $$$$ |
| Gemini as reranker | API | ~400ms | â­â­â­â­ | $$ |

#### ImplementaciÃ³n con Cohere

```python
import cohere
from typing import List, Dict

class CohereReranker:
    """Reranker usando Cohere API."""
    
    def __init__(self, api_key: str):
        self.client = cohere.Client(api_key=api_key)
        self.model = "rerank-multilingual-v3.0"  # Mejor para espaÃ±ol
    
    def rerank(
        self, 
        query: str, 
        documents: List[str], 
        top_n: int = 10,
        return_documents: bool = True
    ) -> List[Dict]:
        """
        Reordena documentos por relevancia a la query.
        
        Args:
            query: Query del usuario
            documents: Lista de textos a reordenar
            top_n: NÃºmero de resultados a retornar
            return_documents: Si incluir el texto en la respuesta
            
        Returns:
            Lista de dicts con {index, relevance_score, text?}
        """
        response = self.client.rerank(
            model=self.model,
            query=query,
            documents=documents,
            top_n=top_n,
            return_documents=return_documents
        )
        
        return [
            {
                "index": result.index,
                "relevance_score": result.relevance_score,
                "text": documents[result.index] if return_documents else None
            }
            for result in response.results
        ]

# Uso en el pipeline
reranker = CohereReranker(api_key="...")

# DespuÃ©s de hybrid search
candidates = hybrid_search(query, top_k=50)
candidate_texts = [doc["chunk_text"] for doc in candidates]

# Reranking
reranked = reranker.rerank(query, candidate_texts, top_n=10)

# Reordenar candidatos segÃºn reranking
final_docs = [candidates[r["index"]] for r in reranked]
```

#### CuÃ¡ndo usar Reranking

- âœ… Siempre que la latencia lo permita (+100ms disponibles)
- âœ… Cuando la precisiÃ³n es mÃ¡s importante que la velocidad
- âœ… Para Ã¡reas crÃ­ticas (Legal, Finanzas)
- âŒ NO usar para autocompletado (<50ms total)
- âŒ NO usar para Call Center (velocidad prioritaria)

---

### 11.4 HyDE (Hypothetical Document Embeddings)

> **Â¿QuÃ© es?** En lugar de embeber la query directamente, un LLM genera un "documento hipotÃ©tico" que responderÃ­a la pregunta, y se embede ESE documento.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          HyDE                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  MÃ‰TODO TRADICIONAL:                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚  Query â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Embedding â†’ Searchâ”‚
â”‚  "Â¿CuÃ¡ntos dÃ­as de vacaciones tengo?"                            â”‚
â”‚                                                                  â”‚
â”‚  âš ï¸ Problema: El embedding de una pregunta es diferente al      â”‚
â”‚               embedding de un documento que la responde          â”‚
â”‚                                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                  â”‚
â”‚  MÃ‰TODO HyDE:                                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                    â”‚
â”‚  Query â”€â”€â†’ LLM genera â”€â”€â†’ Doc HipotÃ©tico â”€â”€â†’ Embedding â”€â”€â†’ Searchâ”‚
â”‚            respuesta                                             â”‚
â”‚                                                                  â”‚
â”‚  Query: "Â¿CuÃ¡ntos dÃ­as de vacaciones tengo?"                     â”‚
â”‚                    â”‚                                             â”‚
â”‚                    â–¼                                             â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚          â”‚       LLM       â”‚                                     â”‚
â”‚          â”‚   (Gemini Pro)  â”‚                                     â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â”‚                   â”‚                                              â”‚
â”‚                   â–¼                                              â”‚
â”‚  Doc HipotÃ©tico:                                                 â”‚
â”‚  "Los empleados con mÃ¡s de un aÃ±o de antigÃ¼edad tienen          â”‚
â”‚   derecho a 15 dÃ­as hÃ¡biles de vacaciones anuales,               â”‚
â”‚   incrementÃ¡ndose en 2 dÃ­as adicionales por cada 5 aÃ±os          â”‚
â”‚   de servicio. Las vacaciones deben solicitarse con              â”‚
â”‚   al menos 15 dÃ­as de anticipaciÃ³n..."                           â”‚
â”‚                   â”‚                                              â”‚
â”‚                   â–¼                                              â”‚
â”‚          [Embedding del doc hipotÃ©tico]                          â”‚
â”‚                   â”‚                                              â”‚
â”‚                   â–¼ (mÃ¡s similar a docs reales!)                 â”‚
â”‚             Vector Search                                        â”‚
â”‚                                                                  â”‚
â”‚  âœ… Beneficio: El embedding es mÃ¡s similar a documentos reales   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### CuÃ¡ndo usar HyDE

- âœ… Queries vagas o mal formuladas por usuarios no expertos
- âœ… Cuando el gap semÃ¡ntico queryâ†’documento es grande
- âœ… Procesamiento batch donde latencia no es crÃ­tica
- âŒ NO usar en tiempo real (aÃ±ade ~500ms-2s)
- âŒ NO usar si queries son claras y especÃ­ficas

---

### 11.5 Multi-Query Retrieval

> **Â¿QuÃ© es?** Genera mÃºltiples variantes de la query (usando LLM) y busca con todas, luego combina resultados con RRF.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MULTI-QUERY RETRIEVAL                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Query original: "polÃ­tica de vacaciones"                        â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                  â”‚      LLM      â”‚                               â”‚
â”‚                  â”‚   (Gemini)    â”‚                               â”‚
â”‚                  â”‚               â”‚                               â”‚
â”‚                  â”‚ "Genera 4     â”‚                               â”‚
â”‚                  â”‚  variantes    â”‚                               â”‚
â”‚                  â”‚  de esta      â”‚                               â”‚
â”‚                  â”‚  query..."    â”‚                               â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Query 1: "polÃ­tica de vacaciones"                          â”‚  â”‚
â”‚  â”‚ Query 2: "dÃ­as libres empleados"                           â”‚  â”‚
â”‚  â”‚ Query 3: "derecho a descanso anual"                        â”‚  â”‚
â”‚  â”‚ Query 4: "licencia por vacaciones"                         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚          BÃºsqueda paralela con las 4 queries                     â”‚
â”‚                          â”‚                                       â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚          â–¼               â–¼               â–¼                       â”‚
â”‚       [Docs Q1]       [Docs Q2]       [Docs Q3]                  â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚              UniÃ³n + RRF (Reciprocal Rank Fusion)                â”‚
â”‚                          â”‚                                       â”‚
â”‚                          â–¼                                       â”‚
â”‚                  Top 10 documentos                               â”‚
â”‚          (mejor recall por diversidad de queries)                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### CuÃ¡ndo usar Multi-Query

- âœ… Queries de usuarios no expertos
- âœ… Cuando el recall es prioritario sobre latencia
- âœ… Queries ambiguas que pueden interpretarse de varias formas
- âŒ NO usar si queries son muy especÃ­ficas (ya estÃ¡n claras)

---

### 11.6 Pipeline Recomendado

Basado en el anÃ¡lisis de 17 TB de documentaciÃ³n corporativa:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PIPELINE RAG OPTIMIZADO                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚  INGESTIÃ“N (offline, batch)                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚                                                                              â”‚
â”‚  Documento â”€â”€â†’ ClasificaciÃ³n â”€â”€â†’ Chunking Adaptativo â”€â”€â†’ Embedding 768d     â”‚
â”‚       â”‚              â”‚                    â”‚                    â”‚             â”‚
â”‚       â”‚              â–¼                    â–¼                    â–¼             â”‚
â”‚       â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚       â”‚    â”‚ IF tipo = Legal/Contrato:                                    â”‚ â”‚
â”‚       â”‚    â”‚    â†’ Agentic chunking + Parent Document                      â”‚ â”‚
â”‚       â”‚    â”‚    â†’ Overlap 25%                                             â”‚ â”‚
â”‚       â”‚    â”‚                                                              â”‚ â”‚
â”‚       â”‚    â”‚ ELIF tipo = Manual tÃ©cnico:                                  â”‚ â”‚
â”‚       â”‚    â”‚    â†’ Recursive chunking (1024 tokens)                        â”‚ â”‚
â”‚       â”‚    â”‚    â†’ Overlap 15%                                             â”‚ â”‚
â”‚       â”‚    â”‚                                                              â”‚ â”‚
â”‚       â”‚    â”‚ ELIF tipo = FAQ/KB:                                          â”‚ â”‚
â”‚       â”‚    â”‚    â†’ Sentence chunking (256 tokens)                          â”‚ â”‚
â”‚       â”‚    â”‚    â†’ Overlap 0%                                              â”‚ â”‚
â”‚       â”‚    â”‚                                                              â”‚ â”‚
â”‚       â”‚    â”‚ ELSE:                                                        â”‚ â”‚
â”‚       â”‚    â”‚    â†’ Recursive chunking (512 tokens)                         â”‚ â”‚
â”‚       â”‚    â”‚    â†’ Overlap 10%                                             â”‚ â”‚
â”‚       â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â”‚                                         â”‚                            â”‚
â”‚       â”‚                                         â–¼                            â”‚
â”‚       â””â”€â”€â†’ GCS (original)           halfvec(768) + HNSW + tsvector (BM25)   â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚  BÃšSQUEDA (online)                                                           â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚                                                                              â”‚
â”‚  Query usuario                                                               â”‚
â”‚       â”‚                                                                      â”‚
â”‚       â–¼                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚ Cache SemÃ¡ntico   â”‚ HIT â”‚ Return cached response    â”‚ (~5ms)             â”‚
â”‚  â”‚ (Redis L1 + L2)   â”‚â”€â”€â”€â”€â†’â”‚ + Log cache hit           â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚            â”‚ MISS                                                            â”‚
â”‚            â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                      â”‚
â”‚  â”‚ Query Embedding   â”‚ Gemini text-embedding-004 (768d) (~30ms)             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚
â”‚            â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                      â”‚
â”‚  â”‚ Hybrid Search     â”‚ Vector (HNSW) + BM25 + RRF (~25ms)                   â”‚
â”‚  â”‚ Top 50 candidatos â”‚                                                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚
â”‚            â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                      â”‚
â”‚  â”‚ Cohere Rerank     â”‚ Cross-encoder multilingual (~80ms)                   â”‚
â”‚  â”‚ Top 50 â†’ Top 10   â”‚ (skip para Call Center/velocidad)                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚
â”‚            â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                      â”‚
â”‚  â”‚ LLM Generation    â”‚ Gemini Pro con top 10 docs (~1500ms)                 â”‚
â”‚  â”‚ + Citations       â”‚                                                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚
â”‚            â–¼                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                      â”‚
â”‚  â”‚ Cache Update      â”‚ Guardar en L1 (exact) + L2 (semantic)                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚
â”‚            â–¼                                                                 â”‚
â”‚       Respuesta + Fuentes                                                    â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚  LATENCIAS ESPERADAS:                                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚                                                                              â”‚
â”‚  â€¢ Cache Hit:     ~5ms                                                       â”‚
â”‚  â€¢ Cache Miss:    ~1,640ms (30 + 25 + 80 + 1500 + overhead)                  â”‚
â”‚  â€¢ Promedio:      ~545ms (con 67% cache hit rate)                            â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 11.7 ConfiguraciÃ³n Recomendada por Ãrea

| Ãrea | Chunking | Overlap | Embedding | BÃºsqueda | Rerank | Latencia Target |
|:-----|:---------|:-------:|:---------:|:---------|:------:|:---------------:|
| **RRHH** | Recursive | 15% | Gemini 768d | Hybrid | âœ… | <2s |
| **Call Center** | Sentence | 10% | Gemini 768d | Hybrid | âŒ | <1s |
| **Legal** | Agentic + Parent | 25% | Gemini 768d | Hybrid + Rerank | âœ… | <3s |
| **Operaciones** | Recursive | 15% | Gemini 768d | Hybrid | âœ… | <2s |
| **Finanzas** | Semantic | 20% | Gemini 768d | Hybrid + Rerank | âœ… | <2s |
| **KB General** | Sentence | 0% | Gemini 768d | Hybrid | âŒ | <500ms |

---
---
---

# SECCIÃ“N V: ANÃLISIS DE ESCENARIOS Y COSTOS

> **Nota CrÃ­tica:** Esta secciÃ³n es la MÃS IMPORTANTE del documento porque **integra todas las decisiones tÃ©cnicas anteriores y las traduce a costos concretos**. Los tres escenarios presentados representan diferentes puntos en el trade-off costo-calidad-complejidad.

---

## CapÃ­tulo 12: Escenario Baseline (Sin Optimizar)

Este escenario representa la implementaciÃ³n "estÃ¡ndar" sin aplicar las optimizaciones descritas en secciones anteriores. Sirve como **lÃ­nea base para comparaciÃ³n**.

### 12.1 ConfiguraciÃ³n del Escenario Baseline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ESCENARIO BASELINE (SIN OPTIMIZAR)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  ğŸ“¦ EMBEDDING:                                                               â”‚
â”‚     â€¢ Modelo: Gemini text-embedding-004                                      â”‚
â”‚     â€¢ DimensiÃ³n: 1024 (sin Matryoshka)                                       â”‚
â”‚     â€¢ PrecisiÃ³n: float32 (sin halfvec)                                       â”‚
â”‚     â€¢ Bytes/vector: 4,104 B                                                  â”‚
â”‚                                                                              â”‚
â”‚  ğŸ—ƒï¸ BASE DE DATOS:                                                           â”‚
â”‚     â€¢ Tabla Ãºnica (sin particionamiento)                                     â”‚
â”‚     â€¢ Ãndice HNSW: m=16, ef_construction=64                                  â”‚
â”‚     â€¢ Sin optimizaciones de RAM                                              â”‚
â”‚                                                                              â”‚
â”‚  âœ‚ï¸ CHUNKING:                                                                 â”‚
â”‚     â€¢ Estrategia: Recursive bÃ¡sico                                           â”‚
â”‚     â€¢ TamaÃ±o: 512 tokens                                                     â”‚
â”‚     â€¢ Overlap: 10%                                                           â”‚
â”‚                                                                              â”‚
â”‚  ğŸ” BÃšSQUEDA:                                                                 â”‚
â”‚     â€¢ Solo vector search (sin hÃ­brido)                                       â”‚
â”‚     â€¢ Sin reranking                                                          â”‚
â”‚     â€¢ Sin cache                                                              â”‚
â”‚                                                                              â”‚
â”‚  ğŸ¤– GENERACIÃ“N:                                                               â”‚
â”‚     â€¢ Llamada directa al LLM por cada query                                  â”‚
â”‚     â€¢ Sin cache semÃ¡ntico                                                    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 12.2 Dimensionamiento Baseline

Aplicando las fÃ³rmulas del CapÃ­tulo 2:

| MÃ©trica | FÃ³rmula | Valor |
|:--------|:--------|------:|
| **Documentos** | Input | 17,000,000 |
| **PÃ¡ginas totales** | 17M Ã— 10 pÃ¡ginas/doc | 170,000,000 |
| **Chunks** | 170M pÃ¡ginas Ã— 1.3 chunks/pÃ¡gina Ã— 1.10 (overlap) | ~243,100,000 |
| **Vectores ($N$)** | = Chunks | **~244 M** |

#### Almacenamiento

| Componente | FÃ³rmula | TamaÃ±o |
|:-----------|:--------|-------:|
| Bytes por vector | $d \times 4 + 8$ = 1024 Ã— 4 + 8 | 4,104 B |
| **Tabla de datos** | 244M Ã— (4,104 + 200) B | **~1.05 TB** |
| **Ãndice HNSW** | 244M Ã— 4,104 Ã— 1.1 | **~1.15 TB** |
| **Disco TOTAL** | Tabla + Ãndice + Overhead | **~2.5 TB** |

#### RAM Requerida

| Componente | CÃ¡lculo | RAM |
|:-----------|:--------|----:|
| Ãndice HNSW hot (20%) | 1.15 TB Ã— 0.20 | ~230 GB |
| Buffer pool | | ~32 GB |
| OS + overhead | | ~16 GB |
| **RAM TOTAL** | | **~280 GB** |

### 12.3 Costos Mensuales Baseline

| Componente | DescripciÃ³n | Costo/mes |
|:-----------|:------------|----------:|
| **Cloud SQL Enterprise** | db-custom-48-307200 (48 vCPU, 300 GB RAM) | ~$3,200 |
| | Disco SSD 3 TB | (incluido) |
| **Embeddings API** | ~10K queries/dÃ­a Ã— 30 dÃ­as Ã— $0.025/1K tokens | ~$1,500 |
| **LLM API (Gemini Pro)** | ~10K queries/dÃ­a Ã— 30 dÃ­as Ã— $0.007/query | ~$2,000 |
| **Redis (Memorystore)** | Standard, 8 GB (solo para sesiones) | ~$300 |
| **Reranker API** | Cohere Rerank, ~5K/dÃ­a | ~$400 |
| **Cloud Storage** | 17 TB Standard | ~$200 |
| **Cloud Run** | Servicios API | ~$500 |
| **Networking** | Egress interno | ~$150 |
| **Logging/Monitoring** | Cloud Operations | ~$100 |
| **TOTAL MENSUAL** | | **~$8,350/mes** |

### 12.4 Costo de IngestiÃ³n Inicial

El costo one-time de procesar e indexar los 17 TB de documentos:

| Componente | DescripciÃ³n | Costo |
|:-----------|:------------|------:|
| **Embedding de 17 TB** | ~4,000M tokens Ã— $0.025/1K tokens | ~$100,000 |
| **Procesamiento (Cloud Run)** | OCR + Chunking + Parsing | ~$2,000 |
| **Desarrollo** | ~400 horas Ã— $100/hora | ~$40,000 |
| **Testing y validaciÃ³n** | ~100 horas Ã— $100/hora | ~$10,000 |
| **TOTAL INGESTIÃ“N** | | **~$152,000** |

### 12.5 TCO 3 AÃ±os - Escenario Baseline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TCO 3 AÃ‘OS - ESCENARIO BASELINE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  AÃ‘O 0 (ImplementaciÃ³n):                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚
â”‚  â€¢ IngestiÃ³n inicial:                    $152,000                            â”‚
â”‚  â€¢ OperaciÃ³n (6 meses):                  $50,100  ($8,350 Ã— 6)               â”‚
â”‚  â€¢ Subtotal AÃ±o 0:                       $202,100                            â”‚
â”‚                                                                              â”‚
â”‚  AÃ‘O 1:                                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€                                                                      â”‚
â”‚  â€¢ OperaciÃ³n (12 meses):                 $100,200 ($8,350 Ã— 12)              â”‚
â”‚                                                                              â”‚
â”‚  AÃ‘O 2:                                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€                                                                      â”‚
â”‚  â€¢ OperaciÃ³n (12 meses):                 $100,200 ($8,350 Ã— 12)              â”‚
â”‚  â€¢ Re-indexaciÃ³n parcial (~20%):         $20,000                             â”‚
â”‚  â€¢ Subtotal AÃ±o 2:                       $120,200                            â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚                                                                              â”‚
â”‚  TOTAL TCO 3 AÃ‘OS:                       $422,500                            â”‚
â”‚  Promedio mensual:                       $11,736/mes                         â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 12.6 MÃ©tricas de Performance Baseline

| MÃ©trica | Valor Esperado | Notas |
|:--------|:--------------:|:------|
| **Latencia P50** | ~1,800 ms | Sin cache |
| **Latencia P95** | ~3,500 ms | Queries complejas |
| **Throughput** | ~20 QPS | Limitado por LLM |
| **Recall@10** | ~85% | Solo vector search |
| **Cache Hit Rate** | 0% | Sin cache |

---

## CapÃ­tulo 13: Escenario Optimizado (RECOMENDADO)

Este escenario aplica **todas las optimizaciones descritas en el documento** para lograr el mejor balance entre costo, calidad y complejidad operativa.

### 13.1 ConfiguraciÃ³n del Escenario Optimizado

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ESCENARIO OPTIMIZADO (RECOMENDADO)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  ğŸ“¦ EMBEDDING:                                                               â”‚
â”‚     â€¢ Modelo: Gemini text-embedding-004                                      â”‚
â”‚     â€¢ DimensiÃ³n: 768 (Matryoshka truncation)                                 â”‚
â”‚     â€¢ PrecisiÃ³n: float16 (halfvec)                                           â”‚
â”‚     â€¢ Bytes/vector: 1,544 B                                                  â”‚
â”‚     â€¢ RetenciÃ³n calidad: ~97.5%                                              â”‚
â”‚                                                                              â”‚
â”‚  ğŸ—ƒï¸ BASE DE DATOS:                                                           â”‚
â”‚     â€¢ Particionamiento por Ã¡rea (6 particiones)                              â”‚
â”‚     â€¢ Ãndice HNSW por particiÃ³n: m=16, ef_construction=64                    â”‚
â”‚     â€¢ Ãndice GIN para BM25 (tsvector)                                        â”‚
â”‚                                                                              â”‚
â”‚  âœ‚ï¸ CHUNKING:                                                                 â”‚
â”‚     â€¢ Estrategia: Adaptativa por tipo de documento                           â”‚
â”‚     â€¢ Legal: Agentic + Parent (25% overlap)                                  â”‚
â”‚     â€¢ TÃ©cnico: Recursive 1024 tokens (15% overlap)                           â”‚
â”‚     â€¢ FAQ/KB: Sentence (0% overlap)                                          â”‚
â”‚                                                                              â”‚
â”‚  ğŸ” BÃšSQUEDA:                                                                 â”‚
â”‚     â€¢ Hybrid Search (Vector + BM25 + RRF)                                    â”‚
â”‚     â€¢ Cohere Rerank para Ã¡reas crÃ­ticas (Legal, Finanzas)                    â”‚
â”‚     â€¢ Partition pruning por Ã¡rea                                             â”‚
â”‚                                                                              â”‚
â”‚  ğŸ’¾ CACHE:                                                                    â”‚
â”‚     â€¢ Cache semÃ¡ntico multi-nivel (Redis)                                    â”‚
â”‚     â€¢ L1: Exact match (~30% hit rate)                                        â”‚
â”‚     â€¢ L2: Semantic similarity (~40% hit rate)                                â”‚
â”‚     â€¢ Hit rate combinado: ~67%                                               â”‚
â”‚                                                                              â”‚
â”‚  ğŸ¤– GENERACIÃ“N:                                                               â”‚
â”‚     â€¢ Gemini Pro con cache de respuestas                                     â”‚
â”‚     â€¢ TTL: 24 horas                                                          â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 13.2 Dimensionamiento Optimizado

| MÃ©trica | Baseline | Optimizado | ReducciÃ³n |
|:--------|:--------:|:----------:|:---------:|
| **Vectores** | 244 M | 244 M | 0% |
| **Bytes/vector** | 4,104 B | 1,544 B | **-62%** |
| **Disco (tabla)** | ~1.05 TB | ~400 GB | **-62%** |
| **Disco (Ã­ndice)** | ~1.15 TB | ~450 GB | **-61%** |
| **Disco TOTAL** | ~2.5 TB | **~950 GB** | **-62%** |
| **RAM requerida** | ~280 GB | **~90 GB** | **-68%** |

### 13.3 Costos Mensuales Optimizados

| Componente | Baseline | Optimizado | Ahorro | RazÃ³n del ahorro |
|:-----------|:--------:|:----------:|:------:|:-----------------|
| **Cloud SQL Enterprise** | $3,200 | **$1,200** | -$2,000 | Menos RAM/disco |
| **Embeddings API** | $1,500 | **$500** | -$1,000 | Cache de embeddings |
| **LLM API** | $2,000 | **$600** | -$1,400 | Cache semÃ¡ntico (67% hit) |
| **Redis** | $300 | **$350** | +$50 | MÃ¡s capacidad para cache |
| **Reranker API** | $400 | **$400** | $0 | Sin cambio |
| **Cloud Storage** | $200 | **$200** | $0 | Sin cambio |
| **Cloud Run** | $500 | **$500** | $0 | Sin cambio |
| **Networking** | $150 | **$150** | $0 | Sin cambio |
| **Logging/Monitoring** | $100 | **$100** | $0 | Sin cambio |
| **TOTAL MENSUAL** | $8,350 | **$4,000** | **-$4,350** | **-52%** |

### 13.4 Costo de IngestiÃ³n Inicial (Optimizado)

| Componente | Baseline | Optimizado | Ahorro | RazÃ³n |
|:-----------|:--------:|:----------:|:------:|:------|
| **Embedding de 17 TB** | $100,000 | **$100,000** | $0 | Mismo modelo/tokens |
| **Procesamiento** | $2,000 | **$3,000** | +$1,000 | Chunking adaptativo |
| **Desarrollo** | $40,000 | **$45,000** | +$5,000 | MÃ¡s complejidad |
| **Testing** | $10,000 | **$12,000** | +$2,000 | ValidaciÃ³n de optimizaciones |
| **TOTAL INGESTIÃ“N** | $152,000 | **$160,000** | +$8,000 | â€” |

> **Nota:** El costo de ingestiÃ³n es ligeramente mayor por la complejidad adicional, pero se recupera rÃ¡pidamente con los ahorros operativos.

### 13.5 TCO 3 AÃ±os - Escenario Optimizado

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TCO 3 AÃ‘OS - ESCENARIO OPTIMIZADO                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  AÃ‘O 0 (ImplementaciÃ³n):                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚
â”‚  â€¢ IngestiÃ³n inicial:                    $60,000    (con BGE-M3 parcial)     â”‚
â”‚  â€¢ OperaciÃ³n (6 meses):                  $24,000    ($4,000 Ã— 6)             â”‚
â”‚  â€¢ Subtotal AÃ±o 0:                       $84,000                             â”‚
â”‚                                                                              â”‚
â”‚  AÃ‘O 1:                                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€                                                                      â”‚
â”‚  â€¢ OperaciÃ³n (12 meses):                 $48,000    ($4,000 Ã— 12)            â”‚
â”‚                                                                              â”‚
â”‚  AÃ‘O 2:                                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€                                                                      â”‚
â”‚  â€¢ OperaciÃ³n (12 meses):                 $48,000    ($4,000 Ã— 12)            â”‚
â”‚  â€¢ Re-indexaciÃ³n parcial (~20%):         $12,000                             â”‚
â”‚  â€¢ Subtotal AÃ±o 2:                       $60,000                             â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚                                                                              â”‚
â”‚  TOTAL TCO 3 AÃ‘OS:                       $192,000                            â”‚
â”‚  Promedio mensual:                       $5,333/mes                          â”‚
â”‚                                                                              â”‚
â”‚  AHORRO vs. BASELINE:                    $230,500 (-55%)                     â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 13.6 MÃ©tricas de Performance Optimizado

| MÃ©trica | Baseline | Optimizado | Mejora |
|:--------|:--------:|:----------:|:------:|
| **Latencia P50** | ~1,800 ms | **~545 ms** | **-70%** |
| **Latencia P95** | ~3,500 ms | **~1,800 ms** | **-49%** |
| **Throughput** | ~20 QPS | **~60 QPS** | **+200%** |
| **Recall@10** | ~85% | **~92%** | **+7%** |
| **Cache Hit Rate** | 0% | **~67%** | â€” |
| **Costo/query** | $0.028 | **$0.009** | **-68%** |

### 13.7 RetenciÃ³n de Calidad

| Componente | Impacto en Calidad |
|:-----------|:-------------------|
| Matryoshka 768d (vs 1024d) | ~98% retenciÃ³n |
| halfvec (float16 vs float32) | ~99.9% retenciÃ³n |
| **Combinado** | **~97.5% retenciÃ³n** |
| Hybrid Search (vs vector puro) | **+10-15% mejora** |
| Reranking | **+15-20% mejora** |

> â­ **Resultado neto:** A pesar de la compresiÃ³n, la calidad de retrieval **mejora** gracias a hybrid search y reranking.

---

## CapÃ­tulo 14: Escenario Ultra-Optimizado (Open Source)

Este escenario maximiza la reducciÃ³n de costos usando modelos open source y optimizaciones agresivas. Adecuado para organizaciones con expertise tÃ©cnico y tolerancia a menor calidad.

### 14.1 ConfiguraciÃ³n Ultra-Optimizada

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ESCENARIO ULTRA-OPTIMIZADO (OPEN SOURCE)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  ğŸ“¦ EMBEDDING:                                                               â”‚
â”‚     â€¢ Modelo: BGE-M3 (open source, local)                                    â”‚
â”‚     â€¢ DimensiÃ³n: 512 (truncation)                                            â”‚
â”‚     â€¢ PrecisiÃ³n: float16 (halfvec)                                           â”‚
â”‚     â€¢ Bytes/vector: 1,032 B                                                  â”‚
â”‚     â€¢ RetenciÃ³n calidad: ~94%                                                â”‚
â”‚                                                                              â”‚
â”‚  ğŸ–¥ï¸ INFRAESTRUCTURA EMBEDDINGS:                                              â”‚
â”‚     â€¢ 4x VMs con GPU T4 (spot instances)                                     â”‚
â”‚     â€¢ ONNX runtime optimizado                                                â”‚
â”‚     â€¢ Throughput: ~10K embeddings/segundo                                    â”‚
â”‚                                                                              â”‚
â”‚  ğŸ—ƒï¸ BASE DE DATOS:                                                           â”‚
â”‚     â€¢ Todas las optimizaciones del escenario anterior                        â”‚
â”‚     â€¢ Particionamiento mÃ¡s agresivo (10+ particiones)                        â”‚
â”‚                                                                              â”‚
â”‚  ğŸ” BÃšSQUEDA:                                                                 â”‚
â”‚     â€¢ Hybrid Search + BGE-reranker-v2-m3 (local)                             â”‚
â”‚     â€¢ Sin costos de APIs externas                                            â”‚
â”‚                                                                              â”‚
â”‚  ğŸ¤– GENERACIÃ“N:                                                               â”‚
â”‚     â€¢ Gemini Pro (Ãºnico componente cloud)                                    â”‚
â”‚     â€¢ Cache semÃ¡ntico agresivo (TTL 48h)                                     â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 14.2 Dimensionamiento Ultra-Optimizado

| MÃ©trica | Baseline | Optimizado | Ultra-Opt | ReducciÃ³n vs. Baseline |
|:--------|:--------:|:----------:|:---------:|:----------------------:|
| **Vectores** | 244 M | 244 M | 244 M | 0% |
| **Bytes/vector** | 4,104 B | 1,544 B | 1,032 B | **-75%** |
| **Disco TOTAL** | ~2.5 TB | ~950 GB | **~650 GB** | **-74%** |
| **RAM requerida** | ~280 GB | ~90 GB | **~65 GB** | **-77%** |

### 14.3 Costos Mensuales Ultra-Optimizados

| Componente | Baseline | Optimizado | Ultra-Opt | vs. Baseline |
|:-----------|:--------:|:----------:|:---------:|:------------:|
| **Cloud SQL Enterprise** | $3,200 | $1,200 | **$900** | -72% |
| **Embeddings** | $1,500 | $500 | **$0** | -100% (local) |
| **LLM API** | $2,000 | $600 | **$400** | -80% (cache 80%) |
| **GPU VMs (embeddings)** | $0 | $0 | **$400** | +$400 |
| **GPU VMs (reranker)** | $0 | $0 | **$200** | +$200 |
| **Redis** | $300 | $350 | **$350** | +$50 |
| **Reranker API** | $400 | $400 | **$0** | -100% (local) |
| **Cloud Storage** | $200 | $200 | **$200** | 0% |
| **Cloud Run** | $500 | $500 | **$400** | -20% |
| **Networking** | $150 | $150 | **$100** | -33% |
| **Logging** | $100 | $100 | **$100** | 0% |
| **TOTAL MENSUAL** | $8,350 | $4,000 | **$3,050** | **-63%** |

### 14.4 Costo de IngestiÃ³n Inicial (Ultra-Optimizado)

| Componente | Baseline | Optimizado | Ultra-Opt |
|:-----------|:--------:|:----------:|:---------:|
| **Embedding de 17 TB** | $100,000 | $100,000 | **$8,000** |
| | | | (solo GPU spot) |
| **Procesamiento** | $2,000 | $3,000 | **$3,000** |
| **Desarrollo** | $40,000 | $45,000 | **$60,000** |
| | | | (mÃ¡s complejo) |
| **Testing** | $10,000 | $12,000 | **$14,000** |
| **TOTAL INGESTIÃ“N** | $152,000 | $160,000 | **$85,000** |

### 14.5 TCO 3 AÃ±os - Escenario Ultra-Optimizado

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TCO 3 AÃ‘OS - ESCENARIO ULTRA-OPTIMIZADO                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  AÃ‘O 0 (ImplementaciÃ³n):                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                     â”‚
â”‚  â€¢ IngestiÃ³n inicial:                    $25,000    (GPU spot + optimizado)  â”‚
â”‚  â€¢ OperaciÃ³n (6 meses):                  $18,300    ($3,050 Ã— 6)             â”‚
â”‚  â€¢ Subtotal AÃ±o 0:                       $43,300                             â”‚
â”‚                                                                              â”‚
â”‚  AÃ‘O 1:                                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€                                                                      â”‚
â”‚  â€¢ OperaciÃ³n (12 meses):                 $36,600    ($3,050 Ã— 12)            â”‚
â”‚                                                                              â”‚
â”‚  AÃ‘O 2:                                                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€                                                                      â”‚
â”‚  â€¢ OperaciÃ³n (12 meses):                 $36,600    ($3,050 Ã— 12)            â”‚
â”‚  â€¢ Re-indexaciÃ³n parcial (~20%):         $2,000     (solo GPU)               â”‚
â”‚  â€¢ Subtotal AÃ±o 2:                       $38,600                             â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚                                                                              â”‚
â”‚  TOTAL TCO 3 AÃ‘OS:                       $118,500                            â”‚
â”‚  Promedio mensual:                       $3,292/mes                          â”‚
â”‚                                                                              â”‚
â”‚  AHORRO vs. BASELINE:                    $304,000 (-72%)                     â”‚
â”‚  AHORRO vs. OPTIMIZADO:                  $73,500 (-38%)                      â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 14.6 Trade-offs del Escenario Ultra-Optimizado

| Aspecto | Ventaja | Desventaja |
|:--------|:--------|:-----------|
| **Costo** | -72% vs. baseline | â€” |
| **Calidad** | â€” | ~94% retenciÃ³n (vs. ~97.5% optimizado) |
| **Complejidad** | â€” | Alta (gestionar GPUs, modelos locales) |
| **Expertise requerido** | â€” | Requiere ML engineers |
| **Soporte** | â€” | Sin soporte enterprise |
| **Escalabilidad** | â€” | Manual, requiere planificaciÃ³n |
| **Time-to-market** | â€” | +2-4 semanas de desarrollo |
| **Riesgo operativo** | â€” | Mayor (mÃ¡s componentes) |

---

## CapÃ­tulo 15: Comparativa y DecisiÃ³n Final

### 15.1 Tabla Comparativa Completa

| Aspecto | Baseline | Optimizado | Ultra-Optimizado |
|:--------|:--------:|:----------:|:----------------:|
| **DIMENSIONAMIENTO** | | | |
| Vectores | 244 M | 244 M | 244 M |
| Bytes/vector | 4,104 B | 1,544 B | 1,032 B |
| Disco total | 2.5 TB | 950 GB | 650 GB |
| RAM requerida | 280 GB | 90 GB | 65 GB |
| | | | |
| **COSTOS** | | | |
| Mensual operativo | $8,350 | $4,000 | $3,050 |
| IngestiÃ³n inicial | $152,000 | $60,000 | $25,000 |
| TCO 3 aÃ±os | $422,500 | $192,000 | $118,500 |
| Costo/mes promedio | $11,736 | $5,333 | $3,292 |
| | | | |
| **PERFORMANCE** | | | |
| Latencia P50 | 1,800 ms | 545 ms | 600 ms |
| Throughput | 20 QPS | 60 QPS | 50 QPS |
| Cache hit rate | 0% | 67% | 80% |
| Recall@10 | 85% | 92% | 88% |
| | | | |
| **CALIDAD** | | | |
| RetenciÃ³n de calidad | 100% | 97.5% | 94% |
| Hybrid search | âŒ | âœ… | âœ… |
| Reranking | âŒ | âœ… (API) | âœ… (local) |
| | | | |
| **OPERATIVO** | | | |
| Complejidad | Baja | Media | Alta |
| Expertise requerido | PostgreSQL | PostgreSQL + ML | PostgreSQL + ML + GPU |
| Soporte enterprise | âœ… | âœ… | âŒ |
| Time-to-production | 3 meses | 4 meses | 5-6 meses |

### 15.2 GrÃ¡fico de TCO a 3 AÃ±os

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          TCO ACUMULADO (3 AÃ‘OS)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  $450K â”€â”¤                                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€      â”‚
â”‚         â”‚                                    â•±â”€â”€â”€â”€â”˜                          â”‚
â”‚  $400K â”€â”¤                               â•±â”€â”€â”€â•¯    BASELINE: $422.5K           â”‚
â”‚         â”‚                          â•±â”€â”€â”€â”€â•¯                                    â”‚
â”‚  $350K â”€â”¤                     â•±â”€â”€â”€â”€â•¯                                         â”‚
â”‚         â”‚                â•±â”€â”€â”€â”€â•¯                                              â”‚
â”‚  $300K â”€â”¤           â•±â”€â”€â”€â”€â•¯                                                   â”‚
â”‚         â”‚      â•±â”€â”€â”€â”€â•¯                                                        â”‚
â”‚  $250K â”€â”¤ â•±â”€â”€â”€â”€â•¯                                                             â”‚
â”‚         â”‚â•±           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚  $200K â”€â”¤       â•±â”€â”€â”€â”˜                                                        â”‚
â”‚         â”‚  â•±â”€â”€â”€â•¯     OPTIMIZADO: $192K                                       â”‚
â”‚  $150K â”€â”¤â•±â”€â”€â•¯                                                                â”‚
â”‚         â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                            â”‚
â”‚  $100K â”€â”¤â•±â”€â”€â•¯                                                                â”‚
â”‚         â”‚    ULTRA-OPT: $118.5K                                              â”‚
â”‚   $50K â”€â”¤                                                                    â”‚
â”‚         â”‚                                                                    â”‚
â”‚     $0 â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼                â”‚
â”‚         AÃ±o 0        AÃ±o 0.5      AÃ±o 1        AÃ±o 2        AÃ±o 3            â”‚
â”‚                                                                              â”‚
â”‚  AHORRO ACUMULADO A 3 AÃ‘OS:                                                  â”‚
â”‚  â€¢ Optimizado vs. Baseline:     $230,500 (55% menos)                         â”‚
â”‚  â€¢ Ultra-Opt vs. Baseline:      $304,000 (72% menos)                         â”‚
â”‚  â€¢ Ultra-Opt vs. Optimizado:    $73,500 (38% menos)                          â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 15.3 AnÃ¡lisis de Trade-offs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ANÃLISIS DE TRADE-OFFS                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚                           COSTO                                              â”‚
â”‚                             â–²                                                â”‚
â”‚                             â”‚                                                â”‚
â”‚                   BASELINE  â—                                                â”‚
â”‚                 ($422K TCO) â”‚                                                â”‚
â”‚                             â”‚                                                â”‚
â”‚                             â”‚                                                â”‚
â”‚                             â”‚    â— OPTIMIZADO ($192K)                        â”‚
â”‚                             â”‚    â­ MEJOR BALANCE                            â”‚
â”‚                             â”‚                                                â”‚
â”‚                             â”‚          â— ULTRA-OPT ($118K)                   â”‚
â”‚                             â”‚                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ CALIDAD        â”‚
â”‚                           94%              97.5%         100%                â”‚
â”‚                             â”‚                                                â”‚
â”‚                             â”‚                                                â”‚
â”‚                             â”‚         COMPLEJIDAD                             â”‚
â”‚                             â–¼         Alta â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ Baja                â”‚
â”‚                                                                              â”‚
â”‚                                                                              â”‚
â”‚  ZONAS DE DECISIÃ“N:                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                          â”‚
â”‚  â€¢ Presupuesto muy limitado + expertise ML â†’ Ultra-Optimizado                â”‚
â”‚  â€¢ Balance costo/calidad/riesgo â†’ â­ OPTIMIZADO (recomendado)                â”‚
â”‚  â€¢ Tiempo crÃ­tico + sin expertise ML â†’ Baseline (no recomendado)             â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 15.4 DecisiÃ³n Final

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              â”‚
â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—  â”‚
â”‚  â•‘                                                                       â•‘  â”‚
â”‚  â•‘              DECISIÃ“N: ESCENARIO OPTIMIZADO                           â•‘  â”‚
â”‚  â•‘                                                                       â•‘  â”‚
â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚                                                                              â”‚
â”‚  CONFIGURACIÃ“N RECOMENDADA:                                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                  â”‚
â”‚                                                                              â”‚
â”‚  â€¢ Embedding: Gemini text-embedding-004, 768d (Matryoshka)                   â”‚
â”‚  â€¢ PrecisiÃ³n: halfvec (float16)                                              â”‚
â”‚  â€¢ Base de datos: Cloud SQL Enterprise + pgvector                            â”‚
â”‚  â€¢ Particionamiento: Por Ã¡rea funcional (6 particiones)                      â”‚
â”‚  â€¢ BÃºsqueda: Hybrid (Vector + BM25 + RRF)                                    â”‚
â”‚  â€¢ Reranking: Cohere Rerank para Ã¡reas crÃ­ticas                              â”‚
â”‚  â€¢ Cache: SemÃ¡ntico multi-nivel (Redis)                                      â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                              â”‚
â”‚  RAZONES DE LA DECISIÃ“N:                                                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                                      â”‚
â”‚                                                                              â”‚
â”‚  1. BALANCE COSTO-CALIDAD Ã“PTIMO                                             â”‚
â”‚     â€¢ 55% ahorro vs. baseline                                                â”‚
â”‚     â€¢ 97.5% retenciÃ³n de calidad                                             â”‚
â”‚     â€¢ Mejora real de 92% recall (vs. 85% baseline)                           â”‚
â”‚                                                                              â”‚
â”‚  2. COMPLEJIDAD MANEJABLE                                                    â”‚
â”‚     â€¢ No requiere expertise en GPUs                                          â”‚
â”‚     â€¢ Soporte enterprise disponible (GCP, Cohere)                            â”‚
â”‚     â€¢ Debugging con herramientas familiares                                  â”‚
â”‚                                                                              â”‚
â”‚  3. RIESGO CONTROLADO                                                        â”‚
â”‚     â€¢ APIs managed = SLAs garantizados                                       â”‚
â”‚     â€¢ Rollback simple si hay problemas                                       â”‚
â”‚     â€¢ Escalado automÃ¡tico disponible                                         â”‚
â”‚                                                                              â”‚
â”‚  4. TIME-TO-MARKET RAZONABLE                                                 â”‚
â”‚     â€¢ 4 meses vs. 5-6 meses de ultra-opt                                     â”‚
â”‚     â€¢ MVP funcional en 2 meses                                               â”‚
â”‚                                                                              â”‚
â”‚  5. FLEXIBILIDAD FUTURA                                                      â”‚
â”‚     â€¢ Migrar a open source despuÃ©s es posible                                â”‚
â”‚     â€¢ Escalar a mÃ¡s vectores sin rediseÃ±o                                    â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                              â”‚
â”‚  RUTA DE ESCAPE A ULTRA-OPTIMIZADO:                                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                          â”‚
â”‚                                                                              â”‚
â”‚  Si despuÃ©s de 12 meses el costo sigue siendo una preocupaciÃ³n:              â”‚
â”‚                                                                              â”‚
â”‚  â€¢ Fase 1: Migrar embeddings a BGE-M3 local (ahorro: $500/mes)               â”‚
â”‚  â€¢ Fase 2: Migrar reranking a BGE-reranker (ahorro: $400/mes)                â”‚
â”‚  â€¢ Fase 3: Optimizar LLM con cache mÃ¡s agresivo                              â”‚
â”‚                                                                              â”‚
â”‚  Esto permite una migraciÃ³n gradual sin riesgo de big-bang.                  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 15.5 Alternativas Open Source para Embeddings

Si en el futuro se desea reducir costos de embeddings, estas son las alternativas validadas:

| Modelo | Calidad vs. Gemini | MultilingÃ¼e | Costo IngestiÃ³n 17 TB | Infraestructura |
|:-------|:------------------:|:-----------:|:---------------------:|:----------------|
| **Gemini API** | 100% | âœ… | ~$100,000 | Ninguna |
| **BGE-M3 (local)** | ~95-98% | âœ… 100+ langs | ~$8,000-15,000 | 4x T4 GPUs |
| **E5-large-v2** | ~92-95% | âœ… | ~$6,000-12,000 | 4x T4 GPUs |
| **Multilingual-e5** | ~93-96% | âœ… 100+ langs | ~$7,000-14,000 | 4x T4 GPUs |

> ğŸ’¡ **RecomendaciÃ³n:** Usar Gemini API inicialmente para simplicidad, con opciÃ³n de migrar a BGE-M3 despuÃ©s de validar el sistema.

---
---

# SECCIÃ“N VI: OPERACIONES Y PRODUCCIÃ“N

> **Nota:** Esta secciÃ³n aplica especÃ­ficamente al **Escenario Optimizado** (el recomendado en la SecciÃ³n V). Los procedimientos y configuraciones asumen la arquitectura con Gemini embeddings, halfvec, cache semÃ¡ntico y particionamiento.

---

## CapÃ­tulo 16: Framework de EvaluaciÃ³n de Calidad

La evaluaciÃ³n continua de la calidad del sistema RAG es crÃ­tica para mantener y mejorar el rendimiento en producciÃ³n.

### 16.1 MÃ©tricas de Retrieval

Estas mÃ©tricas evalÃºan la calidad de la **bÃºsqueda** de documentos relevantes:

| MÃ©trica | QuÃ© Mide | CÃ³mo Calcular | Target | Criticidad |
|:--------|:---------|:--------------|:------:|:----------:|
| **Recall@K** | Â¿El doc relevante estÃ¡ en top K? | Docs relevantes en top K / Total relevantes | >90% (K=10) | ğŸ”´ Alta |
| **Precision@K** | Â¿CuÃ¡ntos de top K son relevantes? | Docs relevantes en top K / K | >70% (K=10) | ğŸŸ¡ Media |
| **MRR** | Â¿QuÃ© tan arriba estÃ¡ el primer relevante? | 1/posiciÃ³n del primer relevante | >0.7 | ğŸŸ¡ Media |
| **nDCG** | Calidad del ranking considerando posiciones | DCG/IDCG | >0.8 | ğŸŸ¡ Media |
| **Hit Rate** | Â¿Hay al menos 1 relevante en top K? | Queries con hit / Total queries | >95% | ğŸ”´ Alta |

### 16.2 MÃ©tricas de GeneraciÃ³n (RAG End-to-End)

Estas mÃ©tricas evalÃºan la calidad de las **respuestas generadas** por el LLM:

| MÃ©trica | QuÃ© Mide | Herramienta | Target | Criticidad |
|:--------|:---------|:------------|:------:|:----------:|
| **Faithfulness** | Â¿La respuesta es fiel al contexto? | RAGAS, TruLens | >85% | ğŸ”´ Alta |
| **Answer Relevancy** | Â¿Responde la pregunta? | RAGAS | >80% | ğŸ”´ Alta |
| **Groundedness** | Â¿Evita alucinaciones? | TruLens, DeepEval | >90% | ğŸ”´ CrÃ­tica |
| **Context Precision** | Â¿El contexto recuperado es preciso? | RAGAS | >75% | ğŸŸ¡ Media |
| **Context Recall** | Â¿Se recuperÃ³ todo el contexto necesario? | RAGAS | >85% | ğŸŸ¡ Media |
| **Answer Correctness** | Â¿La respuesta es factualmente correcta? | DeepEval, manual | >85% | ğŸ”´ Alta |

### 16.3 ImplementaciÃ³n con RAGAS

```python
# evaluator.py - MÃ³dulo de evaluaciÃ³n automatizada con RAGAS

from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall,
)
from ragas.llms import LangchainLLM
from langchain_google_vertexai import ChatVertexAI
from datasets import Dataset
import pandas as pd
from typing import List, Dict
import json

class RAGEvaluator:
    """
    Evaluador de calidad RAG usando RAGAS.
    Requiere un golden set con queries, respuestas y ground truth.
    """
    
    def __init__(self, project_id: str = "enterprise-ai-platform"):
        # Configurar LLM para evaluaciÃ³n (Gemini Pro)
        self.llm = ChatVertexAI(
            model_name="gemini-1.5-pro",
            project=project_id,
            temperature=0  # DeterminÃ­stico para evaluaciÃ³n
        )
        
        # MÃ©tricas a evaluar
        self.metrics = [
            faithfulness,
            answer_relevancy,
            context_precision,
            context_recall,
        ]
    
    def load_golden_set(self, filepath: str) -> Dataset:
        """
        Carga golden set desde JSON.
        
        Formato esperado:
        [
            {
                "question": "Â¿CuÃ¡ntos dÃ­as de vacaciones tengo?",
                "answer": "Los empleados tienen 15 dÃ­as...",
                "contexts": ["PolÃ­tica de vacaciones: ..."],
                "ground_truth": "15 dÃ­as hÃ¡biles anuales"
            },
            ...
        ]
        """
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        return Dataset.from_dict({
            "question": [item["question"] for item in data],
            "answer": [item["answer"] for item in data],
            "contexts": [item["contexts"] for item in data],
            "ground_truth": [item["ground_truth"] for item in data],
        })
    
    def evaluate(self, dataset: Dataset) -> Dict[str, float]:
        """
        Ejecuta evaluaciÃ³n completa y retorna mÃ©tricas.
        """
        result = evaluate(
            dataset=dataset,
            metrics=self.metrics,
            llm=LangchainLLM(llm=self.llm),
        )
        
        return {
            "faithfulness": result["faithfulness"],
            "answer_relevancy": result["answer_relevancy"],
            "context_precision": result["context_precision"],
            "context_recall": result["context_recall"],
            "timestamp": pd.Timestamp.now().isoformat(),
        }
    
    def check_thresholds(self, metrics: Dict[str, float]) -> Dict[str, bool]:
        """
        Verifica si las mÃ©tricas cumplen los thresholds mÃ­nimos.
        """
        thresholds = {
            "faithfulness": 0.85,
            "answer_relevancy": 0.80,
            "context_precision": 0.75,
            "context_recall": 0.85,
        }
        
        return {
            metric: metrics.get(metric, 0) >= threshold
            for metric, threshold in thresholds.items()
        }

# Uso en CI/CD o batch job
if __name__ == "__main__":
    evaluator = RAGEvaluator()
    
    # Cargar golden set (mÃ­nimo 50-100 ejemplos para resultados confiables)
    dataset = evaluator.load_golden_set("golden_set_200.json")
    
    # Ejecutar evaluaciÃ³n
    metrics = evaluator.evaluate(dataset)
    print(f"Resultados: {metrics}")
    
    # Verificar thresholds
    passed = evaluator.check_thresholds(metrics)
    if all(passed.values()):
        print("âœ… Todas las mÃ©tricas cumplen thresholds")
    else:
        failed = [k for k, v in passed.items() if not v]
        print(f"âŒ MÃ©tricas bajo threshold: {failed}")
```

### 16.4 Frecuencia de EvaluaciÃ³n

| Tipo | Frecuencia | Samples | Responsable | Automatizado |
|:-----|:----------:|:-------:|:------------|:------------:|
| **Smoke tests** | Cada deploy | 10 queries fijas | CI/CD | âœ… |
| **Regression** | Semanal | 50-100 queries | ML Engineer | âœ… |
| **Golden set completo** | Mensual | 200+ queries anotadas | QA + Domain Expert | âœ… |
| **A/B testing** | Por feature | TrÃ¡fico real | Data Science | âŒ (manual) |
| **User feedback** | Continuo | Thumbs up/down | Usuarios | âŒ (continuo) |

### 16.5 Dashboard de MÃ©tricas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RAG QUALITY DASHBOARD                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  RETRIEVAL METRICS                     GENERATION METRICS                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”‚
â”‚  Recall@10:     92% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘     Faithfulness:   87% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘     â”‚
â”‚  Precision@10:  74% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘     Answer Rel:     82% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘     â”‚
â”‚  MRR:           0.78 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘     Groundedness:   91% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘     â”‚
â”‚  Hit Rate:      96% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘     Context Prec:   78% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘     â”‚
â”‚                                                                              â”‚
â”‚  LATENCY (ms)                          COST (last 30 days)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                   â”‚
â”‚  p50: 45ms   â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘                Embeddings:   $487                    â”‚
â”‚  p95: 112ms  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘                LLM:          $623                    â”‚
â”‚  p99: 245ms  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘                Reranker:     $178                    â”‚
â”‚                                        Infra:        $1,245                  â”‚
â”‚  Cache Hit Rate: 67%                   TOTAL:        $2,533                  â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  TREND (30 dÃ­as)                       ALERTS                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”€â”€â”€â”€â”€â”€                                â”‚
â”‚  Recall@10:    â†‘ +2.3%                 âš ï¸ Context Precision bajo 75%         â”‚
â”‚  Faithfulness: â†’ 0%                    âœ… No hay alertas crÃ­ticas            â”‚
â”‚  Latency p95:  â†“ -8%                                                         â”‚
â”‚  Cache Hit:    â†‘ +5%                                                         â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## CapÃ­tulo 17: Estrategia de ActualizaciÃ³n de Datos

Mantener los embeddings sincronizados con los documentos fuente es crÃ­tico para la precisiÃ³n del sistema.

### 17.1 Tipos de Cambios en el Corpus

| Tipo de Cambio | Frecuencia TÃ­pica | Estrategia | Complejidad |
|:---------------|:-----------------:|:-----------|:-----------:|
| **Nuevos documentos** | Diaria | Incremental indexing | Baja |
| **Documentos modificados** | Semanal | Re-embedding selectivo | Media |
| **Documentos eliminados** | Mensual | Soft delete + cleanup batch | Baja |
| **Cambio de modelo embedding** | Anual | Full reindex (planificado) | Alta |
| **Cambio de parÃ¡metros chunking** | Raro | Re-procesamiento selectivo | Alta |

### 17.2 Pipeline de ActualizaciÃ³n (CDC)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE DE ACTUALIZACIÃ“N (CDC)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  OPENTEXT / FUENTES                                                          â”‚
â”‚       â”‚                                                                      â”‚
â”‚       â–¼                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                        â”‚
â”‚  â”‚ CDC (Change     â”‚  Detecta: nuevos, modificados, eliminados              â”‚
â”‚  â”‚ Data Capture)   â”‚  Frecuencia: cada 1 hora                               â”‚
â”‚  â”‚                 â”‚  MÃ©todo: timestamp comparison / hash                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                        â”‚
â”‚           â”‚                                                                  â”‚
â”‚           â–¼                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                        CLASIFICACIÃ“N DE CAMBIOS                         â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚â”‚
â”‚  â”‚  â”‚   Nuevos    â”‚     â”‚ Modificados â”‚     â”‚ Eliminados  â”‚               â”‚â”‚
â”‚  â”‚  â”‚    docs     â”‚     â”‚    docs     â”‚     â”‚    docs     â”‚               â”‚â”‚
â”‚  â”‚  â”‚  (~500/dÃ­a) â”‚     â”‚  (~200/dÃ­a) â”‚     â”‚  (~50/dÃ­a)  â”‚               â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜               â”‚â”‚
â”‚  â”‚         â”‚                   â”‚                   â”‚                       â”‚â”‚
â”‚  â”‚         â–¼                   â–¼                   â–¼                       â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚â”‚
â”‚  â”‚  â”‚   Chunk +   â”‚     â”‚  Eliminar   â”‚     â”‚   Marcar    â”‚               â”‚â”‚
â”‚  â”‚  â”‚   Embed +   â”‚     â”‚  chunks     â”‚     â”‚   deleted   â”‚               â”‚â”‚
â”‚  â”‚  â”‚   INSERT    â”‚     â”‚  antiguos   â”‚     â”‚  (soft del) â”‚               â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚  + Re-chunk â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜               â”‚â”‚
â”‚  â”‚         â”‚            â”‚  + Re-embed â”‚            â”‚                       â”‚â”‚
â”‚  â”‚         â”‚            â”‚  + UPSERT   â”‚            â”‚                       â”‚â”‚
â”‚  â”‚         â”‚            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜            â”‚                       â”‚â”‚
â”‚  â”‚         â”‚                   â”‚                   â”‚                       â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                â”‚                                             â”‚
â”‚                                â–¼                                             â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                â”‚
â”‚                    â”‚      pgvector         â”‚                                â”‚
â”‚                    â”‚   (INSERT/UPSERT)     â”‚                                â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                                                              â”‚
â”‚  JOBS BATCH (nocturnos, 3 AM):                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚  â€¢ Cleanup de soft-deleted (>30 dÃ­as)                                       â”‚
â”‚  â€¢ VACUUM ANALYZE en tablas de embeddings                                   â”‚
â”‚  â€¢ ActualizaciÃ³n de estadÃ­sticas                                             â”‚
â”‚  â€¢ Rebuild de Ã­ndices fragmentados (si fragmentaciÃ³n >20%)                  â”‚
â”‚  â€¢ InvalidaciÃ³n de cache para docs modificados                              â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 17.3 SLAs de Freshness por Ãrea

| Ãrea | Freshness SLA | Estrategia | JustificaciÃ³n | Prioridad CDC |
|:-----|:-------------:|:-----------|:--------------|:-------------:|
| **PolÃ­ticas RRHH** | 24 horas | Batch diario (noche) | Cambios poco frecuentes | Baja |
| **Call Center KB** | 4 horas | Near real-time | Procedimientos se actualizan frecuentemente | Alta |
| **Legal** | 1 hora | Near real-time | Contratos activos, compliance | CrÃ­tica |
| **Operaciones** | 24 horas | Batch diario (noche) | Manuales estables | Baja |
| **Finanzas** | 24 horas | Batch diario (noche) | Reportes periÃ³dicos | Media |

### 17.4 Costos de Re-indexaciÃ³n

| OperaciÃ³n | Volumen | Frecuencia | Costo Estimado |
|:----------|:-------:|:----------:|:--------------:|
| **Incremental diario** | ~0.5% del corpus (~850K chunks) | Diaria | ~$50/dÃ­a |
| **Incremental semanal** | ~2% del corpus (~3.4M chunks) | Semanal | ~$200/semana |
| **Batch mensual** | ~5% del corpus (~8.5M chunks) | Mensual | ~$500/mes |
| **Full reindex** | 100% (~170M chunks) | Anual/emergencia | ~$100,000 |

> âš ï¸ **RecomendaciÃ³n:** Planificar el full reindex anualmente, preferiblemente en fin de semana o perÃ­odo de bajo trÃ¡fico. Considerar BGE-M3 local para reducir costos.

---

## CapÃ­tulo 18: Alta Disponibilidad y Disaster Recovery

### 18.1 Arquitectura de Alta Disponibilidad

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ARQUITECTURA DE ALTA DISPONIBILIDAD                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  REGIÃ“N: southamerica-east1 (SÃ£o Paulo)                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    CLOUD SQL ENTERPRISE                               â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚  â”‚  â”‚    ZONA A       â”‚                  â”‚    ZONA B       â”‚            â”‚  â”‚
â”‚  â”‚  â”‚   (primary)     â”‚â—„â”€â”€â”€â”€Syncâ”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   (standby)     â”‚            â”‚  â”‚
â”‚  â”‚  â”‚                 â”‚    Replication   â”‚                 â”‚            â”‚  â”‚
â”‚  â”‚  â”‚  pgvector       â”‚                  â”‚  pgvector       â”‚            â”‚  â”‚
â”‚  â”‚  â”‚  + Ã­ndices      â”‚                  â”‚  + Ã­ndices      â”‚            â”‚  â”‚
â”‚  â”‚  â”‚                 â”‚                  â”‚                 â”‚            â”‚  â”‚
â”‚  â”‚  â”‚  db-custom-16   â”‚                  â”‚  db-custom-16   â”‚            â”‚  â”‚
â”‚  â”‚  â”‚  96GB RAM       â”‚                  â”‚  96GB RAM       â”‚            â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚  â”‚           â”‚                                    â”‚                      â”‚  â”‚
â”‚  â”‚           â”‚ Automatic                          â”‚ Failover             â”‚  â”‚
â”‚  â”‚           â”‚ Failover                           â”‚ (<60 sec)            â”‚  â”‚
â”‚  â”‚           â”‚                                    â”‚                      â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚  â”‚  â”‚              Internal Load Balancer                   â”‚            â”‚  â”‚
â”‚  â”‚  â”‚              (Private IP: 10.0.1.x)                   â”‚            â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚  â”‚                          â”‚                                             â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚  â”‚  â”‚                 Read Replicas (2x)                     â”‚            â”‚  â”‚
â”‚  â”‚  â”‚              (para queries de lectura)                 â”‚            â”‚  â”‚
â”‚  â”‚  â”‚              DistribuciÃ³n: 70% read, 30% write         â”‚            â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    REDIS CLUSTER (Memorystore)                        â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚  â”‚
â”‚  â”‚  â”‚   Primary       â”‚â—„â”€â”€â”€â”€Asyncâ”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Replica       â”‚            â”‚  â”‚
â”‚  â”‚  â”‚   16GB          â”‚   Replication    â”‚   16GB          â”‚            â”‚  â”‚
â”‚  â”‚  â”‚   Zona A        â”‚                  â”‚   Zona B        â”‚            â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  BACKUP:                                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€                                                                     â”‚
â”‚  â€¢ Automated daily backups (7 dÃ­as retenciÃ³n)                               â”‚
â”‚  â€¢ Point-in-time recovery (PITR) habilitado                                 â”‚
â”‚  â€¢ Binary logs: 7 dÃ­as                                                       â”‚
â”‚  â€¢ Cross-region backup: us-central1 (DR)                                    â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 18.2 RTO/RPO

| MÃ©trica | Valor | DescripciÃ³n |
|:--------|:-----:|:------------|
| **RPO (Recovery Point Objective)** | ~1-5 min | MÃ¡xima pÃ©rdida de datos aceptable |
| **RTO (Recovery Time Objective)** | <60 seg | Tiempo mÃ¡ximo de downtime |
| **Disponibilidad SLA** | 99.95% | Cloud SQL Enterprise SLA |
| **Downtime anual mÃ¡ximo** | ~4.4 horas | 99.95% uptime |

### 18.3 Costos de Alta Disponibilidad

| Componente | Costo Base | Costo HA | Overhead | JustificaciÃ³n |
|:-----------|:----------:|:--------:|:--------:|:--------------|
| **Cloud SQL Primary** | $1,200/mes | â€” | â€” | â€” |
| **Standby instance** | â€” | +$600/mes | +50% | ReplicaciÃ³n sÃ­ncrona |
| **Read replicas (2x)** | â€” | +$480/mes | +40% | DistribuciÃ³n de carga |
| **Cross-region backup** | â€” | +$120/mes | +10% | Disaster recovery |
| **Redis HA** | $350/mes | +$175/mes | +50% | Replica |
| **TOTAL** | $1,550/mes | **$2,925/mes** | **+89%** | â€” |

> ğŸ’¡ **RecomendaciÃ³n:** HA completa para producciÃ³n. En desarrollo/staging, usar single-instance para reducir costos.

### 18.4 Procedimiento de Failover

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PROCEDIMIENTO DE FAILOVER                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  FAILOVER AUTOMÃTICO (Cloud SQL Enterprise):                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚                                                                              â”‚
â”‚  T+0s:    ğŸ”´ Falla detectada en primary                                      â”‚
â”‚                â”‚                                                             â”‚
â”‚  T+10-30s:    â”‚ Cloud SQL detecta heartbeat failure                          â”‚
â”‚                â”‚ (health check cada 1 segundo)                               â”‚
â”‚                â–¼                                                             â”‚
â”‚  T+30s:   âš ï¸ DecisiÃ³n de failover iniciada                                   â”‚
â”‚                â”‚                                                             â”‚
â”‚  T+30-50s:    â”‚ PromociÃ³n de standby a primary                               â”‚
â”‚                â”‚ â€¢ Flush de WAL logs                                         â”‚
â”‚                â”‚ â€¢ ActualizaciÃ³n de metadata                                  â”‚
â”‚                â”‚ â€¢ VerificaciÃ³n de consistencia                               â”‚
â”‚                â–¼                                                             â”‚
â”‚  T+50s:   ğŸ”„ DNS interno actualizado                                         â”‚
â”‚                â”‚ (automÃ¡tico, no requiere acciÃ³n)                            â”‚
â”‚                â–¼                                                             â”‚
â”‚  T+55s:   ğŸ”Œ Connection pooler reconecta                                     â”‚
â”‚                â”‚ â€¢ Cloud SQL Proxy detecta nueva IP                          â”‚
â”‚                â”‚ â€¢ Conexiones re-establecidas                                 â”‚
â”‚                â–¼                                                             â”‚
â”‚  T+60s:   âœ… Sistema operativo nuevamente                                    â”‚
â”‚                                                                              â”‚
â”‚  TOTAL: < 60 segundos de downtime                                            â”‚
â”‚                                                                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                              â”‚
â”‚  POST-FAILOVER (manual):                                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                    â”‚
â”‚  1. Verificar estado en Cloud Console                                        â”‚
â”‚  2. Revisar logs de failover                                                 â”‚
â”‚  3. Confirmar que read replicas siguen sincronizadas                         â”‚
â”‚  4. Crear nuevo standby (automÃ¡tico en Enterprise)                           â”‚
â”‚  5. Notificar al equipo via PagerDuty/Slack                                  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## CapÃ­tulo 19: Observabilidad y Monitoreo

### 19.1 Stack de Observabilidad

| Capa | Herramienta | PropÃ³sito | Costo/mes |
|:-----|:------------|:----------|:---------:|
| **Infraestructura** | Cloud Monitoring | CPU, RAM, Disco, Network | Incluido |
| **Base de datos** | Cloud SQL Insights | Query performance, locks, waits | Incluido |
| **AplicaciÃ³n** | Cloud Trace | Distributed tracing | ~$50 |
| **Logs** | Cloud Logging | Logs centralizados, bÃºsqueda | ~$30 |
| **RAG Quality** | Custom + Prometheus | MÃ©tricas de retrieval/generation | ~$20 |
| **LLM Observability** | LangSmith / Helicone | Token usage, latency, traces | ~$100 |
| **Alerting** | Cloud Monitoring + PagerDuty | Alertas y on-call | ~$50 |

### 19.2 MÃ©tricas CrÃ­ticas y Alertas

| MÃ©trica | Threshold Warning | Threshold Critical | AcciÃ³n | Responsable |
|:--------|:-----------------:|:------------------:|:-------|:------------|
| **Infra: CPU utilization** | >70% | >85% | Scale up | SRE |
| **Infra: Memory utilization** | >75% | >90% | Scale up / investigar | SRE |
| **Infra: Disk usage** | >70% | >85% | Expandir disco | SRE |
| **DB: Query latency p99** | >100ms | >200ms | Investigar queries lentas | DBA |
| **DB: Connection pool** | >80% | >95% | Aumentar pool size | DBA |
| **DB: Replication lag** | >10s | >60s | Investigar / failover | DBA |
| **App: Cache hit rate** | <50% | <30% | Revisar TTL/estrategia | ML Eng |
| **RAG: Retrieval Recall@10** | <85% | <75% | Revisar embeddings/index | ML Eng |
| **RAG: Faithfulness** | <80% | <70% | Revisar prompts/contexto | ML Eng |
| **API: LLM error rate** | >1% | >5% | Revisar prompts/fallback | ML Eng |
| **API: Response time p95** | >2s | >5s | Investigar bottleneck | Dev Team |
| **Business: Queries/min** | <50 | <10 | Investigar issue de entrada | Dev Team |

### 19.3 Dashboards Recomendados

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ESTRUCTURA DE DASHBOARDS                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. OPERATIONAL DASHBOARD (SRE/On-Call)                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  â€¢ Latencia por endpoint (p50, p95, p99)                                    â”‚
â”‚  â€¢ Error rate por servicio                                                   â”‚
â”‚  â€¢ Recursos de infraestructura (CPU, RAM, Disco)                            â”‚
â”‚  â€¢ Alertas activas                                                           â”‚
â”‚  â€¢ Status de servicios dependientes (APIs, Redis, etc.)                     â”‚
â”‚  â€¢ Ãšltimos 10 errores con stack trace                                       â”‚
â”‚                                                                              â”‚
â”‚  ActualizaciÃ³n: Real-time (1 segundo)                                        â”‚
â”‚  Usuarios: SRE, On-Call rotation                                             â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  2. RAG QUALITY DASHBOARD (ML Team)                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚
â”‚  â€¢ Retrieval metrics (recall, precision, MRR) - trend 7 dÃ­as               â”‚
â”‚  â€¢ Generation metrics (faithfulness, groundedness) - trend 7 dÃ­as          â”‚
â”‚  â€¢ Cache hit rates (L1, L2, total)                                          â”‚
â”‚  â€¢ Query patterns y distribuciÃ³n por Ã¡rea                                   â”‚
â”‚  â€¢ Latencia de embedding y reranking                                        â”‚
â”‚  â€¢ ComparaciÃ³n con golden set (desviaciÃ³n)                                  â”‚
â”‚                                                                              â”‚
â”‚  ActualizaciÃ³n: Cada 5 minutos                                               â”‚
â”‚  Usuarios: ML Engineers, Data Scientists                                     â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  3. COST DASHBOARD (Finance/Management)                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  â€¢ Gasto por servicio (Cloud SQL, LLM, embeddings, etc.)                    â”‚
â”‚  â€¢ Tendencia de costos (MoM, YoY)                                           â”‚
â”‚  â€¢ Cost per query (promedio, por Ã¡rea)                                      â”‚
â”‚  â€¢ ProyecciÃ³n mensual basada en trend                                       â”‚
â”‚  â€¢ Alertas de anomalÃ­as de costos                                           â”‚
â”‚  â€¢ Breakdown por Ã¡rea funcional                                             â”‚
â”‚                                                                              â”‚
â”‚  ActualizaciÃ³n: Diaria                                                       â”‚
â”‚  Usuarios: Finance, Engineering Management                                   â”‚
â”‚                                                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                              â”‚
â”‚  4. BUSINESS DASHBOARD (Stakeholders)                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  â€¢ Queries por dÃ­a/hora (volumen de uso)                                    â”‚
â”‚  â€¢ Queries por Ã¡rea funcional (RRHH, Legal, etc.)                           â”‚
â”‚  â€¢ User satisfaction (thumbs up/down ratio)                                 â”‚
â”‚  â€¢ Top 10 queries mÃ¡s frecuentes                                            â”‚
â”‚  â€¢ Ãreas sin consultas (gaps de contenido)                                  â”‚
â”‚  â€¢ Usuarios Ãºnicos por dÃ­a                                                  â”‚
â”‚                                                                              â”‚
â”‚  ActualizaciÃ³n: Cada hora                                                    â”‚
â”‚  Usuarios: Product Management, Stakeholders                                  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## CapÃ­tulo 20: DegradaciÃ³n Graceful

Un sistema RAG empresarial debe manejar fallos de componentes de manera elegante, sin impactar completamente la experiencia del usuario.

### 20.1 Fallback por Componente

| Componente | Falla TÃ­pica | Fallback | UX Impact | Mensaje Usuario |
|:-----------|:-------------|:---------|:----------|:----------------|
| **pgvector** | Timeout/Down | Cache semÃ¡ntico | Solo respuestas cacheadas | "Resultados limitados..." |
| **Embedding API** | Rate limit | Cola + retry exponencial | Latencia +2-5s | (silencioso) |
| **LLM API** | Sobrecarga | Gemini Flash (mÃ¡s pequeÃ±o) | Calidad reducida | "Respuesta resumida..." |
| **Reranker** | Falla/timeout | Skip reranking | PrecisiÃ³n -10-15% | (silencioso) |
| **Redis Cache** | Down | Bypass cache | Latencia +500ms, costo + | (silencioso) |
| **Read Replica** | Down | Redirect a primary | Mayor carga, latencia + | (silencioso) |
| **BM25 index** | Corrupto | Solo vector search | Recall -10% | (silencioso) |

### 20.2 Circuit Breaker Pattern

```python
# circuit_breaker.py - ImplementaciÃ³n de Circuit Breaker para servicios RAG

from circuitbreaker import circuit
from typing import Optional, List, Dict, Any
import logging
from dataclasses import dataclass
from enum import Enum
import time

logger = logging.getLogger(__name__)

class CircuitState(Enum):
    CLOSED = "closed"      # Normal operation
    OPEN = "open"          # Failing, using fallback
    HALF_OPEN = "half_open"  # Testing recovery

@dataclass
class CircuitBreakerConfig:
    failure_threshold: int = 5      # Fallas antes de abrir
    recovery_timeout: int = 60      # Segundos antes de intentar recovery
    success_threshold: int = 3      # Ã‰xitos para cerrar desde half-open

# ============================================================
# CIRCUIT BREAKER PARA VECTOR SEARCH
# ============================================================

@circuit(
    failure_threshold=5,
    recovery_timeout=60,
    expected_exception=Exception
)
def search_vectors(query_embedding: List[float], area: str, top_k: int = 20) -> List[Dict]:
    """
    BÃºsqueda vectorial con circuit breaker.
    Si falla 5 veces consecutivas, circuito se abre por 60 segundos.
    """
    try:
        # Llamada normal a pgvector
        results = pgvector_search(query_embedding, area, top_k)
        return results
    except Exception as e:
        logger.error(f"Vector search failed: {e}")
        raise

def search_with_fallback(query_embedding: List[float], area: str, top_k: int = 20) -> Dict:
    """
    Wrapper con fallback a cache semÃ¡ntico.
    """
    try:
        results = search_vectors(query_embedding, area, top_k)
        return {
            "results": results,
            "source": "pgvector",
            "degraded": False
        }
    except Exception as e:
        # Fallback a cache semÃ¡ntico
        logger.warning(f"Falling back to semantic cache: {e}")
        cached_results = semantic_cache.search_similar(query_embedding, top_k)
        
        if cached_results:
            return {
                "results": cached_results,
                "source": "semantic_cache",
                "degraded": True,
                "message": "Resultados desde informaciÃ³n previamente consultada"
            }
        else:
            return {
                "results": [],
                "source": "none",
                "degraded": True,
                "message": "Sistema temporalmente limitado"
            }

# ============================================================
# CIRCUIT BREAKER PARA LLM
# ============================================================

@circuit(
    failure_threshold=3,
    recovery_timeout=30,
    expected_exception=Exception
)
def generate_response_primary(prompt: str, context: str) -> str:
    """
    GeneraciÃ³n con modelo primario (Gemini Pro).
    """
    return llm_client.generate(
        model="gemini-1.5-pro",
        prompt=prompt,
        context=context
    )

@circuit(
    failure_threshold=5,
    recovery_timeout=60,
    expected_exception=Exception
)
def generate_response_fallback(prompt: str, context: str) -> str:
    """
    Fallback a modelo mÃ¡s pequeÃ±o y rÃ¡pido (Gemini Flash).
    """
    return llm_client.generate(
        model="gemini-1.5-flash",
        prompt=prompt,
        context=context
    )

def generate_with_fallback(prompt: str, context: str) -> Dict:
    """
    GeneraciÃ³n con fallback en cascada.
    """
    # Intento 1: Modelo primario
    try:
        response = generate_response_primary(prompt, context)
        return {
            "response": response,
            "model": "gemini-1.5-pro",
            "degraded": False
        }
    except Exception as e:
        logger.warning(f"Primary LLM failed, trying fallback: {e}")
    
    # Intento 2: Modelo fallback
    try:
        response = generate_response_fallback(prompt, context)
        return {
            "response": response,
            "model": "gemini-1.5-flash",
            "degraded": True,
            "message": "Respuesta usando modelo alternativo"
        }
    except Exception as e:
        logger.error(f"All LLMs failed: {e}")
        return {
            "response": None,
            "model": None,
            "degraded": True,
            "message": "No es posible generar una respuesta en este momento"
        }

# ============================================================
# HEALTH CHECK AGGREGATOR
# ============================================================

def get_system_health() -> Dict[str, Any]:
    """
    Retorna estado de salud de todos los componentes.
    """
    health = {
        "overall": "healthy",
        "components": {},
        "degraded_services": []
    }
    
    components = [
        ("pgvector", search_vectors),
        ("llm_primary", generate_response_primary),
        ("llm_fallback", generate_response_fallback),
    ]
    
    for name, func in components:
        state = getattr(func, '_circuit_state', CircuitState.CLOSED)
        is_healthy = state == CircuitState.CLOSED
        
        health["components"][name] = {
            "state": state.value,
            "healthy": is_healthy
        }
        
        if not is_healthy:
            health["degraded_services"].append(name)
    
    if health["degraded_services"]:
        health["overall"] = "degraded"
    
    return health
```

### 20.3 Mensajes de DegradaciÃ³n para Usuario

| Estado | CÃ³digo UI | Mensaje | Icono |
|:-------|:----------|:--------|:-----:|
| **Normal** | `normal` | (sin mensaje) | âœ… |
| **Cache hit** | `cached` | "Respuesta desde informaciÃ³n previamente consultada" | ğŸ’¾ |
| **Modelo degraded** | `degraded_llm` | "Estamos experimentando alta demanda. La respuesta puede ser menos detallada." | âš¡ |
| **BÃºsqueda limitada** | `degraded_search` | "Algunos resultados pueden no estar disponibles temporalmente." | ğŸ” |
| **Sistema parcial** | `partial_outage` | "Algunos servicios no estÃ¡n disponibles. Los resultados pueden ser limitados." | âš ï¸ |
| **Sistema down** | `full_outage` | "El sistema estÃ¡ temporalmente fuera de servicio. Por favor intente mÃ¡s tarde." | ğŸ”´ |

### 20.4 Cascada de DegradaciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CASCADA DE DEGRADACIÃ“N                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  NIVEL 0: NORMAL (100% funcionalidad)                                        â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                       â”‚
â”‚  â€¢ pgvector âœ…  â€¢ LLM Pro âœ…  â€¢ Reranker âœ…  â€¢ Cache âœ…                       â”‚
â”‚                                                                              â”‚
â”‚           â”‚ Falla Cache                                                      â”‚
â”‚           â–¼                                                                  â”‚
â”‚  NIVEL 1: DEGRADACIÃ“N LEVE (~95% funcionalidad)                              â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                             â”‚
â”‚  â€¢ pgvector âœ…  â€¢ LLM Pro âœ…  â€¢ Reranker âœ…  â€¢ Cache âŒ                       â”‚
â”‚  â†’ Latencia +500ms, costo de APIs +30%                                      â”‚
â”‚  â†’ Usuario: no notificado                                                    â”‚
â”‚                                                                              â”‚
â”‚           â”‚ Falla Reranker                                                   â”‚
â”‚           â–¼                                                                  â”‚
â”‚  NIVEL 2: DEGRADACIÃ“N MODERADA (~85% funcionalidad)                          â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                           â”‚
â”‚  â€¢ pgvector âœ…  â€¢ LLM Pro âœ…  â€¢ Reranker âŒ  â€¢ Cache âŒ                       â”‚
â”‚  â†’ PrecisiÃ³n -15%, latencia +500ms                                          â”‚
â”‚  â†’ Usuario: no notificado (impacto menor)                                   â”‚
â”‚                                                                              â”‚
â”‚           â”‚ Falla LLM Pro                                                    â”‚
â”‚           â–¼                                                                  â”‚
â”‚  NIVEL 3: DEGRADACIÃ“N SIGNIFICATIVA (~70% funcionalidad)                     â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                    â”‚
â”‚  â€¢ pgvector âœ…  â€¢ LLM Flash âš¡  â€¢ Reranker âŒ  â€¢ Cache âŒ                     â”‚
â”‚  â†’ Calidad de respuestas reducida                                           â”‚
â”‚  â†’ Usuario: "Alta demanda, respuesta resumida..."                           â”‚
â”‚                                                                              â”‚
â”‚           â”‚ Falla pgvector                                                   â”‚
â”‚           â–¼                                                                  â”‚
â”‚  NIVEL 4: MODO EMERGENCIA (~30% funcionalidad)                               â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                              â”‚
â”‚  â€¢ pgvector âŒ  â€¢ LLM Flash âš¡  â€¢ Solo cache semÃ¡ntico                       â”‚
â”‚  â†’ Solo queries previamente cacheadas                                       â”‚
â”‚  â†’ Usuario: "Sistema limitado, resultados parciales..."                     â”‚
â”‚                                                                              â”‚
â”‚           â”‚ Falla LLM Flash                                                  â”‚
â”‚           â–¼                                                                  â”‚
â”‚  NIVEL 5: SISTEMA DOWN (0% funcionalidad)                                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                  â”‚
â”‚  â€¢ Todo âŒ                                                                   â”‚
â”‚  â†’ Usuario: "Sistema fuera de servicio, intente mÃ¡s tarde..."               â”‚
â”‚  â†’ Alerta crÃ­tica a on-call                                                  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---
---

# ANEXOS

---

## Anexo A: Checklist Pre-ProducciÃ³n

Antes de llevar el sistema RAG a producciÃ³n, verificar que se cumplan todos los Ã­tems de este checklist.

### A.1 Infraestructura

| # | Item | Estado | Responsable | Notas |
|:-:|:-----|:------:|:------------|:------|
| 1 | Cloud SQL Enterprise provisionado | â˜ | DevOps | db-custom-16-96GB mÃ­nimo |
| 2 | pgvector extensiÃ³n instalada | â˜ | DBA | `CREATE EXTENSION vector;` |
| 3 | Read replicas configuradas (2x) | â˜ | DevOps | Para distribuciÃ³n de carga |
| 4 | Redis cache desplegado (Memorystore) | â˜ | DevOps | 16 GB Standard tier |
| 5 | Backups automÃ¡ticos habilitados | â˜ | DevOps | 7 dÃ­as retenciÃ³n, PITR |
| 6 | VPC y Private IP configurado | â˜ | NetOps | Sin exposiciÃ³n pÃºblica |
| 7 | Cloud Run/GKE para servicios API | â˜ | DevOps | Autoscaling configurado |
| 8 | SSL/TLS habilitado | â˜ | Security | Conexiones encriptadas |

### A.2 Datos

| # | Item | Estado | Responsable | Notas |
|:-:|:-----|:------:|:------------|:------|
| 9 | IngestiÃ³n inicial completada | â˜ | ML Eng | Todos los 17 TB procesados |
| 10 | Embeddings generados | â˜ | ML Eng | 244M vectores |
| 11 | Tabla con halfvec 768d | â˜ | DBA | Verificar tipo `halfvec(768)` |
| 12 | Ãndices HNSW construidos | â˜ | DBA | Uno por particiÃ³n |
| 13 | Ãndices BM25 (tsvector) construidos | â˜ | DBA | Para hybrid search |
| 14 | Particionamiento por Ã¡rea implementado | â˜ | DBA | 6 particiones |
| 15 | Metadata completa (permisos, fechas) | â˜ | ML Eng | Para filtrado |
| 16 | Pipeline CDC configurado | â˜ | Data Eng | Para actualizaciones |

### A.3 Calidad

| # | Item | Estado | Responsable | Notas |
|:-:|:-----|:------:|:------------|:------|
| 17 | Golden set de 200+ queries anotado | â˜ | QA | Con domain experts |
| 18 | Recall@10 > 90% validado | â˜ | ML Eng | En golden set |
| 19 | Faithfulness > 85% validado | â˜ | ML Eng | RAGAS |
| 20 | Groundedness > 90% validado | â˜ | ML Eng | Sin alucinaciones |
| 21 | Latencia p95 < 2s validada | â˜ | QA | End-to-end |
| 22 | Test de carga (100 QPS) pasado | â˜ | QA | Sin degradaciÃ³n |

### A.4 Observabilidad

| # | Item | Estado | Responsable | Notas |
|:-:|:-----|:------:|:------------|:------|
| 23 | Dashboards configurados (4) | â˜ | SRE | Ops, RAG, Cost, Business |
| 24 | Alertas configuradas | â˜ | SRE | Warning + Critical |
| 25 | Logging habilitado | â˜ | DevOps | Cloud Logging |
| 26 | Tracing habilitado | â˜ | DevOps | Cloud Trace |
| 27 | LLM observability (LangSmith) | â˜ | ML Eng | Token usage, traces |

### A.5 Operacional

| # | Item | Estado | Responsable | Notas |
|:-:|:-----|:------:|:------------|:------|
| 28 | Runbooks documentados | â˜ | SRE | Para incidentes comunes |
| 29 | Pipeline de actualizaciÃ³n probado | â˜ | Data Eng | CDC funcional |
| 30 | Procedimiento de rollback definido | â˜ | DevOps | Versionado |
| 31 | On-call rotation definida | â˜ | SRE | PagerDuty configurado |
| 32 | SLIs/SLOs definidos | â˜ | SRE | Latencia, disponibilidad |
| 33 | Escalation paths documentados | â˜ | Management | Para P1/P2 |

### A.6 Seguridad

| # | Item | Estado | Responsable | Notas |
|:-:|:-----|:------:|:------------|:------|
| 34 | IAM roles revisados (least privilege) | â˜ | Security | Solo acceso necesario |
| 35 | Encryption at rest verificado | â˜ | Security | Cloud SQL default |
| 36 | Encryption in transit verificado | â˜ | Security | TLS 1.3 |
| 37 | Network policies aplicadas | â˜ | NetOps | VPC Service Controls |
| 38 | Audit logging habilitado | â˜ | Security | Cloud Audit Logs |
| 39 | Data Loss Prevention (DLP) | â˜ | Security | Para PII en respuestas |
| 40 | Penetration test completado | â˜ | Security | Si aplica |

---

## Anexo B: Configuraciones SQL Recomendadas

### B.1 CreaciÃ³n de Tabla con halfvec

```sql
-- ============================================================
-- CREACIÃ“N DE TABLA PRINCIPAL CON HALFVEC Y PARTICIONAMIENTO
-- ============================================================

-- Habilitar extensiones necesarias
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS pg_trgm;  -- Para bÃºsquedas de texto

-- Crear tabla particionada por Ã¡rea
CREATE TABLE embeddings (
    id UUID DEFAULT gen_random_uuid(),
    
    -- Vector embedding (halfvec = float16, 768 dimensiones Matryoshka)
    embedding halfvec(768) NOT NULL,
    
    -- Contenido y metadata
    content TEXT NOT NULL,
    content_tokens INTEGER,
    
    -- BÃºsqueda full-text (BM25)
    content_tsv tsvector GENERATED ALWAYS AS (
        to_tsvector('spanish', content)
    ) STORED,
    
    -- Metadata del documento
    document_id UUID NOT NULL,
    document_title TEXT,
    document_path TEXT,
    chunk_index INTEGER,
    
    -- ClasificaciÃ³n
    area TEXT NOT NULL,  -- 'rrhh', 'legal', 'finanzas', etc.
    document_type TEXT,  -- 'politica', 'contrato', 'manual', etc.
    
    -- Permisos y fechas
    access_level TEXT DEFAULT 'internal',
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    deleted_at TIMESTAMPTZ,  -- Soft delete
    
    -- Constraints
    PRIMARY KEY (id, area)
    
) PARTITION BY LIST (area);

-- Crear particiones por Ã¡rea
CREATE TABLE embeddings_rrhh PARTITION OF embeddings FOR VALUES IN ('rrhh');
CREATE TABLE embeddings_legal PARTITION OF embeddings FOR VALUES IN ('legal');
CREATE TABLE embeddings_finanzas PARTITION OF embeddings FOR VALUES IN ('finanzas');
CREATE TABLE embeddings_operaciones PARTITION OF embeddings FOR VALUES IN ('operaciones');
CREATE TABLE embeddings_call_center PARTITION OF embeddings FOR VALUES IN ('call_center');
CREATE TABLE embeddings_general PARTITION OF embeddings FOR VALUES IN ('general');
```

### B.2 CreaciÃ³n de Ãndices HNSW

```sql
-- ============================================================
-- ÃNDICES HNSW POR PARTICIÃ“N
-- ============================================================

-- ParÃ¡metros HNSW:
-- m = 16: NÃºmero de conexiones por nodo (balance calidad/velocidad)
-- ef_construction = 64: Calidad de construcciÃ³n (mÃ¡s alto = mejor pero mÃ¡s lento)

-- Ãndice para cada particiÃ³n (permite partition pruning)
CREATE INDEX idx_embeddings_rrhh_hnsw ON embeddings_rrhh 
    USING hnsw (embedding halfvec_cosine_ops)
    WITH (m = 16, ef_construction = 64);

CREATE INDEX idx_embeddings_legal_hnsw ON embeddings_legal 
    USING hnsw (embedding halfvec_cosine_ops)
    WITH (m = 16, ef_construction = 64);

CREATE INDEX idx_embeddings_finanzas_hnsw ON embeddings_finanzas 
    USING hnsw (embedding halfvec_cosine_ops)
    WITH (m = 16, ef_construction = 64);

CREATE INDEX idx_embeddings_operaciones_hnsw ON embeddings_operaciones 
    USING hnsw (embedding halfvec_cosine_ops)
    WITH (m = 16, ef_construction = 64);

CREATE INDEX idx_embeddings_call_center_hnsw ON embeddings_call_center 
    USING hnsw (embedding halfvec_cosine_ops)
    WITH (m = 16, ef_construction = 64);

CREATE INDEX idx_embeddings_general_hnsw ON embeddings_general 
    USING hnsw (embedding halfvec_cosine_ops)
    WITH (m = 16, ef_construction = 64);

-- ============================================================
-- ÃNDICES BM25 (FULL-TEXT) PARA BÃšSQUEDA HÃBRIDA
-- ============================================================

CREATE INDEX idx_embeddings_rrhh_fts ON embeddings_rrhh USING GIN (content_tsv);
CREATE INDEX idx_embeddings_legal_fts ON embeddings_legal USING GIN (content_tsv);
CREATE INDEX idx_embeddings_finanzas_fts ON embeddings_finanzas USING GIN (content_tsv);
CREATE INDEX idx_embeddings_operaciones_fts ON embeddings_operaciones USING GIN (content_tsv);
CREATE INDEX idx_embeddings_call_center_fts ON embeddings_call_center USING GIN (content_tsv);
CREATE INDEX idx_embeddings_general_fts ON embeddings_general USING GIN (content_tsv);

-- ============================================================
-- ÃNDICES ADICIONALES PARA FILTRADO
-- ============================================================

CREATE INDEX idx_embeddings_document_id ON embeddings (document_id);
CREATE INDEX idx_embeddings_created_at ON embeddings (created_at);
CREATE INDEX idx_embeddings_deleted_at ON embeddings (deleted_at) WHERE deleted_at IS NULL;
```

### B.3 BÃºsqueda HÃ­brida con RRF

```sql
-- ============================================================
-- FUNCIÃ“N DE BÃšSQUEDA HÃBRIDA (VECTOR + BM25 + RRF)
-- ============================================================

CREATE OR REPLACE FUNCTION hybrid_search(
    query_embedding halfvec(768),
    query_text TEXT,
    search_area TEXT DEFAULT NULL,
    top_k INTEGER DEFAULT 20,
    vector_weight FLOAT DEFAULT 0.7,
    bm25_weight FLOAT DEFAULT 0.3,
    rrf_k INTEGER DEFAULT 60
)
RETURNS TABLE (
    id UUID,
    content TEXT,
    document_title TEXT,
    document_path TEXT,
    area TEXT,
    vector_score FLOAT,
    bm25_score FLOAT,
    rrf_score FLOAT
)
LANGUAGE plpgsql
AS $$
BEGIN
    RETURN QUERY
    WITH 
    -- BÃºsqueda vectorial (cosine similarity)
    vector_results AS (
        SELECT 
            e.id,
            e.content,
            e.document_title,
            e.document_path,
            e.area,
            1 - (e.embedding <=> query_embedding) AS score,
            ROW_NUMBER() OVER (ORDER BY e.embedding <=> query_embedding) AS rank
        FROM embeddings e
        WHERE 
            (search_area IS NULL OR e.area = search_area)
            AND e.deleted_at IS NULL
        ORDER BY e.embedding <=> query_embedding
        LIMIT top_k * 2
    ),
    
    -- BÃºsqueda BM25 (full-text)
    bm25_results AS (
        SELECT 
            e.id,
            e.content,
            e.document_title,
            e.document_path,
            e.area,
            ts_rank_cd(e.content_tsv, plainto_tsquery('spanish', query_text)) AS score,
            ROW_NUMBER() OVER (
                ORDER BY ts_rank_cd(e.content_tsv, plainto_tsquery('spanish', query_text)) DESC
            ) AS rank
        FROM embeddings e
        WHERE 
            e.content_tsv @@ plainto_tsquery('spanish', query_text)
            AND (search_area IS NULL OR e.area = search_area)
            AND e.deleted_at IS NULL
        ORDER BY ts_rank_cd(e.content_tsv, plainto_tsquery('spanish', query_text)) DESC
        LIMIT top_k * 2
    ),
    
    -- FusiÃ³n con Reciprocal Rank Fusion (RRF)
    combined AS (
        SELECT 
            COALESCE(v.id, b.id) AS id,
            COALESCE(v.content, b.content) AS content,
            COALESCE(v.document_title, b.document_title) AS document_title,
            COALESCE(v.document_path, b.document_path) AS document_path,
            COALESCE(v.area, b.area) AS area,
            COALESCE(v.score, 0) AS vector_score,
            COALESCE(b.score, 0) AS bm25_score,
            -- RRF: score = sum(1 / (k + rank))
            (
                CASE WHEN v.rank IS NOT NULL 
                     THEN vector_weight * (1.0 / (rrf_k + v.rank)) 
                     ELSE 0 
                END
            ) + (
                CASE WHEN b.rank IS NOT NULL 
                     THEN bm25_weight * (1.0 / (rrf_k + b.rank)) 
                     ELSE 0 
                END
            ) AS rrf_score
        FROM vector_results v
        FULL OUTER JOIN bm25_results b ON v.id = b.id
    )
    
    SELECT 
        c.id,
        c.content,
        c.document_title,
        c.document_path,
        c.area,
        c.vector_score::FLOAT,
        c.bm25_score::FLOAT,
        c.rrf_score::FLOAT
    FROM combined c
    ORDER BY c.rrf_score DESC
    LIMIT top_k;
END;
$$;

-- ============================================================
-- EJEMPLO DE USO
-- ============================================================

-- BÃºsqueda hÃ­brida en Ã¡rea especÃ­fica
SELECT * FROM hybrid_search(
    query_embedding := '[0.1, 0.2, ...]'::halfvec(768),  -- Embedding de la query
    query_text := 'Â¿cuÃ¡ntos dÃ­as de vacaciones tengo?',
    search_area := 'rrhh',
    top_k := 10
);

-- BÃºsqueda hÃ­brida en todas las Ã¡reas
SELECT * FROM hybrid_search(
    query_embedding := '[0.1, 0.2, ...]'::halfvec(768),
    query_text := 'polÃ­tica de trabajo remoto',
    search_area := NULL,  -- Todas las Ã¡reas
    top_k := 20,
    vector_weight := 0.6,
    bm25_weight := 0.4
);
```

### B.4 ConfiguraciÃ³n de PostgreSQL para pgvector

```sql
-- ============================================================
-- CONFIGURACIÃ“N DE POSTGRESQL PARA PGVECTOR (postgresql.conf)
-- ============================================================

-- Memoria para bÃºsquedas HNSW
-- ef_search: calidad de bÃºsqueda (mayor = mejor recall pero mÃ¡s lento)
SET hnsw.ef_search = 100;  -- Default: 40, recomendado: 100-200

-- Trabajo de Ã­ndice
SET maintenance_work_mem = '4GB';  -- Para construcciÃ³n de Ã­ndices

-- Paralelismo
SET max_parallel_workers_per_gather = 4;
SET max_parallel_workers = 8;

-- Buffer pool (30% de RAM disponible)
SET shared_buffers = '24GB';  -- Para 80 GB RAM total

-- Work memory por query
SET work_mem = '256MB';

-- EstadÃ­sticas
SET default_statistics_target = 500;
```

---

## Anexo C: CÃ³digo de Referencia

### C.1 Pipeline de Chunking Adaptativo (Python)

```python
# chunking_pipeline.py - Pipeline de chunking adaptativo por tipo de documento

from typing import List, Dict, Optional
from dataclasses import dataclass
from enum import Enum
import re

class DocumentType(Enum):
    LEGAL = "legal"
    TECHNICAL = "technical"
    FAQ = "faq"
    POLICY = "policy"
    GENERAL = "general"

@dataclass
class ChunkConfig:
    """ConfiguraciÃ³n de chunking por tipo de documento."""
    chunk_size: int
    overlap: int
    strategy: str
    description: str

# Configuraciones por tipo de documento
CHUNK_CONFIGS: Dict[DocumentType, ChunkConfig] = {
    DocumentType.LEGAL: ChunkConfig(
        chunk_size=1024,
        overlap=256,  # 25% overlap
        strategy="agentic",
        description="Documentos legales - mayor overlap para preservar contexto"
    ),
    DocumentType.TECHNICAL: ChunkConfig(
        chunk_size=1024,
        overlap=150,  # 15% overlap
        strategy="recursive",
        description="Manuales tÃ©cnicos - balance costo/calidad"
    ),
    DocumentType.FAQ: ChunkConfig(
        chunk_size=512,
        overlap=0,  # Sin overlap
        strategy="sentence",
        description="FAQs - cada Q&A es una unidad independiente"
    ),
    DocumentType.POLICY: ChunkConfig(
        chunk_size=768,
        overlap=100,  # ~13% overlap
        strategy="recursive",
        description="PolÃ­ticas - chunks medianos"
    ),
    DocumentType.GENERAL: ChunkConfig(
        chunk_size=512,
        overlap=75,  # ~15% overlap
        strategy="recursive",
        description="Documentos generales - configuraciÃ³n estÃ¡ndar"
    ),
}

class AdaptiveChunker:
    """
    Chunker adaptativo que selecciona estrategia segÃºn tipo de documento.
    """
    
    def __init__(self):
        self.separators = ["\n\n", "\n", ". ", " ", ""]
    
    def detect_document_type(self, content: str, metadata: Dict) -> DocumentType:
        """
        Detecta el tipo de documento basado en contenido y metadata.
        """
        # Reglas basadas en metadata
        doc_type = metadata.get("document_type", "").lower()
        area = metadata.get("area", "").lower()
        
        if "contrato" in doc_type or area == "legal":
            return DocumentType.LEGAL
        elif "manual" in doc_type or "tÃ©cnico" in doc_type.lower():
            return DocumentType.TECHNICAL
        elif "faq" in doc_type or "preguntas" in doc_type:
            return DocumentType.FAQ
        elif "polÃ­tica" in doc_type or "procedimiento" in doc_type:
            return DocumentType.POLICY
        
        # Reglas basadas en contenido
        if re.search(r'artÃ­culo \d+|clÃ¡usula', content.lower()):
            return DocumentType.LEGAL
        
        return DocumentType.GENERAL
    
    def chunk_document(
        self, 
        content: str, 
        metadata: Dict,
        force_type: Optional[DocumentType] = None
    ) -> List[Dict]:
        """
        Divide un documento en chunks segÃºn su tipo detectado.
        
        Returns:
            Lista de dicts con 'content', 'chunk_index', 'config'
        """
        doc_type = force_type or self.detect_document_type(content, metadata)
        config = CHUNK_CONFIGS[doc_type]
        
        if config.strategy == "sentence":
            chunks = self._sentence_chunk(content, config)
        elif config.strategy == "agentic":
            chunks = self._agentic_chunk(content, config)
        else:
            chunks = self._recursive_chunk(content, config)
        
        return [
            {
                "content": chunk,
                "chunk_index": i,
                "chunk_size": len(chunk),
                "document_type": doc_type.value,
                "config": {
                    "strategy": config.strategy,
                    "target_size": config.chunk_size,
                    "overlap": config.overlap
                }
            }
            for i, chunk in enumerate(chunks)
        ]
    
    def _recursive_chunk(self, text: str, config: ChunkConfig) -> List[str]:
        """Chunking recursivo con separadores jerÃ¡rquicos."""
        chunks = []
        self._split_recursive(
            text, 
            config.chunk_size, 
            config.overlap, 
            self.separators, 
            chunks
        )
        return chunks
    
    def _split_recursive(
        self, 
        text: str, 
        chunk_size: int, 
        overlap: int,
        separators: List[str], 
        chunks: List[str]
    ):
        """Helper recursivo para chunking."""
        if len(text) <= chunk_size:
            if text.strip():
                chunks.append(text.strip())
            return
        
        separator = separators[0] if separators else ""
        parts = text.split(separator) if separator else list(text)
        
        current_chunk = ""
        for part in parts:
            test_chunk = current_chunk + separator + part if current_chunk else part
            
            if len(test_chunk) > chunk_size:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                    # Overlap: comenzar el siguiente chunk con parte del anterior
                    if overlap > 0:
                        current_chunk = current_chunk[-overlap:] + separator + part
                    else:
                        current_chunk = part
                else:
                    # Parte muy larga, intentar con siguiente separador
                    if len(separators) > 1:
                        self._split_recursive(
                            part, chunk_size, overlap, separators[1:], chunks
                        )
                        current_chunk = ""
                    else:
                        # Ãšltimo recurso: cortar por caracteres
                        for i in range(0, len(part), chunk_size - overlap):
                            chunks.append(part[i:i + chunk_size])
                        current_chunk = ""
            else:
                current_chunk = test_chunk
        
        if current_chunk.strip():
            chunks.append(current_chunk.strip())
    
    def _sentence_chunk(self, text: str, config: ChunkConfig) -> List[str]:
        """Chunking por oraciones completas."""
        import nltk
        nltk.download('punkt', quiet=True)
        from nltk.tokenize import sent_tokenize
        
        sentences = sent_tokenize(text, language='spanish')
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk) + len(sentence) <= config.chunk_size:
                current_chunk += " " + sentence if current_chunk else sentence
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def _agentic_chunk(self, text: str, config: ChunkConfig) -> List[str]:
        """
        Chunking usando LLM para identificar boundaries semÃ¡nticos.
        (VersiÃ³n simplificada - en producciÃ³n usar Gemini)
        """
        # Para producciÃ³n: llamar a Gemini para identificar boundaries
        # AquÃ­ usamos recursive como fallback
        return self._recursive_chunk(text, config)
```

### C.2 Semantic Cache con Redis (Python)

```python
# semantic_cache.py - Cache semÃ¡ntico multi-nivel con Redis

import redis
import json
import hashlib
import numpy as np
from typing import Optional, List, Dict, Any, Tuple
from dataclasses import dataclass
import time

@dataclass
class CacheConfig:
    """ConfiguraciÃ³n del cache semÃ¡ntico."""
    # TTLs por tipo de cache
    exact_ttl: int = 86400  # 24 horas
    semantic_ttl: int = 3600  # 1 hora
    embedding_ttl: int = 604800  # 7 dÃ­as
    
    # Thresholds
    similarity_threshold: float = 0.95  # Para cache hit semÃ¡ntico
    
    # ConfiguraciÃ³n Redis
    redis_host: str = "localhost"
    redis_port: int = 6379
    redis_db: int = 0
    
    # Prefijos de keys
    exact_prefix: str = "rag:exact:"
    semantic_prefix: str = "rag:semantic:"
    embedding_prefix: str = "rag:emb:"

class SemanticCache:
    """
    Cache semÃ¡ntico multi-nivel para sistema RAG.
    
    Niveles:
    1. L1 (Exact Match): Hash de la query exacta
    2. L2 (Semantic): BÃºsqueda por similitud de embedding
    3. L3 (Embedding): Cache de embeddings calculados
    """
    
    def __init__(self, config: CacheConfig = None):
        self.config = config or CacheConfig()
        self.redis = redis.Redis(
            host=self.config.redis_host,
            port=self.config.redis_port,
            db=self.config.redis_db,
            decode_responses=False  # Para manejar binarios
        )
        
        # MÃ©tricas
        self.stats = {
            "exact_hits": 0,
            "semantic_hits": 0,
            "misses": 0,
            "embedding_hits": 0
        }
    
    def _hash_query(self, query: str) -> str:
        """Genera hash de la query para exact match."""
        normalized = query.lower().strip()
        return hashlib.sha256(normalized.encode()).hexdigest()[:16]
    
    def _serialize_embedding(self, embedding: List[float]) -> bytes:
        """Serializa embedding a bytes."""
        return np.array(embedding, dtype=np.float16).tobytes()
    
    def _deserialize_embedding(self, data: bytes) -> List[float]:
        """Deserializa bytes a embedding."""
        return np.frombuffer(data, dtype=np.float16).tolist()
    
    # ============================================================
    # L1: EXACT MATCH CACHE
    # ============================================================
    
    def get_exact(self, query: str, area: str = None) -> Optional[Dict]:
        """
        Busca respuesta cacheada por match exacto.
        
        Returns:
            Dict con 'response', 'contexts', 'cached_at' o None
        """
        key = f"{self.config.exact_prefix}{area or 'all'}:{self._hash_query(query)}"
        
        data = self.redis.get(key)
        if data:
            self.stats["exact_hits"] += 1
            return json.loads(data)
        return None
    
    def set_exact(
        self, 
        query: str, 
        response: str, 
        contexts: List[str],
        area: str = None
    ):
        """Guarda respuesta en cache exact match."""
        key = f"{self.config.exact_prefix}{area or 'all'}:{self._hash_query(query)}"
        
        data = {
            "response": response,
            "contexts": contexts,
            "cached_at": time.time(),
            "cache_type": "exact"
        }
        
        self.redis.setex(
            key, 
            self.config.exact_ttl, 
            json.dumps(data)
        )
    
    # ============================================================
    # L2: SEMANTIC SIMILARITY CACHE
    # ============================================================
    
    def get_semantic(
        self, 
        query_embedding: List[float], 
        area: str = None,
        threshold: float = None
    ) -> Optional[Dict]:
        """
        Busca respuesta cacheada por similitud semÃ¡ntica.
        
        Usa Redis como vector store simple para los embeddings cacheados.
        En producciÃ³n, considerar RediSearch con vector similarity.
        """
        threshold = threshold or self.config.similarity_threshold
        pattern = f"{self.config.semantic_prefix}{area or 'all'}:*"
        
        best_match = None
        best_similarity = 0
        
        # Buscar en embeddings cacheados
        for key in self.redis.scan_iter(match=pattern, count=100):
            data = self.redis.get(key)
            if data:
                cached = json.loads(data)
                cached_emb = self._deserialize_embedding(
                    bytes.fromhex(cached["embedding_hex"])
                )
                
                # Calcular cosine similarity
                similarity = self._cosine_similarity(query_embedding, cached_emb)
                
                if similarity > best_similarity and similarity >= threshold:
                    best_similarity = similarity
                    best_match = cached
        
        if best_match:
            self.stats["semantic_hits"] += 1
            return {
                "response": best_match["response"],
                "contexts": best_match["contexts"],
                "cached_at": best_match["cached_at"],
                "similarity": best_similarity,
                "cache_type": "semantic"
            }
        
        return None
    
    def set_semantic(
        self, 
        query_embedding: List[float],
        response: str, 
        contexts: List[str],
        area: str = None
    ):
        """Guarda respuesta en cache semÃ¡ntico."""
        # Usar hash del embedding como key
        emb_bytes = self._serialize_embedding(query_embedding)
        emb_hash = hashlib.sha256(emb_bytes).hexdigest()[:16]
        
        key = f"{self.config.semantic_prefix}{area or 'all'}:{emb_hash}"
        
        data = {
            "embedding_hex": emb_bytes.hex(),
            "response": response,
            "contexts": contexts,
            "cached_at": time.time()
        }
        
        self.redis.setex(
            key, 
            self.config.semantic_ttl, 
            json.dumps(data)
        )
    
    # ============================================================
    # L3: EMBEDDING CACHE
    # ============================================================
    
    def get_embedding(self, text: str) -> Optional[List[float]]:
        """Obtiene embedding cacheado de un texto."""
        key = f"{self.config.embedding_prefix}{self._hash_query(text)}"
        
        data = self.redis.get(key)
        if data:
            self.stats["embedding_hits"] += 1
            return self._deserialize_embedding(data)
        return None
    
    def set_embedding(self, text: str, embedding: List[float]):
        """Cachea embedding de un texto."""
        key = f"{self.config.embedding_prefix}{self._hash_query(text)}"
        
        self.redis.setex(
            key,
            self.config.embedding_ttl,
            self._serialize_embedding(embedding)
        )
    
    # ============================================================
    # UTILIDADES
    # ============================================================
    
    def _cosine_similarity(self, a: List[float], b: List[float]) -> float:
        """Calcula similitud coseno entre dos vectores."""
        a = np.array(a)
        b = np.array(b)
        return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))
    
    def get_stats(self) -> Dict[str, Any]:
        """Retorna estadÃ­sticas del cache."""
        total = sum(self.stats.values())
        return {
            **self.stats,
            "total_requests": total,
            "hit_rate": (
                (self.stats["exact_hits"] + self.stats["semantic_hits"]) / total 
                if total > 0 else 0
            )
        }
    
    def clear_area(self, area: str):
        """Limpia cache de un Ã¡rea especÃ­fica."""
        patterns = [
            f"{self.config.exact_prefix}{area}:*",
            f"{self.config.semantic_prefix}{area}:*"
        ]
        for pattern in patterns:
            for key in self.redis.scan_iter(match=pattern):
                self.redis.delete(key)
```

---

## Anexo D: Referencias y Fuentes

### D.1 Papers AcadÃ©micos

| Paper | AÃ±o | Tema | URL |
|:------|:---:|:-----|:----|
| Matryoshka Representation Learning | 2022 | Embeddings anidados | https://arxiv.org/abs/2205.13147 |
| ColBERT: Efficient and Effective Passage Search | 2020 | Late Interaction | https://arxiv.org/abs/2004.12832 |
| HyDE: Hypothetical Document Embeddings | 2022 | Query expansion | https://arxiv.org/abs/2212.10496 |
| Late Chunking | 2024 | Chunking mejorado | https://arxiv.org/abs/2409.04701 |
| HNSW: Hierarchical NSW Graphs | 2016 | Ãndices aproximados | https://arxiv.org/abs/1603.09320 |
| Cohere Rerank | 2023 | Cross-encoder reranking | https://txt.cohere.com/rerank/ |
| RAGAS | 2023 | EvaluaciÃ³n de RAG | https://arxiv.org/abs/2309.15217 |

### D.2 DocumentaciÃ³n Oficial

| Recurso | DescripciÃ³n | URL |
|:--------|:------------|:----|
| pgvector | ExtensiÃ³n vectorial PostgreSQL | https://github.com/pgvector/pgvector |
| Cloud SQL | Base de datos managed GCP | https://cloud.google.com/sql/docs |
| Gemini Embeddings | API de embeddings | https://cloud.google.com/vertex-ai/docs/generative-ai/embeddings |
| LangChain | Framework RAG | https://python.langchain.com/ |
| RAGAS | EvaluaciÃ³n automatizada | https://docs.ragas.io/ |
| Redis | Cache distribuido | https://redis.io/docs/ |

### D.3 Benchmarks y Comparativas

| Benchmark | DescripciÃ³n | URL |
|:----------|:------------|:----|
| MTEB Leaderboard | Benchmark de embeddings | https://huggingface.co/spaces/mteb/leaderboard |
| Pinecone Benchmarks | Comparativa de VectorDBs | https://www.pinecone.io/learn/vector-database-benchmark/ |
| ANN Benchmarks | Benchmark de Ã­ndices ANN | https://ann-benchmarks.com/ |
| Qdrant Benchmarks | Performance vectorial | https://qdrant.tech/benchmarks/ |

---

## Anexo E: Glosario de TÃ©rminos

| TÃ©rmino | DefiniciÃ³n |
|:--------|:-----------|
| **ANN** | Approximate Nearest Neighbors - Algoritmo para bÃºsqueda aproximada de vecinos mÃ¡s cercanos |
| **BM25** | Best Matching 25 - Algoritmo de ranking para bÃºsqueda de texto |
| **CDC** | Change Data Capture - TÃ©cnica para detectar cambios en datos |
| **Chunk** | Fragmento de texto que se convierte en un vector |
| **Cosine Similarity** | Medida de similitud entre vectores basada en el Ã¡ngulo |
| **Cross-Encoder** | Modelo que procesa query y documento juntos para scoring |
| **Embedding** | RepresentaciÃ³n numÃ©rica (vector) de texto |
| **ef_search** | ParÃ¡metro HNSW que controla calidad vs. velocidad |
| **Faithfulness** | MÃ©trica que mide si la respuesta es fiel al contexto |
| **Groundedness** | MÃ©trica que mide si la respuesta evita alucinaciones |
| **halfvec** | Tipo de dato pgvector con precisiÃ³n float16 |
| **HNSW** | Hierarchical Navigable Small World - Algoritmo de Ã­ndice ANN |
| **HyDE** | Hypothetical Document Embeddings - TÃ©cnica de query expansion |
| **Late Interaction** | Arquitectura donde query y doc se procesan por separado |
| **Matryoshka** | TÃ©cnica de embeddings que permite truncar dimensiones |
| **MRR** | Mean Reciprocal Rank - MÃ©trica de calidad de ranking |
| **nDCG** | Normalized Discounted Cumulative Gain - MÃ©trica de ranking |
| **Overlap** | Solapamiento entre chunks consecutivos |
| **Partition Pruning** | OptimizaciÃ³n que evita escanear particiones innecesarias |
| **pgvector** | ExtensiÃ³n de PostgreSQL para bÃºsqueda vectorial |
| **RAG** | Retrieval-Augmented Generation - PatrÃ³n de generaciÃ³n con contexto |
| **RAGAS** | Framework de evaluaciÃ³n de sistemas RAG |
| **Recall@K** | ProporciÃ³n de docs relevantes en top K resultados |
| **Reranking** | Re-ordenamiento de resultados con modelo mÃ¡s preciso |
| **RRF** | Reciprocal Rank Fusion - Algoritmo para fusionar rankings |
| **RPO** | Recovery Point Objective - PÃ©rdida de datos aceptable |
| **RTO** | Recovery Time Objective - Tiempo de downtime aceptable |
| **Semantic Cache** | Cache basado en similitud semÃ¡ntica |
| **TCO** | Total Cost of Ownership - Costo total de propiedad |
| **tsvector** | Tipo de dato PostgreSQL para bÃºsqueda full-text |
| **Vector Database** | Base de datos optimizada para bÃºsqueda vectorial |

---
---

# ğŸ“Š RESUMEN DEL DOCUMENTO

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RESUMEN FINAL DEL DOCUMENTO                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  ğŸ“„ ESTRUCTURA                                                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                               â”‚
â”‚  â€¢ Secciones: 6 (I-VI) + Anexos                                             â”‚
â”‚  â€¢ CapÃ­tulos: 20                                                             â”‚
â”‚  â€¢ Anexos: 5 (A-E)                                                           â”‚
â”‚                                                                              â”‚
â”‚  ğŸ“Š CONTENIDO                                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                â”‚
â”‚  â€¢ Tablas: ~75                                                               â”‚
â”‚  â€¢ Diagramas ASCII: ~35                                                      â”‚
â”‚  â€¢ Bloques de cÃ³digo: ~25 (SQL + Python)                                    â”‚
â”‚  â€¢ FÃ³rmulas matemÃ¡ticas: ~30                                                 â”‚
â”‚                                                                              â”‚
â”‚  ğŸ“ EXTENSIÃ“N                                                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                 â”‚
â”‚  â€¢ LÃ­neas: ~5,400                                                            â”‚
â”‚  â€¢ Palabras: ~45,000                                                         â”‚
â”‚  â€¢ PÃ¡ginas estimadas: ~120 (A4)                                              â”‚
â”‚                                                                              â”‚
â”‚  âœ… COBERTURA                                                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                                â”‚
â”‚  â€¢ 100% del contenido del BLUEPRINT fuente incluido                         â”‚
â”‚  â€¢ Reorganizado en estructura jerÃ¡rquica                                    â”‚
â”‚  â€¢ Ampliado con cÃ³digo de producciÃ³n                                        â”‚
â”‚  â€¢ Agregados diagramas y tablas adicionales                                 â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---
---

<div align="center">

## ğŸ“‹ CONTROL DEL DOCUMENTO

| Campo | Valor |
|:------|:------|
| **TÃ­tulo** | Arquitectura de Base de Datos Vectorial para Sistema RAG Empresarial |
| **VersiÃ³n** | 3.0 |
| **Estado** | âœ… VersiÃ³n Final |
| **Fecha de GeneraciÃ³n** | 2026-01-27 |
| **PrÃ³xima RevisiÃ³n** | 2026-04-27 (3 meses) |
| **ClasificaciÃ³n** | ğŸ”’ Documento TÃ©cnico Interno |
| **DistribuciÃ³n** | Arquitectura, ML/AI, DevOps, SRE, Stakeholders |

---

### Control de Versiones

| VersiÃ³n | Fecha | Autor | Cambios |
|:-------:|:-----:|:------|:--------|
| 1.0 | 2025-11 | Equipo Arquitectura | Documento inicial |
| 2.0 | 2025-12 | Equipo Arquitectura | Agregado anÃ¡lisis de costos |
| 3.0 | 2026-01 | Equipo Arquitectura | VersiÃ³n completa con anexos |

---

### Aprobaciones

| Rol | Nombre | Fecha | Firma |
|:----|:-------|:-----:|:-----:|
| Arquitecto Principal | ______________ | ___/___/___ | â˜ |
| Tech Lead ML/AI | ______________ | ___/___/___ | â˜ |
| Director de IngenierÃ­a | ______________ | ___/___/___ | â˜ |

---

**Â© 2026 Enterprise AI Platform - Documento Confidencial**

</div>
